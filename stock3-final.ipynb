{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae6752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b2550",
   "metadata": {},
   "source": [
    "This Project is predicting stocks for Apple company with error less than 5% using LSTM Networks. I have not used pre-built models. I have trained LSTM NN models for Apple Company listed below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8ad5e",
   "metadata": {},
   "source": [
    "Loading the Dataset..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b1b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6dcbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>adjHigh</th>\n",
       "      <th>adjLow</th>\n",
       "      <th>adjOpen</th>\n",
       "      <th>adjVolume</th>\n",
       "      <th>divCash</th>\n",
       "      <th>splitFactor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-05-27 00:00:00+00:00</td>\n",
       "      <td>132.045</td>\n",
       "      <td>132.260</td>\n",
       "      <td>130.05</td>\n",
       "      <td>130.34</td>\n",
       "      <td>45833246</td>\n",
       "      <td>121.682558</td>\n",
       "      <td>121.880685</td>\n",
       "      <td>119.844118</td>\n",
       "      <td>120.111360</td>\n",
       "      <td>45833246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-05-28 00:00:00+00:00</td>\n",
       "      <td>131.780</td>\n",
       "      <td>131.950</td>\n",
       "      <td>131.10</td>\n",
       "      <td>131.86</td>\n",
       "      <td>30733309</td>\n",
       "      <td>121.438354</td>\n",
       "      <td>121.595013</td>\n",
       "      <td>120.811718</td>\n",
       "      <td>121.512076</td>\n",
       "      <td>30733309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-05-29 00:00:00+00:00</td>\n",
       "      <td>130.280</td>\n",
       "      <td>131.450</td>\n",
       "      <td>129.90</td>\n",
       "      <td>131.23</td>\n",
       "      <td>50884452</td>\n",
       "      <td>120.056069</td>\n",
       "      <td>121.134251</td>\n",
       "      <td>119.705890</td>\n",
       "      <td>120.931516</td>\n",
       "      <td>50884452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-06-01 00:00:00+00:00</td>\n",
       "      <td>130.535</td>\n",
       "      <td>131.390</td>\n",
       "      <td>130.05</td>\n",
       "      <td>131.20</td>\n",
       "      <td>32112797</td>\n",
       "      <td>120.291057</td>\n",
       "      <td>121.078960</td>\n",
       "      <td>119.844118</td>\n",
       "      <td>120.903870</td>\n",
       "      <td>32112797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2015-06-02 00:00:00+00:00</td>\n",
       "      <td>129.960</td>\n",
       "      <td>130.655</td>\n",
       "      <td>129.32</td>\n",
       "      <td>129.86</td>\n",
       "      <td>33667627</td>\n",
       "      <td>119.761181</td>\n",
       "      <td>120.401640</td>\n",
       "      <td>119.171406</td>\n",
       "      <td>119.669029</td>\n",
       "      <td>33667627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 symbol                       date    close     high     low  \\\n",
       "0           0   AAPL  2015-05-27 00:00:00+00:00  132.045  132.260  130.05   \n",
       "1           1   AAPL  2015-05-28 00:00:00+00:00  131.780  131.950  131.10   \n",
       "2           2   AAPL  2015-05-29 00:00:00+00:00  130.280  131.450  129.90   \n",
       "3           3   AAPL  2015-06-01 00:00:00+00:00  130.535  131.390  130.05   \n",
       "4           4   AAPL  2015-06-02 00:00:00+00:00  129.960  130.655  129.32   \n",
       "\n",
       "     open    volume    adjClose     adjHigh      adjLow     adjOpen  \\\n",
       "0  130.34  45833246  121.682558  121.880685  119.844118  120.111360   \n",
       "1  131.86  30733309  121.438354  121.595013  120.811718  121.512076   \n",
       "2  131.23  50884452  120.056069  121.134251  119.705890  120.931516   \n",
       "3  131.20  32112797  120.291057  121.078960  119.844118  120.903870   \n",
       "4  129.86  33667627  119.761181  120.401640  119.171406  119.669029   \n",
       "\n",
       "   adjVolume  divCash  splitFactor  \n",
       "0   45833246      0.0          1.0  \n",
       "1   30733309      0.0          1.0  \n",
       "2   50884452      0.0          1.0  \n",
       "3   32112797      0.0          1.0  \n",
       "4   33667627      0.0          1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1927ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>adjHigh</th>\n",
       "      <th>adjLow</th>\n",
       "      <th>adjOpen</th>\n",
       "      <th>adjVolume</th>\n",
       "      <th>divCash</th>\n",
       "      <th>splitFactor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>1253</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-18 00:00:00+00:00</td>\n",
       "      <td>314.96</td>\n",
       "      <td>316.50</td>\n",
       "      <td>310.3241</td>\n",
       "      <td>313.17</td>\n",
       "      <td>33843125</td>\n",
       "      <td>314.96</td>\n",
       "      <td>316.50</td>\n",
       "      <td>310.3241</td>\n",
       "      <td>313.17</td>\n",
       "      <td>33843125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>1254</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-19 00:00:00+00:00</td>\n",
       "      <td>313.14</td>\n",
       "      <td>318.52</td>\n",
       "      <td>313.0100</td>\n",
       "      <td>315.03</td>\n",
       "      <td>25432385</td>\n",
       "      <td>313.14</td>\n",
       "      <td>318.52</td>\n",
       "      <td>313.0100</td>\n",
       "      <td>315.03</td>\n",
       "      <td>25432385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>1255</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-20 00:00:00+00:00</td>\n",
       "      <td>319.23</td>\n",
       "      <td>319.52</td>\n",
       "      <td>316.2000</td>\n",
       "      <td>316.68</td>\n",
       "      <td>27876215</td>\n",
       "      <td>319.23</td>\n",
       "      <td>319.52</td>\n",
       "      <td>316.2000</td>\n",
       "      <td>316.68</td>\n",
       "      <td>27876215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>1256</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-21 00:00:00+00:00</td>\n",
       "      <td>316.85</td>\n",
       "      <td>320.89</td>\n",
       "      <td>315.8700</td>\n",
       "      <td>318.66</td>\n",
       "      <td>25672211</td>\n",
       "      <td>316.85</td>\n",
       "      <td>320.89</td>\n",
       "      <td>315.8700</td>\n",
       "      <td>318.66</td>\n",
       "      <td>25672211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>1257</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-22 00:00:00+00:00</td>\n",
       "      <td>318.89</td>\n",
       "      <td>319.23</td>\n",
       "      <td>315.3500</td>\n",
       "      <td>315.77</td>\n",
       "      <td>20450754</td>\n",
       "      <td>318.89</td>\n",
       "      <td>319.23</td>\n",
       "      <td>315.3500</td>\n",
       "      <td>315.77</td>\n",
       "      <td>20450754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 symbol                       date   close    high       low  \\\n",
       "1253        1253   AAPL  2020-05-18 00:00:00+00:00  314.96  316.50  310.3241   \n",
       "1254        1254   AAPL  2020-05-19 00:00:00+00:00  313.14  318.52  313.0100   \n",
       "1255        1255   AAPL  2020-05-20 00:00:00+00:00  319.23  319.52  316.2000   \n",
       "1256        1256   AAPL  2020-05-21 00:00:00+00:00  316.85  320.89  315.8700   \n",
       "1257        1257   AAPL  2020-05-22 00:00:00+00:00  318.89  319.23  315.3500   \n",
       "\n",
       "        open    volume  adjClose  adjHigh    adjLow  adjOpen  adjVolume  \\\n",
       "1253  313.17  33843125    314.96   316.50  310.3241   313.17   33843125   \n",
       "1254  315.03  25432385    313.14   318.52  313.0100   315.03   25432385   \n",
       "1255  316.68  27876215    319.23   319.52  316.2000   316.68   27876215   \n",
       "1256  318.66  25672211    316.85   320.89  315.8700   318.66   25672211   \n",
       "1257  315.77  20450754    318.89   319.23  315.3500   315.77   20450754   \n",
       "\n",
       "      divCash  splitFactor  \n",
       "1253      0.0          1.0  \n",
       "1254      0.0          1.0  \n",
       "1255      0.0          1.0  \n",
       "1256      0.0          1.0  \n",
       "1257      0.0          1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62023039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.reset_index()['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869bbc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       132.045\n",
       "1       131.780\n",
       "2       130.280\n",
       "3       130.535\n",
       "4       129.960\n",
       "         ...   \n",
       "1253    314.960\n",
       "1254    313.140\n",
       "1255    319.230\n",
       "1256    316.850\n",
       "1257    318.890\n",
       "Name: close, Length: 1258, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3cf8389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27f54ca8b20>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71433ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b75bab04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       132.045\n",
       "1       131.780\n",
       "2       130.280\n",
       "3       130.535\n",
       "4       129.960\n",
       "         ...   \n",
       "1253    314.960\n",
       "1254    313.140\n",
       "1255    319.230\n",
       "1256    316.850\n",
       "1257    318.890\n",
       "Name: close, Length: 1258, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6afc8fa",
   "metadata": {},
   "source": [
    "Normalising the Data..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71984105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cde804e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17607447]\n",
      " [0.17495567]\n",
      " [0.16862282]\n",
      " ...\n",
      " [0.96635143]\n",
      " [0.9563033 ]\n",
      " [0.96491598]]\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b00d27",
   "metadata": {},
   "source": [
    "Splitting the dataset into Training and Testing Data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0bb9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size=int(len(df1)*0.65)\n",
    "test_size=len(df1)-training_size\n",
    "train_data,test_data=df1[0:training_size,:1],df1[training_size:len(df1),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6f4ea7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817, 441)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size,test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "736af7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17607447],\n",
       "       [0.17495567],\n",
       "       [0.16862282],\n",
       "       [0.1696994 ],\n",
       "       [0.16727181],\n",
       "       [0.16794731],\n",
       "       [0.16473866],\n",
       "       [0.16174111],\n",
       "       [0.1581525 ],\n",
       "       [0.15654817],\n",
       "       [0.16271215],\n",
       "       [0.1614878 ],\n",
       "       [0.1554927 ],\n",
       "       [0.15443722],\n",
       "       [0.15730811],\n",
       "       [0.15604154],\n",
       "       [0.15849025],\n",
       "       [0.15308621],\n",
       "       [0.15735033],\n",
       "       [0.15490163],\n",
       "       [0.15946129],\n",
       "       [0.15688592],\n",
       "       [0.1537195 ],\n",
       "       [0.14434687],\n",
       "       [0.14812547],\n",
       "       [0.15308621],\n",
       "       [0.15241071],\n",
       "       [0.15055307],\n",
       "       [0.14924428],\n",
       "       [0.13607194],\n",
       "       [0.12551718],\n",
       "       [0.13906949],\n",
       "       [0.14911762],\n",
       "       [0.14890653],\n",
       "       [0.15401503],\n",
       "       [0.16115005],\n",
       "       [0.16583636],\n",
       "       [0.17618002],\n",
       "       [0.17060711],\n",
       "       [0.14725998],\n",
       "       [0.14700667],\n",
       "       [0.14422021],\n",
       "       [0.13691632],\n",
       "       [0.13949168],\n",
       "       [0.13784514],\n",
       "       [0.13522756],\n",
       "       [0.13071012],\n",
       "       [0.11863548],\n",
       "       [0.10259225],\n",
       "       [0.1058009 ],\n",
       "       [0.10466098],\n",
       "       [0.10630752],\n",
       "       [0.12403952],\n",
       "       [0.09773706],\n",
       "       [0.10512539],\n",
       "       [0.10474542],\n",
       "       [0.10816516],\n",
       "       [0.11323144],\n",
       "       [0.11044499],\n",
       "       [0.10415435],\n",
       "       [0.09419066],\n",
       "       [0.06510175],\n",
       "       [0.05395592],\n",
       "       [0.0565735 ],\n",
       "       [0.08169383],\n",
       "       [0.09533058],\n",
       "       [0.09689268],\n",
       "       [0.09465507],\n",
       "       [0.07337668],\n",
       "       [0.09288187],\n",
       "       [0.08456472],\n",
       "       [0.07992063],\n",
       "       [0.09275521],\n",
       "       [0.0836359 ],\n",
       "       [0.09385291],\n",
       "       [0.10077683],\n",
       "       [0.10542092],\n",
       "       [0.10951617],\n",
       "       [0.11006502],\n",
       "       [0.09955248],\n",
       "       [0.09756818],\n",
       "       [0.10499873],\n",
       "       [0.09735709],\n",
       "       [0.10124124],\n",
       "       [0.10411213],\n",
       "       [0.10288778],\n",
       "       [0.09330406],\n",
       "       [0.07903403],\n",
       "       [0.08426919],\n",
       "       [0.08122942],\n",
       "       [0.08460694],\n",
       "       [0.0862957 ],\n",
       "       [0.08853331],\n",
       "       [0.0862957 ],\n",
       "       [0.08089167],\n",
       "       [0.09195305],\n",
       "       [0.08975766],\n",
       "       [0.09055982],\n",
       "       [0.08388922],\n",
       "       [0.09085536],\n",
       "       [0.0873934 ],\n",
       "       [0.09030651],\n",
       "       [0.09891919],\n",
       "       [0.09887697],\n",
       "       [0.10622309],\n",
       "       [0.1213375 ],\n",
       "       [0.10529427],\n",
       "       [0.10221228],\n",
       "       [0.12213966],\n",
       "       [0.12745926],\n",
       "       [0.1231107 ],\n",
       "       [0.1302035 ],\n",
       "       [0.13607194],\n",
       "       [0.13366546],\n",
       "       [0.1291058 ],\n",
       "       [0.12969687],\n",
       "       [0.12762813],\n",
       "       [0.1115849 ],\n",
       "       [0.10879845],\n",
       "       [0.1071519 ],\n",
       "       [0.09288187],\n",
       "       [0.10062906],\n",
       "       [0.09858144],\n",
       "       [0.11378029],\n",
       "       [0.12007093],\n",
       "       [0.12226632],\n",
       "       [0.11572237],\n",
       "       [0.12049312],\n",
       "       [0.1169045 ],\n",
       "       [0.11597568],\n",
       "       [0.11804441],\n",
       "       [0.11399139],\n",
       "       [0.10951617],\n",
       "       [0.10495651],\n",
       "       [0.1211264 ],\n",
       "       [0.11795998],\n",
       "       [0.11774888],\n",
       "       [0.10672971],\n",
       "       [0.10905176],\n",
       "       [0.09642827],\n",
       "       [0.09347294],\n",
       "       [0.08507135],\n",
       "       [0.08865997],\n",
       "       [0.07869628],\n",
       "       [0.06624166],\n",
       "       [0.07173014],\n",
       "       [0.07130795],\n",
       "       [0.07713417],\n",
       "       [0.07468547],\n",
       "       [0.06957697],\n",
       "       [0.07768302],\n",
       "       [0.07168792],\n",
       "       [0.0629908 ],\n",
       "       [0.06337077],\n",
       "       [0.05222494],\n",
       "       [0.04373892],\n",
       "       [0.02579583],\n",
       "       [0.027949  ],\n",
       "       [0.03457739],\n",
       "       [0.04061471],\n",
       "       [0.02976442],\n",
       "       [0.03875707],\n",
       "       [0.02866672],\n",
       "       [0.02668243],\n",
       "       [0.02723128],\n",
       "       [0.02516254],\n",
       "       [0.04677869],\n",
       "       [0.03841932],\n",
       "       [0.04074137],\n",
       "       [0.01300346],\n",
       "       [0.01583214],\n",
       "       [0.02955332],\n",
       "       [0.02571139],\n",
       "       [0.01747868],\n",
       "       [0.02537364],\n",
       "       [0.02642911],\n",
       "       [0.0155366 ],\n",
       "       [0.01971629],\n",
       "       [0.01963185],\n",
       "       [0.01659208],\n",
       "       [0.01418559],\n",
       "       [0.01540995],\n",
       "       [0.02659799],\n",
       "       [0.03284641],\n",
       "       [0.02499367],\n",
       "       [0.02406485],\n",
       "       [0.02761125],\n",
       "       [0.01836528],\n",
       "       [0.02431816],\n",
       "       [0.02710462],\n",
       "       [0.0277379 ],\n",
       "       [0.02680909],\n",
       "       [0.04302119],\n",
       "       [0.04395001],\n",
       "       [0.04711644],\n",
       "       [0.05349151],\n",
       "       [0.04867854],\n",
       "       [0.04513215],\n",
       "       [0.04551212],\n",
       "       [0.04572321],\n",
       "       [0.05032509],\n",
       "       [0.05142278],\n",
       "       [0.0601199 ],\n",
       "       [0.06598835],\n",
       "       [0.06527062],\n",
       "       [0.06577725],\n",
       "       [0.06573503],\n",
       "       [0.06915477],\n",
       "       [0.06666385],\n",
       "       [0.06472178],\n",
       "       [0.06269526],\n",
       "       [0.0732078 ],\n",
       "       [0.08114498],\n",
       "       [0.0787385 ],\n",
       "       [0.0829604 ],\n",
       "       [0.08773115],\n",
       "       [0.08220046],\n",
       "       [0.08705564],\n",
       "       [0.07683864],\n",
       "       [0.07734527],\n",
       "       [0.07886515],\n",
       "       [0.08486026],\n",
       "       [0.0916153 ],\n",
       "       [0.09186861],\n",
       "       [0.08236933],\n",
       "       [0.07236342],\n",
       "       [0.06995694],\n",
       "       [0.07088576],\n",
       "       [0.06598835],\n",
       "       [0.064764  ],\n",
       "       [0.06223085],\n",
       "       [0.05914886],\n",
       "       [0.03157984],\n",
       "       [0.01895635],\n",
       "       [0.01435447],\n",
       "       [0.01393228],\n",
       "       [0.02043401],\n",
       "       [0.01625433],\n",
       "       [0.01224352],\n",
       "       [0.01004813],\n",
       "       [0.01034366],\n",
       "       [0.01300346],\n",
       "       [0.00916153],\n",
       "       [0.        ],\n",
       "       [0.00075994],\n",
       "       [0.01494554],\n",
       "       [0.013299  ],\n",
       "       [0.01781643],\n",
       "       [0.01629655],\n",
       "       [0.02060289],\n",
       "       [0.02571139],\n",
       "       [0.03191759],\n",
       "       [0.03917926],\n",
       "       [0.04251457],\n",
       "       [0.04226125],\n",
       "       [0.04019252],\n",
       "       [0.03428185],\n",
       "       [0.03115765],\n",
       "       [0.03200203],\n",
       "       [0.03499958],\n",
       "       [0.03668834],\n",
       "       [0.03630837],\n",
       "       [0.03930592],\n",
       "       [0.03584396],\n",
       "       [0.02955332],\n",
       "       [0.03005995],\n",
       "       [0.02870894],\n",
       "       [0.03043992],\n",
       "       [0.0210673 ],\n",
       "       [0.02009626],\n",
       "       [0.023516  ],\n",
       "       [0.02199612],\n",
       "       [0.02431816],\n",
       "       [0.01291902],\n",
       "       [0.00717724],\n",
       "       [0.01372119],\n",
       "       [0.01714093],\n",
       "       [0.02220721],\n",
       "       [0.02343156],\n",
       "       [0.01963185],\n",
       "       [0.02191168],\n",
       "       [0.02364266],\n",
       "       [0.02676687],\n",
       "       [0.02803344],\n",
       "       [0.02989107],\n",
       "       [0.02756903],\n",
       "       [0.03567508],\n",
       "       [0.03563286],\n",
       "       [0.04006586],\n",
       "       [0.04023474],\n",
       "       [0.04061471],\n",
       "       [0.0383771 ],\n",
       "       [0.03512623],\n",
       "       [0.02955332],\n",
       "       [0.02672465],\n",
       "       [0.0532382 ],\n",
       "       [0.05910665],\n",
       "       [0.0585578 ],\n",
       "       [0.0663261 ],\n",
       "       [0.05969771],\n",
       "       [0.0652284 ],\n",
       "       [0.06556616],\n",
       "       [0.07236342],\n",
       "       [0.07612092],\n",
       "       [0.07797855],\n",
       "       [0.07455881],\n",
       "       [0.07426328],\n",
       "       [0.07531875],\n",
       "       [0.08080723],\n",
       "       [0.08038504],\n",
       "       [0.07970953],\n",
       "       [0.07911847],\n",
       "       [0.0803006 ],\n",
       "       [0.07671198],\n",
       "       [0.07814743],\n",
       "       [0.07468547],\n",
       "       [0.07274339],\n",
       "       [0.07008359],\n",
       "       [0.06957697],\n",
       "       [0.066115  ],\n",
       "       [0.06653719],\n",
       "       [0.06919699],\n",
       "       [0.0734189 ],\n",
       "       [0.07329224],\n",
       "       [0.0760787 ],\n",
       "       [0.06408849],\n",
       "       [0.05399814],\n",
       "       [0.06375074],\n",
       "       [0.07434772],\n",
       "       [0.09047539],\n",
       "       [0.10651862],\n",
       "       [0.10377438],\n",
       "       [0.09811703],\n",
       "       [0.09807481],\n",
       "       [0.09799037],\n",
       "       [0.10250781],\n",
       "       [0.09444398],\n",
       "       [0.0951617 ],\n",
       "       [0.0960483 ],\n",
       "       [0.09967914],\n",
       "       [0.09220637],\n",
       "       [0.09587942],\n",
       "       [0.09364181],\n",
       "       [0.09566833],\n",
       "       [0.09587942],\n",
       "       [0.09942582],\n",
       "       [0.10014354],\n",
       "       [0.10854513],\n",
       "       [0.10960061],\n",
       "       [0.11399139],\n",
       "       [0.1124715 ],\n",
       "       [0.11521574],\n",
       "       [0.11487799],\n",
       "       [0.11454023],\n",
       "       [0.11306257],\n",
       "       [0.11280925],\n",
       "       [0.11086718],\n",
       "       [0.11530018],\n",
       "       [0.11783332],\n",
       "       [0.10660306],\n",
       "       [0.10191674],\n",
       "       [0.0987081 ],\n",
       "       [0.09794816],\n",
       "       [0.08929325],\n",
       "       [0.08971544],\n",
       "       [0.08228489],\n",
       "       [0.07810521],\n",
       "       [0.0847336 ],\n",
       "       [0.08747784],\n",
       "       [0.08671789],\n",
       "       [0.07367221],\n",
       "       [0.07637423],\n",
       "       [0.06489065],\n",
       "       [0.07080132],\n",
       "       [0.0829604 ],\n",
       "       [0.08279152],\n",
       "       [0.08325593],\n",
       "       [0.09030651],\n",
       "       [0.09060204],\n",
       "       [0.08819556],\n",
       "       [0.09055982],\n",
       "       [0.08963101],\n",
       "       [0.0891666 ],\n",
       "       [0.08519801],\n",
       "       [0.08084945],\n",
       "       [0.08258043],\n",
       "       [0.07924512],\n",
       "       [0.08279152],\n",
       "       [0.08735118],\n",
       "       [0.09195305],\n",
       "       [0.09967914],\n",
       "       [0.0969349 ],\n",
       "       [0.1049143 ],\n",
       "       [0.1049143 ],\n",
       "       [0.10757409],\n",
       "       [0.10820738],\n",
       "       [0.11103606],\n",
       "       [0.11234485],\n",
       "       [0.11280925],\n",
       "       [0.10955839],\n",
       "       [0.11052943],\n",
       "       [0.11365364],\n",
       "       [0.11154268],\n",
       "       [0.11141603],\n",
       "       [0.10757409],\n",
       "       [0.10896732],\n",
       "       [0.10841848],\n",
       "       [0.1109094 ],\n",
       "       [0.11639787],\n",
       "       [0.12095753],\n",
       "       [0.12146416],\n",
       "       [0.12416617],\n",
       "       [0.12205522],\n",
       "       [0.12116862],\n",
       "       [0.12522165],\n",
       "       [0.12517943],\n",
       "       [0.12429283],\n",
       "       [0.12522165],\n",
       "       [0.1255594 ],\n",
       "       [0.12509499],\n",
       "       [0.13315883],\n",
       "       [0.13341214],\n",
       "       [0.13345436],\n",
       "       [0.13210335],\n",
       "       [0.13092122],\n",
       "       [0.1621633 ],\n",
       "       [0.16123448],\n",
       "       [0.16355653],\n",
       "       [0.16866503],\n",
       "       [0.17390019],\n",
       "       [0.17605336],\n",
       "       [0.17765769],\n",
       "       [0.17639112],\n",
       "       [0.18133074],\n",
       "       [0.18863464],\n",
       "       [0.19070337],\n",
       "       [0.19000676],\n",
       "       [0.19158997],\n",
       "       [0.19572743],\n",
       "       [0.19745841],\n",
       "       [0.19500971],\n",
       "       [0.19555856],\n",
       "       [0.19669847],\n",
       "       [0.19695179],\n",
       "       [0.20877311],\n",
       "       [0.20526894],\n",
       "       [0.2087309 ],\n",
       "       [0.20687326],\n",
       "       [0.2076332 ],\n",
       "       [0.20543781],\n",
       "       [0.2040868 ],\n",
       "       [0.20602888],\n",
       "       [0.20628219],\n",
       "       [0.20539559],\n",
       "       [0.21160179],\n",
       "       [0.21257283],\n",
       "       [0.2096175 ],\n",
       "       [0.21582369],\n",
       "       [0.20898421],\n",
       "       [0.21565482],\n",
       "       [0.21354387],\n",
       "       [0.21236173],\n",
       "       [0.21337499],\n",
       "       [0.22570295],\n",
       "       [0.22705396],\n",
       "       [0.22625179],\n",
       "       [0.22511188],\n",
       "       [0.22528076],\n",
       "       [0.22979819],\n",
       "       [0.22663177],\n",
       "       [0.22511188],\n",
       "       [0.22376087],\n",
       "       [0.22304315],\n",
       "       [0.21654142],\n",
       "       [0.21725914],\n",
       "       [0.21409271],\n",
       "       [0.2173858 ],\n",
       "       [0.214726  ],\n",
       "       [0.21253061],\n",
       "       [0.21996116],\n",
       "       [0.21924343],\n",
       "       [0.22502744],\n",
       "       [0.22878494],\n",
       "       [0.22519632],\n",
       "       [0.22566073],\n",
       "       [0.22506966],\n",
       "       [0.23743984],\n",
       "       [0.24136621],\n",
       "       [0.23946635],\n",
       "       [0.23722874],\n",
       "       [0.24748797],\n",
       "       [0.26458668],\n",
       "       [0.26872414],\n",
       "       [0.26564215],\n",
       "       [0.26855526],\n",
       "       [0.27763236],\n",
       "       [0.2759436 ],\n",
       "       [0.27497256],\n",
       "       [0.25293422],\n",
       "       [0.26260238],\n",
       "       [0.26479777],\n",
       "       [0.26872414],\n",
       "       [0.26792198],\n",
       "       [0.2659799 ],\n",
       "       [0.26821751],\n",
       "       [0.26711982],\n",
       "       [0.26737313],\n",
       "       [0.2635312 ],\n",
       "       [0.2653044 ],\n",
       "       [0.27488812],\n",
       "       [0.26847083],\n",
       "       [0.27066622],\n",
       "       [0.27455037],\n",
       "       [0.27294604],\n",
       "       [0.24757241],\n",
       "       [0.23254243],\n",
       "       [0.23748206],\n",
       "       [0.23144474],\n",
       "       [0.22777168],\n",
       "       [0.21924343],\n",
       "       [0.23642658],\n",
       "       [0.23081145],\n",
       "       [0.23444229],\n",
       "       [0.23342903],\n",
       "       [0.23617327],\n",
       "       [0.23423119],\n",
       "       [0.22540741],\n",
       "       [0.23427341],\n",
       "       [0.22519632],\n",
       "       [0.22663177],\n",
       "       [0.22443638],\n",
       "       [0.2269273 ],\n",
       "       [0.22118551],\n",
       "       [0.22730727],\n",
       "       [0.23102254],\n",
       "       [0.23300684],\n",
       "       [0.23389344],\n",
       "       [0.2424639 ],\n",
       "       [0.24782572],\n",
       "       [0.25002111],\n",
       "       [0.2522165 ],\n",
       "       [0.25618509],\n",
       "       [0.25331419],\n",
       "       [0.25301866],\n",
       "       [0.26070252],\n",
       "       [0.26344676],\n",
       "       [0.26648653],\n",
       "       [0.25424301],\n",
       "       [0.2497678 ],\n",
       "       [0.24651693],\n",
       "       [0.25208984],\n",
       "       [0.28202314],\n",
       "       [0.27539475],\n",
       "       [0.27885671],\n",
       "       [0.28907371],\n",
       "       [0.29443553],\n",
       "       [0.298573  ],\n",
       "       [0.27433927],\n",
       "       [0.28345858],\n",
       "       [0.29346449],\n",
       "       [0.30085282],\n",
       "       [0.29810859],\n",
       "       [0.28506291],\n",
       "       [0.28354302],\n",
       "       [0.28231867],\n",
       "       [0.29316896],\n",
       "       [0.29401334],\n",
       "       [0.29101579],\n",
       "       [0.29350671],\n",
       "       [0.30030398],\n",
       "       [0.30638352],\n",
       "       [0.30824116],\n",
       "       [0.31098539],\n",
       "       [0.31119649],\n",
       "       [0.30287934],\n",
       "       [0.30216161],\n",
       "       [0.29941738],\n",
       "       [0.28831377],\n",
       "       [0.30043063],\n",
       "       [0.29772862],\n",
       "       [0.29262011],\n",
       "       [0.28683611],\n",
       "       [0.29359115],\n",
       "       [0.28848265],\n",
       "       [0.28873596],\n",
       "       [0.2775057 ],\n",
       "       [0.266191  ],\n",
       "       [0.25985814],\n",
       "       [0.25420079],\n",
       "       [0.26513552],\n",
       "       [0.2697374 ],\n",
       "       [0.26572659],\n",
       "       [0.26927299],\n",
       "       [0.2679642 ],\n",
       "       [0.27079287],\n",
       "       [0.26657097],\n",
       "       [0.27463481],\n",
       "       [0.27425483],\n",
       "       [0.27653466],\n",
       "       [0.27678798],\n",
       "       [0.27953221],\n",
       "       [0.27721017],\n",
       "       [0.28138985],\n",
       "       [0.29359115],\n",
       "       [0.29608207],\n",
       "       [0.29308452],\n",
       "       [0.27712573],\n",
       "       [0.27826564],\n",
       "       [0.27792789],\n",
       "       [0.28185426],\n",
       "       [0.27894115],\n",
       "       [0.28316305],\n",
       "       [0.30697458],\n",
       "       [0.32246897],\n",
       "       [0.33226378],\n",
       "       [0.32318669],\n",
       "       [0.32833741],\n",
       "       [0.34687157],\n",
       "       [0.3542599 ],\n",
       "       [0.35662417],\n",
       "       [0.36266149],\n",
       "       [0.3611416 ],\n",
       "       [0.3560331 ],\n",
       "       [0.35307777],\n",
       "       [0.34197416],\n",
       "       [0.33243266],\n",
       "       [0.34096091],\n",
       "       [0.3369501 ],\n",
       "       [0.33623237],\n",
       "       [0.34957359],\n",
       "       [0.35725745],\n",
       "       [0.35729967],\n",
       "       [0.3535844 ],\n",
       "       [0.34927805],\n",
       "       [0.33412142],\n",
       "       [0.34412733],\n",
       "       [0.34074981],\n",
       "       [0.33547243],\n",
       "       [0.33479693],\n",
       "       [0.33213713],\n",
       "       [0.33344592],\n",
       "       [0.33365701],\n",
       "       [0.34758929],\n",
       "       [0.34349405],\n",
       "       [0.34590053],\n",
       "       [0.34568944],\n",
       "       [0.35307777],\n",
       "       [0.36342143],\n",
       "       [0.35548425],\n",
       "       [0.35468209],\n",
       "       [0.35746855],\n",
       "       [0.35746855],\n",
       "       [0.3387233 ],\n",
       "       [0.33884995],\n",
       "       [0.34087647],\n",
       "       [0.33306595],\n",
       "       [0.34585831],\n",
       "       [0.34573166],\n",
       "       [0.34910918],\n",
       "       [0.35742633],\n",
       "       [0.35468209],\n",
       "       [0.35459765],\n",
       "       [0.35442878],\n",
       "       [0.35860846],\n",
       "       [0.36625011],\n",
       "       [0.36245039],\n",
       "       [0.37473613],\n",
       "       [0.37541164],\n",
       "       [0.37203411],\n",
       "       [0.36587013],\n",
       "       [0.36603901],\n",
       "       [0.35413324],\n",
       "       [0.34100312],\n",
       "       [0.34269189],\n",
       "       [0.32770413],\n",
       "       [0.32352444],\n",
       "       [0.32546652],\n",
       "       [0.32694419],\n",
       "       [0.29620873],\n",
       "       [0.2792789 ],\n",
       "       [0.30689015],\n",
       "       [0.2921557 ],\n",
       "       [0.27362155],\n",
       "       [0.27894115],\n",
       "       [0.30553914],\n",
       "       [0.31242084],\n",
       "       [0.32521321],\n",
       "       [0.3489403 ],\n",
       "       [0.34657604],\n",
       "       [0.34412733],\n",
       "       [0.34083425],\n",
       "       [0.34687157],\n",
       "       [0.35953728],\n",
       "       [0.37418728],\n",
       "       [0.37173858],\n",
       "       [0.37059867],\n",
       "       [0.35742633],\n",
       "       [0.36253483],\n",
       "       [0.36511019],\n",
       "       [0.36447691],\n",
       "       [0.35755298],\n",
       "       [0.36561682],\n",
       "       [0.37845141],\n",
       "       [0.38579752],\n",
       "       [0.37840919],\n",
       "       [0.37194967],\n",
       "       [0.37283627],\n",
       "       [0.37017648],\n",
       "       [0.3586929 ],\n",
       "       [0.35843958],\n",
       "       [0.34167863],\n",
       "       [0.33146162],\n",
       "       [0.31495398],\n",
       "       [0.34801148],\n",
       "       [0.32930845],\n",
       "       [0.32145571],\n",
       "       [0.32694419],\n",
       "       [0.32230009],\n",
       "       [0.32951955],\n",
       "       [0.34311408],\n",
       "       [0.34813814],\n",
       "       [0.32947733],\n",
       "       [0.33652791],\n",
       "       [0.350038  ],\n",
       "       [0.34661826],\n",
       "       [0.35379549],\n",
       "       [0.35628641],\n",
       "       [0.36088829],\n",
       "       [0.37110529],\n",
       "       [0.36941653],\n",
       "       [0.34813814],\n",
       "       [0.31824707],\n",
       "       [0.31622055],\n",
       "       [0.30651017],\n",
       "       [0.30950773],\n",
       "       [0.31191421],\n",
       "       [0.30389259],\n",
       "       [0.31630499],\n",
       "       [0.3325171 ],\n",
       "       [0.36405472],\n",
       "       [0.36540572],\n",
       "       [0.39470573],\n",
       "       [0.40032086],\n",
       "       [0.40407836],\n",
       "       [0.40960905],\n",
       "       [0.42092375],\n",
       "       [0.41480199],\n",
       "       [0.41294436],\n",
       "       [0.4057249 ],\n",
       "       [0.41307101],\n",
       "       [0.40804695],\n",
       "       [0.40517605],\n",
       "       [0.41074897],\n",
       "       [0.40876467],\n",
       "       [0.41383095],\n",
       "       [0.41294436],\n",
       "       [0.41475977],\n",
       "       [0.41188888],\n",
       "       [0.41020012],\n",
       "       [0.40754032],\n",
       "       [0.42176813],\n",
       "       [0.42848096],\n",
       "       [0.43472938],\n",
       "       [0.43755805],\n",
       "       [0.43536266],\n",
       "       [0.42793211],\n",
       "       [0.42594782],\n",
       "       [0.43038082],\n",
       "       [0.42371021],\n",
       "       [0.4241324 ],\n",
       "       [0.41585747],\n",
       "       [0.41543528],\n",
       "       [0.40255847],\n",
       "       [0.40597821],\n",
       "       [0.40158744],\n",
       "       [0.39930761],\n",
       "       [0.38769737],\n",
       "       [0.39723888],\n",
       "       [0.39609896],\n",
       "       [0.40175631],\n",
       "       [0.40010977],\n",
       "       [0.40884911],\n",
       "       [0.3950857 ],\n",
       "       [0.40133412],\n",
       "       [0.41218441],\n",
       "       [0.42320358],\n",
       "       [0.42223254],\n",
       "       [0.41180444],\n",
       "       [0.42510344],\n",
       "       [0.42637001],\n",
       "       [0.42459681],\n",
       "       [0.42687664],\n",
       "       [0.42244364],\n",
       "       [0.42869205],\n",
       "       [0.42683442],\n",
       "       [0.42755214],\n",
       "       [0.43342059],\n",
       "       [0.44110445],\n",
       "       [0.43852909],\n",
       "       [0.42489234],\n",
       "       [0.42037491],\n",
       "       [0.42197923],\n",
       "       [0.46930676],\n",
       "       [0.49417377],\n",
       "       [0.49670692],\n",
       "       [0.50126657],\n",
       "       [0.49299164],\n",
       "       [0.49358271],\n",
       "       [0.50046441],\n",
       "       [0.49476484],\n",
       "       [0.50042219],\n",
       "       [0.50413747],\n",
       "       [0.5062062 ],\n",
       "       [0.51920966],\n",
       "       [0.53719497],\n",
       "       [0.52824453],\n",
       "       [0.52647133]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef5af935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52651355],\n",
       "       [0.52837119],\n",
       "       [0.53119986],\n",
       "       [0.53871485],\n",
       "       [0.5461454 ],\n",
       "       [0.55999324],\n",
       "       [0.56864815],\n",
       "       [0.57962509],\n",
       "       [0.58270708],\n",
       "       [0.57641645],\n",
       "       [0.56049987],\n",
       "       [0.55290045],\n",
       "       [0.54036139],\n",
       "       [0.5636663 ],\n",
       "       [0.55192941],\n",
       "       [0.57447437],\n",
       "       [0.56362408],\n",
       "       [0.53846154],\n",
       "       [0.53998142],\n",
       "       [0.54053027],\n",
       "       [0.54753863],\n",
       "       [0.53753272],\n",
       "       [0.55074728],\n",
       "       [0.55665794],\n",
       "       [0.54918517],\n",
       "       [0.56831039],\n",
       "       [0.5716457 ],\n",
       "       [0.57806299],\n",
       "       [0.58659124],\n",
       "       [0.59837035],\n",
       "       [0.58114498],\n",
       "       [0.56552394],\n",
       "       [0.56332855],\n",
       "       [0.57641645],\n",
       "       [0.53204425],\n",
       "       [0.52398041],\n",
       "       [0.55632019],\n",
       "       [0.53626615],\n",
       "       [0.55648907],\n",
       "       [0.55243604],\n",
       "       [0.5306088 ],\n",
       "       [0.54449886],\n",
       "       [0.55015621],\n",
       "       [0.55893777],\n",
       "       [0.52668243],\n",
       "       [0.54656759],\n",
       "       [0.53179093],\n",
       "       [0.51465   ],\n",
       "       [0.51912522],\n",
       "       [0.542599  ],\n",
       "       [0.5567846 ],\n",
       "       [0.49455374],\n",
       "       [0.46968673],\n",
       "       [0.47889048],\n",
       "       [0.50498185],\n",
       "       [0.49881787],\n",
       "       [0.48184582],\n",
       "       [0.43836021],\n",
       "       [0.43016972],\n",
       "       [0.40724479],\n",
       "       [0.42670776],\n",
       "       [0.43565819],\n",
       "       [0.4032762 ],\n",
       "       [0.3657857 ],\n",
       "       [0.36494132],\n",
       "       [0.34598497],\n",
       "       [0.355822  ],\n",
       "       [0.35421768],\n",
       "       [0.38250443],\n",
       "       [0.37663599],\n",
       "       [0.37254074],\n",
       "       [0.39888542],\n",
       "       [0.36456134],\n",
       "       [0.35624419],\n",
       "       [0.32994174],\n",
       "       [0.33462805],\n",
       "       [0.3305328 ],\n",
       "       [0.3325171 ],\n",
       "       [0.34032762],\n",
       "       [0.31723381],\n",
       "       [0.31073208],\n",
       "       [0.31972473],\n",
       "       [0.29785527],\n",
       "       [0.28071435],\n",
       "       [0.25496074],\n",
       "       [0.23849531],\n",
       "       [0.28214979],\n",
       "       [0.27784345],\n",
       "       [0.2781812 ],\n",
       "       [0.28455628],\n",
       "       [0.28531622],\n",
       "       [0.21890568],\n",
       "       [0.24453264],\n",
       "       [0.24313941],\n",
       "       [0.25504517],\n",
       "       [0.26585325],\n",
       "       [0.26792198],\n",
       "       [0.26154691],\n",
       "       [0.25187875],\n",
       "       [0.26483999],\n",
       "       [0.27273495],\n",
       "       [0.2766191 ],\n",
       "       [0.28067213],\n",
       "       [0.26581103],\n",
       "       [0.26842861],\n",
       "       [0.26327789],\n",
       "       [0.28464072],\n",
       "       [0.27847674],\n",
       "       [0.27163725],\n",
       "       [0.31626277],\n",
       "       [0.32128684],\n",
       "       [0.32162459],\n",
       "       [0.34159419],\n",
       "       [0.35396437],\n",
       "       [0.35421768],\n",
       "       [0.3402854 ],\n",
       "       [0.33804779],\n",
       "       [0.33391033],\n",
       "       [0.34007431],\n",
       "       [0.33707675],\n",
       "       [0.33969433],\n",
       "       [0.33809001],\n",
       "       [0.34024318],\n",
       "       [0.34488728],\n",
       "       [0.34079203],\n",
       "       [0.34885586],\n",
       "       [0.35417546],\n",
       "       [0.35459765],\n",
       "       [0.35687748],\n",
       "       [0.34961581],\n",
       "       [0.35729967],\n",
       "       [0.36101495],\n",
       "       [0.35966394],\n",
       "       [0.35539981],\n",
       "       [0.34687157],\n",
       "       [0.34860255],\n",
       "       [0.37389175],\n",
       "       [0.38237778],\n",
       "       [0.3857553 ],\n",
       "       [0.39428354],\n",
       "       [0.40437389],\n",
       "       [0.41239551],\n",
       "       [0.40610487],\n",
       "       [0.41298657],\n",
       "       [0.44224436],\n",
       "       [0.42518787],\n",
       "       [0.41543528],\n",
       "       [0.40720257],\n",
       "       [0.41429536],\n",
       "       [0.41535084],\n",
       "       [0.42054378],\n",
       "       [0.42599004],\n",
       "       [0.43772693],\n",
       "       [0.44334206],\n",
       "       [0.44477751],\n",
       "       [0.4503082 ],\n",
       "       [0.4633961 ],\n",
       "       [0.46086296],\n",
       "       [0.46559149],\n",
       "       [0.45854091],\n",
       "       [0.45820316],\n",
       "       [0.45972304],\n",
       "       [0.45980748],\n",
       "       [0.47618847],\n",
       "       [0.47927046],\n",
       "       [0.48209913],\n",
       "       [0.49455374],\n",
       "       [0.49320274],\n",
       "       [0.48526556],\n",
       "       [0.48112809],\n",
       "       [0.48243688],\n",
       "       [0.46580258],\n",
       "       [0.50738833],\n",
       "       [0.50160432],\n",
       "       [0.51258127],\n",
       "       [0.49877565],\n",
       "       [0.47504855],\n",
       "       [0.47521743],\n",
       "       [0.46601368],\n",
       "       [0.45106814],\n",
       "       [0.40268513],\n",
       "       [0.41509753],\n",
       "       [0.42463903],\n",
       "       [0.42109263],\n",
       "       [0.41653297],\n",
       "       [0.39158152],\n",
       "       [0.40640041],\n",
       "       [0.39027273],\n",
       "       [0.3771004 ],\n",
       "       [0.37418728],\n",
       "       [0.37106308],\n",
       "       [0.36747446],\n",
       "       [0.37135861],\n",
       "       [0.35772186],\n",
       "       [0.35024909],\n",
       "       [0.37701596],\n",
       "       [0.38925948],\n",
       "       [0.40057418],\n",
       "       [0.42138816],\n",
       "       [0.43164739],\n",
       "       [0.44106223],\n",
       "       [0.43844465],\n",
       "       [0.43827577],\n",
       "       [0.43232289],\n",
       "       [0.43717808],\n",
       "       [0.45642996],\n",
       "       [0.45398125],\n",
       "       [0.46069408],\n",
       "       [0.45782319],\n",
       "       [0.45697881],\n",
       "       [0.44427088],\n",
       "       [0.46212953],\n",
       "       [0.46187621],\n",
       "       [0.45419235],\n",
       "       [0.46951786],\n",
       "       [0.4744997 ],\n",
       "       [0.4815925 ],\n",
       "       [0.48083256],\n",
       "       [0.46305835],\n",
       "       [0.46820907],\n",
       "       [0.47661066],\n",
       "       [0.47036224],\n",
       "       [0.47690619],\n",
       "       [0.48497002],\n",
       "       [0.48197247],\n",
       "       [0.47711728],\n",
       "       [0.48686988],\n",
       "       [0.47390864],\n",
       "       [0.49345605],\n",
       "       [0.50029553],\n",
       "       [0.49957781],\n",
       "       [0.49261167],\n",
       "       [0.49565144],\n",
       "       [0.50384193],\n",
       "       [0.50004222],\n",
       "       [0.51802753],\n",
       "       [0.49856455],\n",
       "       [0.47994596],\n",
       "       [0.43485603],\n",
       "       [0.4503082 ],\n",
       "       [0.45892088],\n",
       "       [0.47745504],\n",
       "       [0.46715359],\n",
       "       [0.46500042],\n",
       "       [0.50084438],\n",
       "       [0.47458414],\n",
       "       [0.47032002],\n",
       "       [0.49041628],\n",
       "       [0.50667061],\n",
       "       [0.50671283],\n",
       "       [0.51633877],\n",
       "       [0.51557882],\n",
       "       [0.47411973],\n",
       "       [0.49037406],\n",
       "       [0.48053703],\n",
       "       [0.48632103],\n",
       "       [0.50101326],\n",
       "       [0.49987334],\n",
       "       [0.48703876],\n",
       "       [0.5017732 ],\n",
       "       [0.51904078],\n",
       "       [0.51895635],\n",
       "       [0.52279828],\n",
       "       [0.53347969],\n",
       "       [0.56256861],\n",
       "       [0.56043654],\n",
       "       [0.54213459],\n",
       "       [0.54698978],\n",
       "       [0.55036731],\n",
       "       [0.55910665],\n",
       "       [0.551465  ],\n",
       "       [0.53782825],\n",
       "       [0.54200794],\n",
       "       [0.53761716],\n",
       "       [0.55176053],\n",
       "       [0.54694756],\n",
       "       [0.54243013],\n",
       "       [0.56417293],\n",
       "       [0.56679051],\n",
       "       [0.54302119],\n",
       "       [0.55087393],\n",
       "       [0.57700751],\n",
       "       [0.57721861],\n",
       "       [0.56598835],\n",
       "       [0.57709195],\n",
       "       [0.59001098],\n",
       "       [0.61584902],\n",
       "       [0.61441358],\n",
       "       [0.61209153],\n",
       "       [0.60808072],\n",
       "       [0.61192265],\n",
       "       [0.61669341],\n",
       "       [0.63400321],\n",
       "       [0.63168116],\n",
       "       [0.64527569],\n",
       "       [0.64696445],\n",
       "       [0.65963016],\n",
       "       [0.67005826],\n",
       "       [0.6457401 ],\n",
       "       [0.64561344],\n",
       "       [0.66883391],\n",
       "       [0.69864055],\n",
       "       [0.70573334],\n",
       "       [0.70417124],\n",
       "       [0.70463565],\n",
       "       [0.71388162],\n",
       "       [0.71687917],\n",
       "       [0.72557629],\n",
       "       [0.72456303],\n",
       "       [0.73516001],\n",
       "       [0.72743393],\n",
       "       [0.74060627],\n",
       "       [0.74626362],\n",
       "       [0.74284387],\n",
       "       [0.72975597],\n",
       "       [0.72477413],\n",
       "       [0.72380309],\n",
       "       [0.74318163],\n",
       "       [0.73440007],\n",
       "       [0.74938782],\n",
       "       [0.7468969 ],\n",
       "       [0.73385122],\n",
       "       [0.71396606],\n",
       "       [0.72363421],\n",
       "       [0.73984632],\n",
       "       [0.76150469],\n",
       "       [0.74550367],\n",
       "       [0.75208984],\n",
       "       [0.761758  ],\n",
       "       [0.76467111],\n",
       "       [0.78024994],\n",
       "       [0.8001351 ],\n",
       "       [0.80245715],\n",
       "       [0.79962847],\n",
       "       [0.80081061],\n",
       "       [0.7983619 ],\n",
       "       [0.81761378],\n",
       "       [0.81875369],\n",
       "       [0.84256523],\n",
       "       [0.84210082],\n",
       "       [0.84936249],\n",
       "       [0.85835515],\n",
       "       [0.8866419 ],\n",
       "       [0.87431394],\n",
       "       [0.88431985],\n",
       "       [0.87836697],\n",
       "       [0.8986321 ],\n",
       "       [0.92582116],\n",
       "       [0.92877649],\n",
       "       [0.95676771],\n",
       "       [0.93869797],\n",
       "       [0.93304061],\n",
       "       [0.94950604],\n",
       "       [0.96424048],\n",
       "       [0.95512117],\n",
       "       [0.95989192],\n",
       "       [0.96635143],\n",
       "       [0.96246728],\n",
       "       [0.92295027],\n",
       "       [0.9598497 ],\n",
       "       [0.98792536],\n",
       "       [0.98594106],\n",
       "       [0.92531453],\n",
       "       [0.92172591],\n",
       "       [0.96474711],\n",
       "       [0.97572406],\n",
       "       [0.99159841],\n",
       "       [0.96972895],\n",
       "       [0.97614625],\n",
       "       [0.96795575],\n",
       "       [1.        ],\n",
       "       [0.99016297],\n",
       "       [0.99050072],\n",
       "       [0.96538039],\n",
       "       [0.98488559],\n",
       "       [0.97086887],\n",
       "       [0.94026007],\n",
       "       [0.87748037],\n",
       "       [0.83483915],\n",
       "       [0.85413324],\n",
       "       [0.77336823],\n",
       "       [0.77269273],\n",
       "       [0.88014017],\n",
       "       [0.84007431],\n",
       "       [0.89673225],\n",
       "       [0.85527316],\n",
       "       [0.83884995],\n",
       "       [0.74233725],\n",
       "       [0.82327113],\n",
       "       [0.78143207],\n",
       "       [0.6665963 ],\n",
       "       [0.7921557 ],\n",
       "       [0.64118044],\n",
       "       [0.68614371],\n",
       "       [0.66001013],\n",
       "       [0.65203074],\n",
       "       [0.58642236],\n",
       "       [0.56586169],\n",
       "       [0.66089673],\n",
       "       [0.65515494],\n",
       "       [0.70970193],\n",
       "       [0.66452757],\n",
       "       [0.69437642],\n",
       "       [0.69218104],\n",
       "       [0.63569197],\n",
       "       [0.65266402],\n",
       "       [0.63780292],\n",
       "       [0.7267162 ],\n",
       "       [0.71388162],\n",
       "       [0.74191506],\n",
       "       [0.75002111],\n",
       "       [0.77222832],\n",
       "       [0.83049059],\n",
       "       [0.8194292 ],\n",
       "       [0.8289707 ],\n",
       "       [0.8125475 ],\n",
       "       [0.78776492],\n",
       "       [0.75162543],\n",
       "       [0.78426074],\n",
       "       [0.77974331],\n",
       "       [0.81326522],\n",
       "       [0.8141096 ],\n",
       "       [0.79473106],\n",
       "       [0.83336148],\n",
       "       [0.85898843],\n",
       "       [0.83901883],\n",
       "       [0.85628641],\n",
       "       [0.87486279],\n",
       "       [0.88782403],\n",
       "       [0.90095415],\n",
       "       [0.92793211],\n",
       "       [0.948535  ],\n",
       "       [0.93333615],\n",
       "       [0.91746179],\n",
       "       [0.92544119],\n",
       "       [0.91771511],\n",
       "       [0.9483239 ],\n",
       "       [0.94064004],\n",
       "       [0.96635143],\n",
       "       [0.9563033 ],\n",
       "       [0.96491598]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc097b",
   "metadata": {},
   "source": [
    "Creating Dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "324bd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63277932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "time_step = 100\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, ytest = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9e1ae89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17607447, 0.17495567, 0.16862282, ..., 0.09055982, 0.08388922,\n",
       "        0.09085536],\n",
       "       [0.17495567, 0.16862282, 0.1696994 , ..., 0.08388922, 0.09085536,\n",
       "        0.0873934 ],\n",
       "       [0.16862282, 0.1696994 , 0.16727181, ..., 0.09085536, 0.0873934 ,\n",
       "        0.09030651],\n",
       "       ...,\n",
       "       [0.34801148, 0.32930845, 0.32145571, ..., 0.50042219, 0.50413747,\n",
       "        0.5062062 ],\n",
       "       [0.32930845, 0.32145571, 0.32694419, ..., 0.50413747, 0.5062062 ,\n",
       "        0.51920966],\n",
       "       [0.32145571, 0.32694419, 0.32230009, ..., 0.5062062 , 0.51920966,\n",
       "        0.53719497]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b038dda1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0873934 , 0.09030651, 0.09891919, 0.09887697, 0.10622309,\n",
       "       0.1213375 , 0.10529427, 0.10221228, 0.12213966, 0.12745926,\n",
       "       0.1231107 , 0.1302035 , 0.13607194, 0.13366546, 0.1291058 ,\n",
       "       0.12969687, 0.12762813, 0.1115849 , 0.10879845, 0.1071519 ,\n",
       "       0.09288187, 0.10062906, 0.09858144, 0.11378029, 0.12007093,\n",
       "       0.12226632, 0.11572237, 0.12049312, 0.1169045 , 0.11597568,\n",
       "       0.11804441, 0.11399139, 0.10951617, 0.10495651, 0.1211264 ,\n",
       "       0.11795998, 0.11774888, 0.10672971, 0.10905176, 0.09642827,\n",
       "       0.09347294, 0.08507135, 0.08865997, 0.07869628, 0.06624166,\n",
       "       0.07173014, 0.07130795, 0.07713417, 0.07468547, 0.06957697,\n",
       "       0.07768302, 0.07168792, 0.0629908 , 0.06337077, 0.05222494,\n",
       "       0.04373892, 0.02579583, 0.027949  , 0.03457739, 0.04061471,\n",
       "       0.02976442, 0.03875707, 0.02866672, 0.02668243, 0.02723128,\n",
       "       0.02516254, 0.04677869, 0.03841932, 0.04074137, 0.01300346,\n",
       "       0.01583214, 0.02955332, 0.02571139, 0.01747868, 0.02537364,\n",
       "       0.02642911, 0.0155366 , 0.01971629, 0.01963185, 0.01659208,\n",
       "       0.01418559, 0.01540995, 0.02659799, 0.03284641, 0.02499367,\n",
       "       0.02406485, 0.02761125, 0.01836528, 0.02431816, 0.02710462,\n",
       "       0.0277379 , 0.02680909, 0.04302119, 0.04395001, 0.04711644,\n",
       "       0.05349151, 0.04867854, 0.04513215, 0.04551212, 0.04572321,\n",
       "       0.05032509, 0.05142278, 0.0601199 , 0.06598835, 0.06527062,\n",
       "       0.06577725, 0.06573503, 0.06915477, 0.06666385, 0.06472178,\n",
       "       0.06269526, 0.0732078 , 0.08114498, 0.0787385 , 0.0829604 ,\n",
       "       0.08773115, 0.08220046, 0.08705564, 0.07683864, 0.07734527,\n",
       "       0.07886515, 0.08486026, 0.0916153 , 0.09186861, 0.08236933,\n",
       "       0.07236342, 0.06995694, 0.07088576, 0.06598835, 0.064764  ,\n",
       "       0.06223085, 0.05914886, 0.03157984, 0.01895635, 0.01435447,\n",
       "       0.01393228, 0.02043401, 0.01625433, 0.01224352, 0.01004813,\n",
       "       0.01034366, 0.01300346, 0.00916153, 0.        , 0.00075994,\n",
       "       0.01494554, 0.013299  , 0.01781643, 0.01629655, 0.02060289,\n",
       "       0.02571139, 0.03191759, 0.03917926, 0.04251457, 0.04226125,\n",
       "       0.04019252, 0.03428185, 0.03115765, 0.03200203, 0.03499958,\n",
       "       0.03668834, 0.03630837, 0.03930592, 0.03584396, 0.02955332,\n",
       "       0.03005995, 0.02870894, 0.03043992, 0.0210673 , 0.02009626,\n",
       "       0.023516  , 0.02199612, 0.02431816, 0.01291902, 0.00717724,\n",
       "       0.01372119, 0.01714093, 0.02220721, 0.02343156, 0.01963185,\n",
       "       0.02191168, 0.02364266, 0.02676687, 0.02803344, 0.02989107,\n",
       "       0.02756903, 0.03567508, 0.03563286, 0.04006586, 0.04023474,\n",
       "       0.04061471, 0.0383771 , 0.03512623, 0.02955332, 0.02672465,\n",
       "       0.0532382 , 0.05910665, 0.0585578 , 0.0663261 , 0.05969771,\n",
       "       0.0652284 , 0.06556616, 0.07236342, 0.07612092, 0.07797855,\n",
       "       0.07455881, 0.07426328, 0.07531875, 0.08080723, 0.08038504,\n",
       "       0.07970953, 0.07911847, 0.0803006 , 0.07671198, 0.07814743,\n",
       "       0.07468547, 0.07274339, 0.07008359, 0.06957697, 0.066115  ,\n",
       "       0.06653719, 0.06919699, 0.0734189 , 0.07329224, 0.0760787 ,\n",
       "       0.06408849, 0.05399814, 0.06375074, 0.07434772, 0.09047539,\n",
       "       0.10651862, 0.10377438, 0.09811703, 0.09807481, 0.09799037,\n",
       "       0.10250781, 0.09444398, 0.0951617 , 0.0960483 , 0.09967914,\n",
       "       0.09220637, 0.09587942, 0.09364181, 0.09566833, 0.09587942,\n",
       "       0.09942582, 0.10014354, 0.10854513, 0.10960061, 0.11399139,\n",
       "       0.1124715 , 0.11521574, 0.11487799, 0.11454023, 0.11306257,\n",
       "       0.11280925, 0.11086718, 0.11530018, 0.11783332, 0.10660306,\n",
       "       0.10191674, 0.0987081 , 0.09794816, 0.08929325, 0.08971544,\n",
       "       0.08228489, 0.07810521, 0.0847336 , 0.08747784, 0.08671789,\n",
       "       0.07367221, 0.07637423, 0.06489065, 0.07080132, 0.0829604 ,\n",
       "       0.08279152, 0.08325593, 0.09030651, 0.09060204, 0.08819556,\n",
       "       0.09055982, 0.08963101, 0.0891666 , 0.08519801, 0.08084945,\n",
       "       0.08258043, 0.07924512, 0.08279152, 0.08735118, 0.09195305,\n",
       "       0.09967914, 0.0969349 , 0.1049143 , 0.1049143 , 0.10757409,\n",
       "       0.10820738, 0.11103606, 0.11234485, 0.11280925, 0.10955839,\n",
       "       0.11052943, 0.11365364, 0.11154268, 0.11141603, 0.10757409,\n",
       "       0.10896732, 0.10841848, 0.1109094 , 0.11639787, 0.12095753,\n",
       "       0.12146416, 0.12416617, 0.12205522, 0.12116862, 0.12522165,\n",
       "       0.12517943, 0.12429283, 0.12522165, 0.1255594 , 0.12509499,\n",
       "       0.13315883, 0.13341214, 0.13345436, 0.13210335, 0.13092122,\n",
       "       0.1621633 , 0.16123448, 0.16355653, 0.16866503, 0.17390019,\n",
       "       0.17605336, 0.17765769, 0.17639112, 0.18133074, 0.18863464,\n",
       "       0.19070337, 0.19000676, 0.19158997, 0.19572743, 0.19745841,\n",
       "       0.19500971, 0.19555856, 0.19669847, 0.19695179, 0.20877311,\n",
       "       0.20526894, 0.2087309 , 0.20687326, 0.2076332 , 0.20543781,\n",
       "       0.2040868 , 0.20602888, 0.20628219, 0.20539559, 0.21160179,\n",
       "       0.21257283, 0.2096175 , 0.21582369, 0.20898421, 0.21565482,\n",
       "       0.21354387, 0.21236173, 0.21337499, 0.22570295, 0.22705396,\n",
       "       0.22625179, 0.22511188, 0.22528076, 0.22979819, 0.22663177,\n",
       "       0.22511188, 0.22376087, 0.22304315, 0.21654142, 0.21725914,\n",
       "       0.21409271, 0.2173858 , 0.214726  , 0.21253061, 0.21996116,\n",
       "       0.21924343, 0.22502744, 0.22878494, 0.22519632, 0.22566073,\n",
       "       0.22506966, 0.23743984, 0.24136621, 0.23946635, 0.23722874,\n",
       "       0.24748797, 0.26458668, 0.26872414, 0.26564215, 0.26855526,\n",
       "       0.27763236, 0.2759436 , 0.27497256, 0.25293422, 0.26260238,\n",
       "       0.26479777, 0.26872414, 0.26792198, 0.2659799 , 0.26821751,\n",
       "       0.26711982, 0.26737313, 0.2635312 , 0.2653044 , 0.27488812,\n",
       "       0.26847083, 0.27066622, 0.27455037, 0.27294604, 0.24757241,\n",
       "       0.23254243, 0.23748206, 0.23144474, 0.22777168, 0.21924343,\n",
       "       0.23642658, 0.23081145, 0.23444229, 0.23342903, 0.23617327,\n",
       "       0.23423119, 0.22540741, 0.23427341, 0.22519632, 0.22663177,\n",
       "       0.22443638, 0.2269273 , 0.22118551, 0.22730727, 0.23102254,\n",
       "       0.23300684, 0.23389344, 0.2424639 , 0.24782572, 0.25002111,\n",
       "       0.2522165 , 0.25618509, 0.25331419, 0.25301866, 0.26070252,\n",
       "       0.26344676, 0.26648653, 0.25424301, 0.2497678 , 0.24651693,\n",
       "       0.25208984, 0.28202314, 0.27539475, 0.27885671, 0.28907371,\n",
       "       0.29443553, 0.298573  , 0.27433927, 0.28345858, 0.29346449,\n",
       "       0.30085282, 0.29810859, 0.28506291, 0.28354302, 0.28231867,\n",
       "       0.29316896, 0.29401334, 0.29101579, 0.29350671, 0.30030398,\n",
       "       0.30638352, 0.30824116, 0.31098539, 0.31119649, 0.30287934,\n",
       "       0.30216161, 0.29941738, 0.28831377, 0.30043063, 0.29772862,\n",
       "       0.29262011, 0.28683611, 0.29359115, 0.28848265, 0.28873596,\n",
       "       0.2775057 , 0.266191  , 0.25985814, 0.25420079, 0.26513552,\n",
       "       0.2697374 , 0.26572659, 0.26927299, 0.2679642 , 0.27079287,\n",
       "       0.26657097, 0.27463481, 0.27425483, 0.27653466, 0.27678798,\n",
       "       0.27953221, 0.27721017, 0.28138985, 0.29359115, 0.29608207,\n",
       "       0.29308452, 0.27712573, 0.27826564, 0.27792789, 0.28185426,\n",
       "       0.27894115, 0.28316305, 0.30697458, 0.32246897, 0.33226378,\n",
       "       0.32318669, 0.32833741, 0.34687157, 0.3542599 , 0.35662417,\n",
       "       0.36266149, 0.3611416 , 0.3560331 , 0.35307777, 0.34197416,\n",
       "       0.33243266, 0.34096091, 0.3369501 , 0.33623237, 0.34957359,\n",
       "       0.35725745, 0.35729967, 0.3535844 , 0.34927805, 0.33412142,\n",
       "       0.34412733, 0.34074981, 0.33547243, 0.33479693, 0.33213713,\n",
       "       0.33344592, 0.33365701, 0.34758929, 0.34349405, 0.34590053,\n",
       "       0.34568944, 0.35307777, 0.36342143, 0.35548425, 0.35468209,\n",
       "       0.35746855, 0.35746855, 0.3387233 , 0.33884995, 0.34087647,\n",
       "       0.33306595, 0.34585831, 0.34573166, 0.34910918, 0.35742633,\n",
       "       0.35468209, 0.35459765, 0.35442878, 0.35860846, 0.36625011,\n",
       "       0.36245039, 0.37473613, 0.37541164, 0.37203411, 0.36587013,\n",
       "       0.36603901, 0.35413324, 0.34100312, 0.34269189, 0.32770413,\n",
       "       0.32352444, 0.32546652, 0.32694419, 0.29620873, 0.2792789 ,\n",
       "       0.30689015, 0.2921557 , 0.27362155, 0.27894115, 0.30553914,\n",
       "       0.31242084, 0.32521321, 0.3489403 , 0.34657604, 0.34412733,\n",
       "       0.34083425, 0.34687157, 0.35953728, 0.37418728, 0.37173858,\n",
       "       0.37059867, 0.35742633, 0.36253483, 0.36511019, 0.36447691,\n",
       "       0.35755298, 0.36561682, 0.37845141, 0.38579752, 0.37840919,\n",
       "       0.37194967, 0.37283627, 0.37017648, 0.3586929 , 0.35843958,\n",
       "       0.34167863, 0.33146162, 0.31495398, 0.34801148, 0.32930845,\n",
       "       0.32145571, 0.32694419, 0.32230009, 0.32951955, 0.34311408,\n",
       "       0.34813814, 0.32947733, 0.33652791, 0.350038  , 0.34661826,\n",
       "       0.35379549, 0.35628641, 0.36088829, 0.37110529, 0.36941653,\n",
       "       0.34813814, 0.31824707, 0.31622055, 0.30651017, 0.30950773,\n",
       "       0.31191421, 0.30389259, 0.31630499, 0.3325171 , 0.36405472,\n",
       "       0.36540572, 0.39470573, 0.40032086, 0.40407836, 0.40960905,\n",
       "       0.42092375, 0.41480199, 0.41294436, 0.4057249 , 0.41307101,\n",
       "       0.40804695, 0.40517605, 0.41074897, 0.40876467, 0.41383095,\n",
       "       0.41294436, 0.41475977, 0.41188888, 0.41020012, 0.40754032,\n",
       "       0.42176813, 0.42848096, 0.43472938, 0.43755805, 0.43536266,\n",
       "       0.42793211, 0.42594782, 0.43038082, 0.42371021, 0.4241324 ,\n",
       "       0.41585747, 0.41543528, 0.40255847, 0.40597821, 0.40158744,\n",
       "       0.39930761, 0.38769737, 0.39723888, 0.39609896, 0.40175631,\n",
       "       0.40010977, 0.40884911, 0.3950857 , 0.40133412, 0.41218441,\n",
       "       0.42320358, 0.42223254, 0.41180444, 0.42510344, 0.42637001,\n",
       "       0.42459681, 0.42687664, 0.42244364, 0.42869205, 0.42683442,\n",
       "       0.42755214, 0.43342059, 0.44110445, 0.43852909, 0.42489234,\n",
       "       0.42037491, 0.42197923, 0.46930676, 0.49417377, 0.49670692,\n",
       "       0.50126657, 0.49299164, 0.49358271, 0.50046441, 0.49476484,\n",
       "       0.50042219, 0.50413747, 0.5062062 , 0.51920966, 0.53719497,\n",
       "       0.52824453])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db35e44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(716, 100)\n",
      "(716,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape), print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "354be9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(340, 100)\n",
      "(340,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape), print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea789cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02a7a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0660046",
   "metadata": {},
   "source": [
    "Models for Stock Prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a2d2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "def bidirectional_model(learn_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(32),input_shape=(100,1)))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = RMSprop(lr=learn_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "def stacked_model(learn_rate):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32,return_sequences=True,input_shape=(100,1)))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = RMSprop(lr=learn_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c54cad",
   "metadata": {},
   "source": [
    "Pushing models in the 'models 'array... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba21ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models =[]\n",
    "\n",
    "models.append((\"Bidirectional\",bidirectional_model))\n",
    "models.append((\"Stacked\",stacked_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d428ca",
   "metadata": {},
   "source": [
    "Choosing the Best Model with most appropriate Learning Rate...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6fe7e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 64)               8704      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,769\n",
      "Trainable params: 8,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aviral\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 88ms/step - loss: 0.0508 - val_loss: 0.0302\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0030 - val_loss: 0.0104\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0026 - val_loss: 0.0135\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.0077\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.0078\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0029 - val_loss: 0.0076\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0032 - val_loss: 0.0233\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0019 - val_loss: 0.0387\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0015 - val_loss: 0.0155\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0024 - val_loss: 0.0292\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0014 - val_loss: 0.0098\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0024 - val_loss: 0.0178\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 6.3437e-04 - val_loss: 0.0082\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0016 - val_loss: 0.0092\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0011 - val_loss: 0.0115\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0010 - val_loss: 0.0073\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 0.0018 - val_loss: 0.0091\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 4.9074e-04 - val_loss: 0.0247\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 8.8491e-04 - val_loss: 0.0176\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.0012 - val_loss: 0.0060\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 8.9065e-04 - val_loss: 0.0217\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 8.0615e-04 - val_loss: 0.0103\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 8.2353e-04 - val_loss: 0.0157\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 7.5159e-04 - val_loss: 0.0237\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 8.5096e-04 - val_loss: 0.0040\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 7.4771e-04 - val_loss: 0.0026\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 9.7544e-04 - val_loss: 0.0119\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 4.5371e-04 - val_loss: 0.0110\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 7.8112e-04 - val_loss: 0.0078\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 6.2899e-04 - val_loss: 0.0125\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 4.6572e-04 - val_loss: 0.0054\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 7.7208e-04 - val_loss: 0.0073\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 4.7956e-04 - val_loss: 0.0041\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 7.6294e-04 - val_loss: 0.0099\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 4.5743e-04 - val_loss: 0.0023\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 6.4608e-04 - val_loss: 0.0085\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 6.1717e-04 - val_loss: 0.0022\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 4.9755e-04 - val_loss: 0.0046\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 4.3562e-04 - val_loss: 0.0058\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 6.6131e-04 - val_loss: 0.0044\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.4230e-04 - val_loss: 0.0086\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 7.1711e-04 - val_loss: 0.0019\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.9735e-04 - val_loss: 0.0078\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 3.5956e-04 - val_loss: 0.0035\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 6.4368e-04 - val_loss: 7.0991e-04\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.8506e-04 - val_loss: 0.0010\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.2987e-04 - val_loss: 0.0010\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 5.5626e-04 - val_loss: 0.0011\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.4576e-04 - val_loss: 0.0019\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 4.2258e-04 - val_loss: 0.0010\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.9070e-04 - val_loss: 0.0027\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 4.0650e-04 - val_loss: 0.0015\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 5.9357e-04 - val_loss: 9.6191e-04\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.7926e-04 - val_loss: 9.6479e-04\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.0998e-04 - val_loss: 0.0051\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 4.4006e-04 - val_loss: 0.0041\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.6716e-04 - val_loss: 0.0085\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 4.7535e-04 - val_loss: 0.0010\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 4.2395e-04 - val_loss: 8.6422e-04\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.0835e-04 - val_loss: 0.0012\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 4.0900e-04 - val_loss: 8.9812e-04\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.1496e-04 - val_loss: 0.0012\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.8215e-04 - val_loss: 8.7969e-04\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.0735e-04 - val_loss: 9.4655e-04\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.8539e-04 - val_loss: 9.0380e-04\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.5462e-04 - val_loss: 0.0043\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.9091e-04 - val_loss: 0.0014\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 4.2542e-04 - val_loss: 0.0011\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.9915e-04 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.3765e-04 - val_loss: 0.0047\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.7227e-04 - val_loss: 9.2152e-04\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.0675e-04 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.8998e-04 - val_loss: 0.0011\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.0101e-04 - val_loss: 0.0039\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.2455e-04 - val_loss: 0.0010\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 4.5513e-04 - val_loss: 0.0016\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.8466e-04 - val_loss: 8.8935e-04\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.9134e-04 - val_loss: 9.0324e-04\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.8857e-04 - val_loss: 0.0026\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.3504e-04 - val_loss: 9.6742e-04\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.7838e-04 - val_loss: 0.0013\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.8732e-04 - val_loss: 9.7256e-04\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.0275e-04 - val_loss: 0.0040\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.9591e-04 - val_loss: 0.0011\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.4986e-04 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.0789e-04 - val_loss: 0.0026\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.7871e-04 - val_loss: 0.0016\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.6951e-04 - val_loss: 0.0011\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.5524e-04 - val_loss: 0.0043\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.5258e-04 - val_loss: 0.0021\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 3.1528e-04 - val_loss: 0.0014\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 2.8879e-04 - val_loss: 0.0032\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.7227e-04 - val_loss: 0.0010\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.0623e-04 - val_loss: 7.8824e-04\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.5937e-04 - val_loss: 0.0012\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.8458e-04 - val_loss: 8.0529e-04\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.4141e-04 - val_loss: 7.9472e-04\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.8702e-04 - val_loss: 0.0030\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.1249e-04 - val_loss: 0.0011\n",
      "23/23 [==============================] - 1s 7ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_1 (Bidirectio  (None, 64)               8704      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,769\n",
      "Trainable params: 8,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aviral\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 3s 85ms/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0011 - val_loss: 0.0067\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0010 - val_loss: 0.0164\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 9.6882e-04 - val_loss: 0.0036\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 7.9954e-04 - val_loss: 0.0031\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 8.7499e-04 - val_loss: 0.0029\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.5303e-04 - val_loss: 0.0045\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 6.2660e-04 - val_loss: 0.0020\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.6531e-04 - val_loss: 0.0021\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.4814e-04 - val_loss: 0.0021\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 5.7551e-04 - val_loss: 0.0037\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 3.9953e-04 - val_loss: 0.0029\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 5.1928e-04 - val_loss: 0.0031\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 4.1243e-04 - val_loss: 0.0044\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 3.9246e-04 - val_loss: 0.0032\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 4.6353e-04 - val_loss: 0.0012\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 4.1489e-04 - val_loss: 0.0012\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.5378e-04 - val_loss: 0.0013\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.9133e-04 - val_loss: 0.0012\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 3.7842e-04 - val_loss: 0.0013\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.5816e-04 - val_loss: 0.0065\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.5128e-04 - val_loss: 0.0013\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.2154e-04 - val_loss: 0.0011\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.4485e-04 - val_loss: 0.0028\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.1225e-04 - val_loss: 0.0028\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.2502e-04 - val_loss: 0.0055\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.4436e-04 - val_loss: 0.0018\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.6120e-04 - val_loss: 0.0017\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.1555e-04 - val_loss: 0.0012\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.1999e-04 - val_loss: 0.0025\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.9757e-04 - val_loss: 0.0010\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.7902e-04 - val_loss: 0.0050\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.6127e-04 - val_loss: 0.0041\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.2952e-04 - val_loss: 0.0019\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.1093e-04 - val_loss: 0.0012\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.2870e-04 - val_loss: 0.0034\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.2833e-04 - val_loss: 0.0040\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.3571e-04 - val_loss: 0.0011\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.3404e-04 - val_loss: 0.0010\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.0933e-04 - val_loss: 0.0014\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 2.4608e-04 - val_loss: 0.0021\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.1960e-04 - val_loss: 0.0011\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.9498e-04 - val_loss: 0.0018\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.3571e-04 - val_loss: 9.0401e-04\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.6266e-04 - val_loss: 0.0011\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.9962e-04 - val_loss: 0.0021\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.4743e-04 - val_loss: 0.0041\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.1430e-04 - val_loss: 0.0010\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.2855e-04 - val_loss: 9.8096e-04\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.5929e-04 - val_loss: 9.7523e-04\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.0218e-04 - val_loss: 0.0015\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.2986e-04 - val_loss: 8.5555e-04\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.6515e-04 - val_loss: 0.0018\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.8816e-04 - val_loss: 0.0013\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.3219e-04 - val_loss: 0.0015\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.2272e-04 - val_loss: 9.6492e-04\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.8111e-04 - val_loss: 9.1802e-04\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.4845e-04 - val_loss: 0.0013\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.0968e-04 - val_loss: 9.0352e-04\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.5254e-04 - val_loss: 8.6525e-04\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.8799e-04 - val_loss: 9.0881e-04\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.5270e-04 - val_loss: 0.0015\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.7415e-04 - val_loss: 0.0013\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.4884e-04 - val_loss: 0.0011\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.8020e-04 - val_loss: 9.4222e-04\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.2822e-04 - val_loss: 7.2623e-04\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.9047e-04 - val_loss: 7.8281e-04\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.6873e-04 - val_loss: 0.0019\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.7260e-04 - val_loss: 9.6336e-04\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.2282e-04 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.6939e-04 - val_loss: 0.0018\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.4335e-04 - val_loss: 0.0017\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.5708e-04 - val_loss: 0.0018\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.2274e-04 - val_loss: 7.6238e-04\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.6119e-04 - val_loss: 7.8973e-04\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.7199e-04 - val_loss: 0.0010\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.2356e-04 - val_loss: 9.5253e-04\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.5829e-04 - val_loss: 0.0025\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.3627e-04 - val_loss: 0.0010\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.5637e-04 - val_loss: 0.0015\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.2134e-04 - val_loss: 6.9797e-04\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.8049e-04 - val_loss: 0.0024\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.3339e-04 - val_loss: 7.5065e-04\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.2863e-04 - val_loss: 0.0011\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.6846e-04 - val_loss: 0.0012\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1044e-04 - val_loss: 7.4212e-04\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.5832e-04 - val_loss: 8.4068e-04\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.3095e-04 - val_loss: 7.3414e-04\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.2737e-04 - val_loss: 9.1769e-04\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.6247e-04 - val_loss: 0.0011\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.3228e-04 - val_loss: 0.0013\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.0909e-04 - val_loss: 7.7552e-04\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.3835e-04 - val_loss: 0.0011\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.3203e-04 - val_loss: 7.9921e-04\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.3438e-04 - val_loss: 0.0019\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.2052e-04 - val_loss: 8.7269e-04\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.2515e-04 - val_loss: 0.0013\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.3673e-04 - val_loss: 0.0015\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.2876e-04 - val_loss: 6.9811e-04\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.4357e-04 - val_loss: 7.1898e-04\n",
      "23/23 [==============================] - 1s 7ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, 64)               8704      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,769\n",
      "Trainable params: 8,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aviral\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 3s 82ms/step - loss: 0.0186 - val_loss: 0.1088\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0108 - val_loss: 0.0773\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0066 - val_loss: 0.0533\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0040 - val_loss: 0.0337\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.0026 - val_loss: 0.0214\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 34ms/step - loss: 0.0020 - val_loss: 0.0161\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0016 - val_loss: 0.0094\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 0.0011 - val_loss: 0.0069\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 8.3247e-04 - val_loss: 0.0051\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 6.2066e-04 - val_loss: 0.0032\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 5.0354e-04 - val_loss: 0.0028\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 4.5921e-04 - val_loss: 0.0028\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 4.3320e-04 - val_loss: 0.0031\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 4.3430e-04 - val_loss: 0.0025\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 4.1874e-04 - val_loss: 0.0025\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 4.0546e-04 - val_loss: 0.0024\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.9439e-04 - val_loss: 0.0023\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 3.8723e-04 - val_loss: 0.0023\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.7825e-04 - val_loss: 0.0023\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.7322e-04 - val_loss: 0.0023\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 3.6209e-04 - val_loss: 0.0021\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.6541e-04 - val_loss: 0.0021\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.5052e-04 - val_loss: 0.0022\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.5353e-04 - val_loss: 0.0020\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.4439e-04 - val_loss: 0.0021\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.4508e-04 - val_loss: 0.0020\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.4050e-04 - val_loss: 0.0029\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.3691e-04 - val_loss: 0.0023\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.3913e-04 - val_loss: 0.0026\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.3698e-04 - val_loss: 0.0020\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.2900e-04 - val_loss: 0.0027\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.3571e-04 - val_loss: 0.0019\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 3.2485e-04 - val_loss: 0.0023\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 3.2001e-04 - val_loss: 0.0019\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 3.2011e-04 - val_loss: 0.0021\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 3.1244e-04 - val_loss: 0.0019\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.2025e-04 - val_loss: 0.0021\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 3.1312e-04 - val_loss: 0.0020\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.1062e-04 - val_loss: 0.0019\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.0876e-04 - val_loss: 0.0021\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.0650e-04 - val_loss: 0.0019\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 3.1096e-04 - val_loss: 0.0021\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.0192e-04 - val_loss: 0.0019\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.0714e-04 - val_loss: 0.0017\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.9990e-04 - val_loss: 0.0018\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.0180e-04 - val_loss: 0.0017\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.9657e-04 - val_loss: 0.0018\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 3.0050e-04 - val_loss: 0.0017\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.9547e-04 - val_loss: 0.0017\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.9548e-04 - val_loss: 0.0021\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.9027e-04 - val_loss: 0.0018\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.8815e-04 - val_loss: 0.0017\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.8956e-04 - val_loss: 0.0017\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 2.9096e-04 - val_loss: 0.0017\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.8494e-04 - val_loss: 0.0017\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.9299e-04 - val_loss: 0.0018\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.8082e-04 - val_loss: 0.0018\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.8702e-04 - val_loss: 0.0017\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.8653e-04 - val_loss: 0.0016\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.7513e-04 - val_loss: 0.0019\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.8179e-04 - val_loss: 0.0017\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 2.8473e-04 - val_loss: 0.0017\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.8276e-04 - val_loss: 0.0016\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.7713e-04 - val_loss: 0.0016\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.7479e-04 - val_loss: 0.0016\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.7605e-04 - val_loss: 0.0016\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.7907e-04 - val_loss: 0.0015\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.7424e-04 - val_loss: 0.0015\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.6393e-04 - val_loss: 0.0020\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.7763e-04 - val_loss: 0.0015\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 2.6910e-04 - val_loss: 0.0017\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.7021e-04 - val_loss: 0.0015\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.6692e-04 - val_loss: 0.0016\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.6460e-04 - val_loss: 0.0016\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.6611e-04 - val_loss: 0.0016\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.6276e-04 - val_loss: 0.0014\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.5967e-04 - val_loss: 0.0017\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.6305e-04 - val_loss: 0.0016\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.5726e-04 - val_loss: 0.0014\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.5969e-04 - val_loss: 0.0014\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.5600e-04 - val_loss: 0.0014\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.5785e-04 - val_loss: 0.0014\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.5923e-04 - val_loss: 0.0015\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.5547e-04 - val_loss: 0.0014\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.4868e-04 - val_loss: 0.0014\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.5527e-04 - val_loss: 0.0014\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 2.4701e-04 - val_loss: 0.0014\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 2.4756e-04 - val_loss: 0.0014\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 2.4530e-04 - val_loss: 0.0014\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 2.4241e-04 - val_loss: 0.0016\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 2.5329e-04 - val_loss: 0.0015\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 2.4413e-04 - val_loss: 0.0013\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.4296e-04 - val_loss: 0.0013\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 2.4866e-04 - val_loss: 0.0013\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 2.4279e-04 - val_loss: 0.0014\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.4034e-04 - val_loss: 0.0013\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.4142e-04 - val_loss: 0.0013\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 2.3806e-04 - val_loss: 0.0013\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 2.4044e-04 - val_loss: 0.0013\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 2.3881e-04 - val_loss: 0.0012\n",
      "23/23 [==============================] - 1s 7ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 100, 32)           4352      \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,705\n",
      "Trainable params: 12,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aviral\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 96ms/step - loss: 0.7682 - val_loss: 0.0688\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0035 - val_loss: 0.0282\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0041 - val_loss: 0.0286\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.0029 - val_loss: 0.0413\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.0040 - val_loss: 0.0299\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.0036 - val_loss: 0.0743\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0030 - val_loss: 0.0387\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0032 - val_loss: 0.0710\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0037 - val_loss: 0.0336\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0027 - val_loss: 0.0338\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0019 - val_loss: 0.0352\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0046 - val_loss: 0.0467\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0015 - val_loss: 0.0240\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0015 - val_loss: 0.0152\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0026 - val_loss: 0.0109\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0014 - val_loss: 0.0154\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0014 - val_loss: 0.0281\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0019 - val_loss: 0.0143\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 8.9799e-04 - val_loss: 0.0494\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0021 - val_loss: 0.0521\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 5.2214e-04 - val_loss: 0.0071\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.0021 - val_loss: 0.0118\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 5.3734e-04 - val_loss: 0.0051\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 1.7243e-04 - val_loss: 0.0012\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 9.0438e-04 - val_loss: 0.0094\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 9.0991e-04 - val_loss: 0.0049\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 9.6373e-04 - val_loss: 0.0049\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 8.5054e-04 - val_loss: 0.0066\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 4.8876e-04 - val_loss: 0.0068\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 6.0889e-04 - val_loss: 0.0041\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 8.0884e-04 - val_loss: 0.0013\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 9.8296e-04 - val_loss: 0.0060\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 5.2572e-04 - val_loss: 0.0017\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 7.9771e-04 - val_loss: 0.0023\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 3.4744e-04 - val_loss: 0.0083\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0010 - val_loss: 0.0070\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 4.2947e-04 - val_loss: 0.0459\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 7.3920e-04 - val_loss: 0.0077\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 7.7769e-04 - val_loss: 0.0263\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 5.0104e-04 - val_loss: 0.0093\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 6.8000e-04 - val_loss: 0.0154\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 4.5528e-04 - val_loss: 0.0142\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 8.0540e-04 - val_loss: 0.0021\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 4.6883e-04 - val_loss: 0.0031\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 8.0197e-04 - val_loss: 0.0026\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 5.4546e-04 - val_loss: 0.0037\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 3.4164e-04 - val_loss: 0.0039\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 7.9005e-04 - val_loss: 0.0012\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 5.5031e-04 - val_loss: 0.0093\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 3.8380e-04 - val_loss: 0.0087\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 3.2481e-04 - val_loss: 0.0018\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 7.4008e-04 - val_loss: 0.0041\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 4.4676e-04 - val_loss: 0.0014\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 4.1853e-04 - val_loss: 0.0040\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 5.7296e-04 - val_loss: 0.0045\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 4.6577e-04 - val_loss: 0.0045\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 4.0846e-04 - val_loss: 0.0069\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 4.8518e-04 - val_loss: 0.0031\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 5.9614e-04 - val_loss: 0.0056\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 5.3181e-04 - val_loss: 0.0140\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 4.0044e-04 - val_loss: 0.0066\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 3.1910e-04 - val_loss: 0.0022\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 4.2899e-04 - val_loss: 0.0135\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 5.6358e-04 - val_loss: 0.0096\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 4.9604e-04 - val_loss: 0.0047\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 4.8846e-04 - val_loss: 0.0032\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 4.1402e-04 - val_loss: 0.0014\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 5.0520e-04 - val_loss: 0.0066\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 5.5499e-04 - val_loss: 0.0170\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.7758e-04 - val_loss: 0.0186\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 4.1360e-04 - val_loss: 0.0140\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 3.5561e-04 - val_loss: 0.0129\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 3.8163e-04 - val_loss: 0.0081\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 4.0449e-04 - val_loss: 0.0029\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 5.3569e-04 - val_loss: 0.0012\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.3628e-04 - val_loss: 8.1377e-04\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 5.2931e-04 - val_loss: 0.0122\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.6926e-04 - val_loss: 0.0045\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 4.2185e-04 - val_loss: 0.0098\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 4.3381e-04 - val_loss: 0.0015\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 4.0469e-04 - val_loss: 0.0016\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.8013e-04 - val_loss: 0.0044\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.5864e-04 - val_loss: 0.0040\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.8673e-04 - val_loss: 0.0039\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 4.3666e-04 - val_loss: 0.0065\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.7098e-04 - val_loss: 0.0046\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.9931e-04 - val_loss: 0.0012\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 3.3372e-04 - val_loss: 0.0025\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 4.5886e-04 - val_loss: 0.0036\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.0044e-04 - val_loss: 0.0017\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.2093e-04 - val_loss: 0.0104\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.9325e-04 - val_loss: 8.5346e-04\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.6813e-04 - val_loss: 0.0015\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 4.5366e-04 - val_loss: 8.4975e-04\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.2061e-04 - val_loss: 0.0040\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 4.1577e-04 - val_loss: 9.0495e-04\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 3.3049e-04 - val_loss: 0.0011\n",
      "23/23 [==============================] - 1s 10ms/step\n",
      "11/11 [==============================] - 0s 10ms/step\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 100, 32)           4352      \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,705\n",
      "Trainable params: 12,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aviral\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 99ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0013 - val_loss: 0.0056\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0014 - val_loss: 0.0139\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0012 - val_loss: 0.0087\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0015 - val_loss: 0.0046\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 6.5689e-04 - val_loss: 0.0053\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 5.5990e-04 - val_loss: 0.0030\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 8.4853e-04 - val_loss: 0.0067\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 9.9639e-04 - val_loss: 0.0026\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 6.2130e-04 - val_loss: 0.0074\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 8.9095e-04 - val_loss: 0.0083\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 5.8632e-04 - val_loss: 0.0029\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 6.7246e-04 - val_loss: 0.0038\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 6.4590e-04 - val_loss: 0.0020\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 6.7926e-04 - val_loss: 0.0066\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 4.4004e-04 - val_loss: 0.0025\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 5.2936e-04 - val_loss: 0.0017\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 5.3607e-04 - val_loss: 0.0052\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 3.4111e-04 - val_loss: 0.0018\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 6.6720e-04 - val_loss: 0.0015\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 5.1685e-04 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 4.0350e-04 - val_loss: 0.0055\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 4.7693e-04 - val_loss: 0.0023\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 4.9392e-04 - val_loss: 0.0014\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 4.7366e-04 - val_loss: 0.0015\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 3.4440e-04 - val_loss: 0.0014\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 4.3870e-04 - val_loss: 0.0023\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 3.7280e-04 - val_loss: 0.0041\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 4.4971e-04 - val_loss: 0.0095\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 3.2273e-04 - val_loss: 0.0023\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 4.1912e-04 - val_loss: 0.0077\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 3.7560e-04 - val_loss: 0.0026\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 3.7380e-04 - val_loss: 0.0022\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 3.0545e-04 - val_loss: 0.0025\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 2.9903e-04 - val_loss: 0.0012\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 3.8646e-04 - val_loss: 0.0014\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 3.1825e-04 - val_loss: 0.0026\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 3.0077e-04 - val_loss: 0.0013\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 2.9319e-04 - val_loss: 0.0015\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 3.7322e-04 - val_loss: 0.0013\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.6441e-04 - val_loss: 0.0013\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 2.7231e-04 - val_loss: 0.0034\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 3.3107e-04 - val_loss: 0.0034\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 2.5648e-04 - val_loss: 0.0017\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 3.5635e-04 - val_loss: 0.0011\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 1.7939e-04 - val_loss: 0.0015\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 3.0844e-04 - val_loss: 0.0026\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 3.1154e-04 - val_loss: 0.0019\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 3.2091e-04 - val_loss: 0.0011\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.8497e-04 - val_loss: 9.9895e-04\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 2.2969e-04 - val_loss: 0.0010\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.2148e-04 - val_loss: 0.0015\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.4948e-04 - val_loss: 0.0022\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.7748e-04 - val_loss: 9.7943e-04\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.7905e-04 - val_loss: 0.0015\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.3292e-04 - val_loss: 0.0012\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 2.3463e-04 - val_loss: 0.0051\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.7416e-04 - val_loss: 8.9951e-04\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.1084e-04 - val_loss: 0.0021\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.7764e-04 - val_loss: 0.0014\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.6666e-04 - val_loss: 8.6460e-04\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.7786e-04 - val_loss: 0.0012\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 1.6409e-04 - val_loss: 0.0013\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 2.6985e-04 - val_loss: 0.0014\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 2.1641e-04 - val_loss: 0.0046\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.1970e-04 - val_loss: 7.7117e-04\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 2.9382e-04 - val_loss: 8.3672e-04\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.2272e-04 - val_loss: 0.0025\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 1.8489e-04 - val_loss: 0.0056\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 1.8277e-04 - val_loss: 0.0012\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.1414e-04 - val_loss: 0.0027\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 1.7138e-04 - val_loss: 0.0039\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 2.4214e-04 - val_loss: 8.8844e-04\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.3802e-04 - val_loss: 9.2757e-04\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 2.5733e-04 - val_loss: 0.0022\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.0589e-04 - val_loss: 9.9126e-04\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 1.2764e-04 - val_loss: 0.0019\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.3401e-04 - val_loss: 0.0022\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.0490e-04 - val_loss: 0.0019\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 2.0186e-04 - val_loss: 8.4546e-04\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 2.2181e-04 - val_loss: 7.4263e-04\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 1.6704e-04 - val_loss: 0.0010\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.1034e-04 - val_loss: 9.5220e-04\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 1.7730e-04 - val_loss: 8.8024e-04\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 1.4363e-04 - val_loss: 0.0016\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 1.8320e-04 - val_loss: 0.0033\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 2.3143e-04 - val_loss: 0.0015\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 1.7460e-04 - val_loss: 0.0019\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 2.0780e-04 - val_loss: 0.0011\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 1.9340e-04 - val_loss: 9.5257e-04\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 1.8202e-04 - val_loss: 7.9732e-04\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 1.1025e-04 - val_loss: 0.0019\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 1.9777e-04 - val_loss: 8.8350e-04\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 2.1461e-04 - val_loss: 0.0011\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 1.2999e-04 - val_loss: 0.0026\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 2.0268e-04 - val_loss: 0.0016\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 1.8612e-04 - val_loss: 0.0030\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 2.0056e-04 - val_loss: 0.0013\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 1.5826e-04 - val_loss: 6.9498e-04\n",
      "23/23 [==============================] - 1s 15ms/step\n",
      "11/11 [==============================] - 0s 16ms/step\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_7 (LSTM)               (None, 100, 32)           4352      \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,705\n",
      "Trainable params: 12,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aviral\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\rmsprop.py:140: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 5s 137ms/step - loss: 0.0704 - val_loss: 0.4288\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0530 - val_loss: 0.3550\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.0403 - val_loss: 0.2801\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.0285 - val_loss: 0.2086\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0184 - val_loss: 0.1442\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0111 - val_loss: 0.0888\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0067 - val_loss: 0.0453\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0048 - val_loss: 0.0257\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0036 - val_loss: 0.0156\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0025 - val_loss: 0.0089\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0017 - val_loss: 0.0077\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 9.3239e-04 - val_loss: 0.0051\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 8.2647e-04 - val_loss: 0.0073\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 7.7973e-04 - val_loss: 0.0052\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 7.7930e-04 - val_loss: 0.0055\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 7.4635e-04 - val_loss: 0.0067\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 7.0678e-04 - val_loss: 0.0090\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 1s 88ms/step - loss: 7.4275e-04 - val_loss: 0.0097\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 7.3069e-04 - val_loss: 0.0069\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 1s 77ms/step - loss: 6.9739e-04 - val_loss: 0.0107\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 7.3500e-04 - val_loss: 0.0076\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 7.0354e-04 - val_loss: 0.0054\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 6.6607e-04 - val_loss: 0.0043\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 6.7130e-04 - val_loss: 0.0054\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 6.6199e-04 - val_loss: 0.0048\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 6.4456e-04 - val_loss: 0.0045\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 6.2374e-04 - val_loss: 0.0065\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 6.1072e-04 - val_loss: 0.0041\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 6.1635e-04 - val_loss: 0.0058\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 1s 83ms/step - loss: 6.2322e-04 - val_loss: 0.0038\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 5.8197e-04 - val_loss: 0.0037\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 5.8807e-04 - val_loss: 0.0052\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 5.8156e-04 - val_loss: 0.0035\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 5.7057e-04 - val_loss: 0.0036\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 5.7668e-04 - val_loss: 0.0049\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 5.7008e-04 - val_loss: 0.0041\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 5.5045e-04 - val_loss: 0.0033\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 5.4961e-04 - val_loss: 0.0034\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 5.4574e-04 - val_loss: 0.0032\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 5.3602e-04 - val_loss: 0.0036\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 5.3030e-04 - val_loss: 0.0035\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 5.2093e-04 - val_loss: 0.0030\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 5.1504e-04 - val_loss: 0.0033\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 5.2138e-04 - val_loss: 0.0037\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 5.0468e-04 - val_loss: 0.0030\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 5.0170e-04 - val_loss: 0.0029\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 4.8824e-04 - val_loss: 0.0036\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 4.9283e-04 - val_loss: 0.0028\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 4.8554e-04 - val_loss: 0.0029\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 4.7641e-04 - val_loss: 0.0030\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 4.9000e-04 - val_loss: 0.0033\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 4.7197e-04 - val_loss: 0.0028\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 4.6122e-04 - val_loss: 0.0032\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 1s 86ms/step - loss: 4.6464e-04 - val_loss: 0.0028\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 4.6319e-04 - val_loss: 0.0026\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 4.5400e-04 - val_loss: 0.0029\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 4.5728e-04 - val_loss: 0.0025\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 4.4972e-04 - val_loss: 0.0026\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 1s 97ms/step - loss: 4.5513e-04 - val_loss: 0.0028\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 4.4958e-04 - val_loss: 0.0023\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 4.3932e-04 - val_loss: 0.0026\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 4.3058e-04 - val_loss: 0.0024\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 4.4225e-04 - val_loss: 0.0023\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 4.2096e-04 - val_loss: 0.0026\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 4.2326e-04 - val_loss: 0.0023\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 4.1569e-04 - val_loss: 0.0030\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 4.1685e-04 - val_loss: 0.0022\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 4.1331e-04 - val_loss: 0.0024\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 4.0486e-04 - val_loss: 0.0021\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 4.0535e-04 - val_loss: 0.0021\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 3.9566e-04 - val_loss: 0.0027\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 4.0111e-04 - val_loss: 0.0021\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 3.9294e-04 - val_loss: 0.0022\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 3.9131e-04 - val_loss: 0.0034\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 4.1743e-04 - val_loss: 0.0022\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 1s 102ms/step - loss: 3.8540e-04 - val_loss: 0.0025\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 3.9010e-04 - val_loss: 0.0019\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 3.9129e-04 - val_loss: 0.0019\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 1s 110ms/step - loss: 3.8075e-04 - val_loss: 0.0020\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 3.8234e-04 - val_loss: 0.0020\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 1s 90ms/step - loss: 3.7727e-04 - val_loss: 0.0021\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 3.6507e-04 - val_loss: 0.0018\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 3.8205e-04 - val_loss: 0.0018\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 3.6214e-04 - val_loss: 0.0018\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 3.6624e-04 - val_loss: 0.0017\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 3.5881e-04 - val_loss: 0.0017\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 1s 95ms/step - loss: 3.5322e-04 - val_loss: 0.0025\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 1s 81ms/step - loss: 3.6182e-04 - val_loss: 0.0019\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 3.4471e-04 - val_loss: 0.0018\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 1s 99ms/step - loss: 3.5341e-04 - val_loss: 0.0023\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 3.6069e-04 - val_loss: 0.0016\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 3.4312e-04 - val_loss: 0.0018\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 3.4130e-04 - val_loss: 0.0018\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 3.4744e-04 - val_loss: 0.0017\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 3.4216e-04 - val_loss: 0.0017\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 3.3623e-04 - val_loss: 0.0020\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 3.3346e-04 - val_loss: 0.0015\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 3.2634e-04 - val_loss: 0.0019\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 1s 91ms/step - loss: 3.3123e-04 - val_loss: 0.0015\n",
      "23/23 [==============================] - 1s 14ms/step\n",
      "11/11 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "learn_rates = [0.01,0.001,0.0001]\n",
    "j=0\n",
    "i=0\n",
    "c=10000\n",
    "rows = 4\n",
    "cols = 3\n",
    "model = []\n",
    "model = [0 for i in range(6)] \n",
    "q = []\n",
    "q=[0 for i in range(6)] \n",
    "learn_rate=0\n",
    "model_name=\"\"\n",
    "for model_item in models:\n",
    "    for lr in learn_rates:\n",
    "        model[i] = model_item[1](lr)\n",
    "        model[i].summary()\n",
    "        model[i].fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=64,verbose=1)\n",
    "\n",
    "        train_predict=model[i].predict(X_train)\n",
    "        test_predict=model[i].predict(X_test)\n",
    "        train_predict=scaler.inverse_transform(train_predict)\n",
    "        test_predict=scaler.inverse_transform(test_predict)\n",
    "        c=math.sqrt(mean_squared_error(y_train,train_predict))\n",
    "        q[i]=c\n",
    "                          \n",
    "        \n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "# print(\"Best Model for AAPL is \".format(model_name))\n",
    "# print(\"Best learning rate is {}\".format(learn_rate))\n",
    "# print(\"Minimum mean squared error is {}\".format(c))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f104240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.engine.sequential.Sequential object at 0x0000027F6E883B80>, <keras.engine.sequential.Sequential object at 0x0000027F7C65B910>, <keras.engine.sequential.Sequential object at 0x0000027F7D7BC250>, <keras.engine.sequential.Sequential object at 0x0000027F0A8EF3D0>, <keras.engine.sequential.Sequential object at 0x0000027F11405750>, <keras.engine.sequential.Sequential object at 0x0000027F114FCA60>]\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa8b5791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144.67435457704687, 143.21719606140388, 141.75288392819817, 143.63776185465346, 142.96995978153694, 142.51937460777881]\n"
     ]
    }
   ],
   "source": [
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f01551c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = min(q)\n",
    "p=0\n",
    "for idx in range(0, len(q)):\n",
    "    if temp == q[idx]:\n",
    "        p=idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97a34d",
   "metadata": {},
   "source": [
    "Minimum Error.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41adf8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141.75288392819817\n"
     ]
    }
   ],
   "source": [
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5a6c18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4dae7",
   "metadata": {},
   "source": [
    "Best Model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32df3c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bidirectional\n"
     ]
    }
   ],
   "source": [
    "model_name=models[int(p/3)][0]\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31aa12a",
   "metadata": {},
   "source": [
    "Best Learning Rate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0347b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_rate=learn_rates[p%3]\n",
    "learn_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7f83c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "print(learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77b51c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, 64)               8704      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,769\n",
      "Trainable params: 8,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model[p].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b985d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1d92af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d107fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 7ms/step\n",
      "11/11 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "train_predict=model[p].predict(X_train)\n",
    "test_predict=model[p].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bd5caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c84bef",
   "metadata": {},
   "source": [
    "Training Predict Error...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae388398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141.75288392819817"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(y_train,train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8803c82",
   "metadata": {},
   "source": [
    "Testing Predict Error...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a92e58f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237.98829456329963"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(ytest,test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe56877",
   "metadata": {},
   "source": [
    "Plotting the Training and Testing Result....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f1a7d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAAsTAAALEwEAmpwYAABCUUlEQVR4nO3dd3hUVfrA8e+5d2p6BQIBQpemNKWIithQsa699+66tl1d67qrq66rq+7PXdfVtSv2DhbEAtIC0lvoJEB6T6af3x8zCROSkEJ63s/z5GHm1vdmwpuTc899j9JaI4QQomsx2jsAIYQQLU+SuxBCdEGS3IUQoguS5C6EEF2QJHchhOiCLO0dAEBSUpJOS0tr7zCEEKJTWbZsWZ7WOrmudR0iuaelpZGent7eYQghRKeilNpR3zrplhFCiC5IkrsQQnRBktyFEKILkuQuhBBdkCR3IYTogiS5CyFEFyTJXQghuiBJ7kII0Qw/bsplR355e4dRrw7xEJMQQnQ2l7+yBIDtj5/azpHUTVruQgjRBC6vn3s/Wl39vqNOeCTJXQghGumXLXkc8sAc3lmyE5SHiAH/4L4fnmzvsOokyV0IIRpp6bbC6tfW2OWYjr18vvNN9pbvbceo6ibJXQghGslQ+15bYldUv84ozGj7YBogyV0IIRrJF9CYURuwJc/BErEdb/GhABS5i9o3sDpIchdCiEZ4c9EOnp27kYi+r2JP+oGAJxF39mkAFLoKG9i7tsVb80m750vmrGmdLh1J7kII0YAyt4/7P1mDJWZl9bLJvY5C+yPR2mhWy/2Wd34F4Ou1rZPcZZy7EEIcgNaaUQ99DWicfWaFlhncdsRVJLpL+aokolnJPRAIDqHsEWNvwWj3kZa7EEIcgNsXAMCw5QAQ8MZStuEx+sWk4rSZ4G96cl+VWUT/npVEDnyKSSMKWjpkQFruQghxQBUePwBm5Obg+x3XA2C3GDisJgFfBMXu4kYfb+3uYk7/5wIs0WtwpubRKyqh5YNGWu5CCHFA5W4fAKZzFwFvLNobTMY208BpNfH7I5p0QzWnxA2A4diNDpgMjhvc8kEjyV0IIQ6o0htsuRv2PQRcKdXLDUPhsBroJnbLBELlCkxHFqavN1bT2qLxVsfXKkcVQoguosLjB+XDsOfid/eqsc5qGtV97o2tMVPi8gIa05nFiMThrRBxkCR3IYQ4gIzsUgxbNkoFarTcAawWA+134g14cfvdjTpecYUXZS1EmZWkOFunSwYkuQshxAFtzy/H4twDgN/du8Y6m6nQgeBQxnJv42q7F1f6MB27g2/cfVou0P3IaBkhhDiAcrcfe0QudtPOj3+4gJxSD8UVXiDYLVOV3Cu8FSQ6Exs8XnGlF8ORhdYGh/ce2WpxS3IXQogDKHX5sNiKSYlMISHSQUKko3qd1TSgquXua2zL3YvNkUPvyL5ccPjAVokZpFtGCCEOqNztQ1kLSYlMqbXOahpof1O7ZTzYHeWkxfZGKdXwDs0kyV0IIQ6g3OMjYBSSElU7udsszelz96LNEpIjkls0zv01mNyVUg6l1BKl1Eql1Fql1J9CywcopRYrpTYrpWYppWyh5fbQ+82h9WmtegVCCNGKStwV+I2SelvuVd0yV70+v1HHK6r04FMljeqfPxiNabm7gela68OAMcAMpdQk4AngGa31YKAQuDq0/dVAYWj5M6HthBCi09FaU+QNjpTpH9O/1vrwG6rKcDdqrHuxqxiNj2RnO7fcdVBZ6K019KWB6cAHoeWvAWeGXp8Rek9o/XGqNTuWhBCilZz63HyyynYCDSd3DDcef6DBY5b4goXCkpxJLRdoHRrV566UMpVSK4Ac4FtgC1CktfaFNskEqgZs9gF2AYTWFwO1/v5QSl2nlEpXSqXn5uYe1EUIIURrWLenBMOWD9SX3BUE7Gi/HdOxG4/vwMnd5fXj1cEiYx0iuWut/VrrMUAqcARwyMGeWGv9H631BK31hOTk1v3zRAghmsuw5WJXsURaI2uts5oGYBDwxWKN/ZU9ZTkHPFZJpRdlCXaEdIjkXkVrXQTMAyYDcUqpqnHyqUBW6HUW0BcgtD4WyG+JYIUQoq0pWz4jkwfVuS6Y3CEQqjnz9Y45BzxWcaUXw1oEQM+Ini0XZB0aM1omWSkVF3rtBE4A1hNM8ueENrsc+DT0+rPQe0Lrv9eNragjhBAdSN8EJxERhXV2yUCw7C+AK+t8tN/BmryVdW5XpbgyWFcmyhJLhDWixeMN15gnVFOA15RSJsFfBu9prb9QSq0D3lVK/QX4FXg5tP3LwBtKqc1AAXBBK8QthBCtrsJbjodi+sX0q3O91VI1VsTE7+pNofvAdd3fXrwTw1pEsrP2sMqW1mBy11qvAsbWsXwrwf73/Ze7gHNbJDohhGgnPn+AUv8e7NR9MxX2dcsA6ICDMk/JAY/50a9ZRAwsJCVyVEuGWid5QlUIIeqQWVhJwAzeLuwXXU/LPSy543dS5i2rc7t9NIa1iNTo3g1sd/AkuQshRB0WbMnDsAXHpKdGp9a5jS0suQd80ZR4Cw5YhkCZ5SjDS1ps3cdrSZLchRCiDl+t3oOyFhBnj69zGCSExrmH+CvS8GsfGws21ntMwxZ8pmdAXFqLxlrnuVr9DEII0QkFAuCMKKRfTN96tzGNfcm9auLs3eW769zWH9AY9uA4+EGxdQ+tbEmS3IUQog6VXj/Kln3ARBxeWSXgiwYgv7LmYz3nvbiQtHu+JL/cjWHPwaoc9IqsORdra5DkLoQQdSj1FOFTJQyMPfCEGoemxgZfBGwAVPoqa6xfsi3Yb//mwh0YthwSbamtWse9iiR3IYTYj9aaHPcOAAbGNXa2JBMdsFDhq6hzrTfULdPDUffIm5YmyV0IIfazJbcclwr2nQ+NH3rAbcPb4Dpgo8Jbd3J/M305hrWYlIi6x8y3NEnuQgixn6IKD4Z9L04zquEaMOFdLAEb5fsl94HJwZE2LutqAMYnHdOisdZHkrsQQoTRWvPmoh2Y9r30ixrUYP942IAZtC+GzYWb9ztg8B/TuZOAN5ZeEfWPvmlJktyFECLMTxl5fLIiC8O+l4GNGLIYnvr9rlR2lu6ssd7jD2BGbsQauwp/+cBGTejREiS5CyFEmB355ShrAcp0c1jP4Q1uH96y134nFb5yAnpfAvf5NbaEBQB48o+t8eBTa5LkLoQQYYoqvFgitwAwuXet2oi11Lyh6gCoUYLA6w+gLCX4Sg/BEujFtKE9WjTe+khyF0KIMMWVXuwRu4m2RTMgdkCD29fokvcHk3uZZ18BMa8/gGEpIeCL45zxqRiGtNyFEKLNFVV4MZ27GZEwolEPG6mwtntVy73UW1q9zBfwoiwVaF909QNNbUGSuxBChCmsrCBg3c3wxIb72/dXldxrtNwJdtFofwR/PXt0ywTZCJLchRAiTJ4rE5SPYQnDGrX97ScMZXhKDAC6qlsmVNfdH9D4qQitc9I3vnWn1gsnyV0IIUK255WzqSgDgGHxjUvukwclMvu2o4CwbhlPsFumzO0DM1hrRvudOK1mS4dcL0nuQggRMu2pH9DWLAwspMWmNf0A/trJXYUld7u17VKuJHchhKimsUStY1DMKKyGtel7B2p2y5S5fCgjlNwDTuyWtku5DU6QLYQQXdna3cX4/AEu//IWooevAuDUATc272Daig5YKAlNlF1c6UWZoVozfmeblPqtIsldCNFtubx+Zr7wFc6+r2I6g1UgA75ILh11VrOPqQPO6m6ZnQUV1d0ym/589sEH3ASS3IUQ3da6PSXYEn7GdOzGVzaMgCeRk9JOwGZpepdMUpSNvDIP2u+oTu57iipRZiURlohmdfMcDOlzF0J0W2e/8Atm5BZ85QOp3HUl7uzTmZ42uVnHevHSCcEX/n0t93KPH9N0EWOPaamQG02SuxCi+zIqMOx78Ffsm20pxtm8Do2qybJ1YF/L/Zu1e9FGBTE2Se5CCNEmtuaWYYnYhlIaf3lYcnc0r/ukqmSM9jurb6huzStHmRXE2eMONtymx9PmZxRCiA5g495SzIjtmMrK7UcfX728Z4yjWcczVO2WO4CyFNMjom0qQdaIp83PKIQQHcCirflYInYxMnEEtxw7nB7RdgBSYpuX3Ku7ZUItd6/PDwRQ1tKGp+prBTJaRgjR7bi8ft5avJ3IoXsYmRS8gfrBDVNYt6cYi9m8Nm9Vy52AA1/Ax5AHPkOZbpTy0zNSkrsQQrS6j3/Nwm/JI6DcDE8IVn/slxhBv8TmF/YK73MHUGYlyhLsnmmPlrt0ywghup2iCi+mI/jQUnNK+9alquGuA8HuHWW4MSzFgCR3IYRoE+VuH6ZjNxbDwqBGTILdFFXJHcONsgZHzbRHt4wkdyFEt1Pi8mJzZjModhBWs4WfHA1ruStLMQYmCY6Elj1HIzSY3JVSfZVS85RS65RSa5VSt4WWP6yUylJKrQh9nRK2z71Kqc1KqY1KqZNa8wKEEKKpSl0+DFtuo+ZIbbyqoZCh5G4twnTsJsqSiKHavh3dmBuqPuBOrfVypVQ0sEwp9W1o3TNa66fCN1ZKjQAuAEYCvYHvlFJDtdb+lgxcCCGaq6iygoBZ0Lya7Q2omo3J2fsDAKItLdOn31QN/jrRWu/RWi8PvS4F1gN9DrDLGcC7Wmu31nobsBk4oiWCFUKIg1Xq8rI+bxsoTVpMWosfX3vja7yv8Be3+Dkao0l/Kyil0oCxwOLQoluUUquUUq8opaquqA+wK2y3TOr4ZaCUuk4pla6USs/NzW165EII0Qxn/HMBee5MgFZpue+fVns4+rfCOZoaxQEopaKAD4Hfaa1LgH8Bg4AxwB7g7005sdb6P1rrCVrrCcnJyU3ZVQghmm1rXjmGLdigbMmWe98EZ/Xrss13Ub7tZsq23MmZfe5ssXM0RaMeYlJKWQkm9re01h8BaK2zw9a/BHwRepsF9A3bPTW0TAghOgTDno1DxRNpjWyxY9ot+ya/1t4ktDf4OtLWcudoisaMllHAy8B6rfXTYctTwjY7C1gTev0ZcIFSyq6UGgAMAZa0XMhCCHEQlBczcguJliFtcjqt2+Q0tTSm5X4kcCmwWim1IrTsj8CFSqkxgAa2A9cDaK3XKqXeA9YRHGlzs4yUEUJ0BCUuL5aodRiWUgY7TmiTc+aWutvkPPtrMLlrredTNYCzpq8OsM+jwKMHEZcQQrS4BRl5GI49aG1y+rCj2uSc5W5fm5xnf/KEqhCi29hRUIFpz2ZAbH9OHHmgEd3Nc+/Jh7T4MZtLkrsQott4fPYGDPsehsa3Tn/79cfsq1PjtAZvsN4wrWVr1zSWlPwVQnQbyizDsBUxOmlUq5/rX5eMY9qwtp+BqYq03IUQ3UZUdLDM7+jk0a1+rqqZmdqLtNyFEF1epcfPSz9vxW3ZjgOjeoKO1mAoCGgwVfsmd2m5CyG6vCXbC3j6202YEdtIcQ4kwtr8GZcaokJJvb1b7pLchRBdXoXbF3x4ybmTo1Inteq5qlK6JHchRJvRWuP1B9o7jDZX7vFjOnegDD9H95vcqueqmijbkOQuhGgrj8/ZwJD7ZuPrZgm+wuPDjNiGgcG4HuNa92ShnC597kKINvPij1sBKK70tnMkbavc7cdw7KF/TBpRtqhWPVdVg126ZYQQba6wonsl9xKXF9O+lyHxg1v9XAq5oSqEaEVPztnAyc/+XOe6ogpPG0fTvnYXF2HYChjSSk+mhrNZgmlVkrsQolW88MMW1u8pYX5GHtklrho3Uu98f2U7Rta25m3I4fP1KwAYEtf6yT3CFiw70N7JXR5iEqIL0mFFxC95eTGmoZhz274qiDvyK9BaV4/J7so+WJ6JGRG81zCqDcoOVCV3f6CdCrmHSMtdiC6odL8ys/6AZsHmvBrLPF14xEzVL7fMwgq+XJWJLeEX/JV96RnZs9XPHWUPtpkrPO07jYUkdyG6oL3FrlrLcsvcNboKPL4A6/eU4PF1rST/0k9bGXr/bBZtzeeFH7Zg7zEbw1rMTWOvbpPzP3nOYZwwoicjUmLa5Hz1Ubq95oAKM2HCBJ2ent7eYQjRZfy4KZfLX6l7dssbpw3iXz9sqX5/WGosJS4fs287CofVrHOfzmTY/bNx+wIos5TU/ispsgend1500aIWnTO1I1BKLdNaT6hrnfS5C9EF7S2urHddv4SadVVWZhYDsKuggiE9o1s1rrYQabfg9rmIGPA8RdYSdMBC+bbbulxib4gkdyG6oD3FLpSqe3Jmm1l3b6zd0vlb7RC8PjNiG4a1BG/ReFzZp0Kg9QqFdVTS5y5EF7Q9r5yUGEet5V/cOrV6HPb+fIGu0fdusxhYYlahA1Zce8+AQASH9Or8f5E0lSR3IbqQjOxS0u75kk9W7GZwz2j+ds6hRNr2tciTouwHSO7tf/+tJcRFGFii1+ArHQ7axn2nDOf9G1q3WFhHJN0yQnQhP2fsG+44pEcU507oy9njUtmWV05OqYtesQ427K07uXeVapFFvj0YlnJunnwa/exjmXlo7/YOqV1IcheiC3GGtdKnHxKcv9M0FIN7RDG4R7BgVq/Y2t01AF5/52+5a63Jc2ViAscMGM3IpO6Z2EG6ZYToUkpC1R5/P2MYUwYl1rlNWmJw1Mi9Jx/CtUcNqF7emcoAV3r8FJTXro+zJqsEr5EDQL+Yfm0dVociLXchupCCCg/nWudz4/AB9ZYWcFhNtv31FJRSrMos4qWftwFt33LXWlPm9hHtsDZ533P+/Qtrd5ew/fFT0Vpz45vLmTgwgZ0FFZiO3STYk4i2db+bqOGk5S5EF1JaWsoT5r9Q6z494HZViX9Q8r7a5m09WuaVBdsZ/fA37C6qf0x+fdbuLql+XVLpY87avfzp83XkllZgjd7E0X2ntmSonZIkdyG6ECN3PQYaegxv1PaRdgsf3zQFgKe/3USgDUfM/PmLdQBkFjY9uStLMZGDnmTujnl8vmo3KC/Kmk+max0YlUxLndbC0XY+0i0jRBcwPyOPS15ezE3mfLACTZgn1Bp6qOnXnUWs2V3MoalxrRNkHQxHJrtLs4GERm3vD2hufHMZtqS5GLYCnkt/iZVLL8becza2hF+oKqowuXf3G/q4P2m5C9EFXPlqsI7MdHMFZYmjILrx1Q8t5r6++ea0opuquMLLs99loCwlRA74J0+svp6AblyX0La8Mr7NWIc1LliLKiMvePPUErWxehtb4flEWLvfE6n7k+QuRBfg9WviKGWsysA5/OQm7RtejqCoDabf+3Z9Ns98twlL1HoAynyFrMxt3OQhW3PLsSd9D9rAWzwWw5YHRiXKWog7bxql6x9DlU1szfA7DUnuQnQBdovBLQNzMJXGHHp8k/atqj8OUFTZ+tPvFZS7MRy7cKR8XL1s6d6lDe63clcRN332Ita4ZYyOOQlf2RCU4cfZexZKBfBXDAIMDmvDbqWOTPrchejkfP4Abl+AcWwA0w69xzZp/8iw5F7cBi33bXnl2HvMBsCVfQqJKUvYXry93u13FVRw5v8toNC/lYi0j9ABk2sPvYZFy5cBYIneAIC/oj8Az17YtOvvqhpsuSul+iql5iml1iml1iqlbgstT1BKfauUygj9Gx9arpRSzymlNiulVimlxrX2RQjRnZWHZvxJLVsJfcaDxd6k/Z1hNdxd3tadPcjrD/DFmg1YIrfizj0eb8HRVFRGkV2RXe8+C7fkU2wsI6LfS2h/JOWb72VoUm+0P4rKzEsAqNh1OWgb7143qcZfIt1ZY7plfMCdWusRwCTgZqXUCOAeYK7WeggwN/Qe4GRgSOjrOuBfLR61EKJauduHQYDEso2QOr7J+xvhszO18lOqBeUeXLbVAPhKRgMQ8MYeMLmvzCzA3uszUAEqd1yL04ytnlTEVzqK0vWP4y8bTo9oO0ekNW7UTXfQYHLXWu/RWi8PvS4F1gN9gDOA10KbvQacGXp9BvC6DloExCmlUlo6cCFEUKXXTwr5mAEvJA5u1jGunhosQ+D2tl5y/3FTLhMfm4sleh1RZi8CnmDtG687mr3l2dQ1K1wgoJmfuQjDUopr93l8eM2ZrHtkRq3Klh/eOJkl9x1f4xdVd9ekG6pKqTRgLLAY6Km13hNatReoGnvVB9gVtltmaNn+x7pOKZWulErPzc1tatxCiBCPL0B/I9TyTRjYrGM8MHMEA5Mjcbdiy/3yV5agbLmYEVuY3PNoHpw5kgdmjiDgjcPtd1HgKqix/fKdhQz841fkGN+i/XacvlGM7RcP1Bzhc/3RAxnfX1rs+2t0cldKRQEfAr/TWpeEr9PBX7lNerRNa/0frfUErfWE5OTkpuwqhAjj8QVIU1XJfVCzj2MzjVafLNvR40sUdm4cdyVXTR3AkB5RBDzBduHmos01tj37hV8w7FlYojbiKTySZfedUiPWKnefNKxVY+6sGpXclVJWgon9La31R6HF2VXdLaF/c0LLs4C+YbunhpYJIVqB1x8gTe3Fb9ohuvk9oHZL6yV3rTWRzgos0Ru4/rDLGJKYCkBCpI2AqxcAmwo31drPljwXHbDy8DHX1+iKCe9+sdQzbWB315jRMgp4GVivtX46bNVnwOWh15cDn4Ytvyw0amYSUBzWfSOEaGHBlvte3NH9wWh+orNZDNy+lh0tU+b2kVfmJiOnDLc1A4Bj+h5dvT7CZqL9UURaYskozKherrXGMLxYIjPwFk3gogkjWjSu7qAxY4aOBC4FViulVoSW/RF4HHhPKXU1sAM4L7TuK+AUYDNQAVzZkgEL0Z0UlnvIK3MzpGfd5WsXb83nov8u5mtbNp6Y4RzMQ/c2i0Glp2WT+8znfmZ7fgU3HDMIS8QWIiyRDE/cV9QsWNdGkWxPq07uFR4fY/70LcqehTK8HJ8mFR6bo8HkrrWeD9R3C/q4OrbXwM0HGZcQArjm9XRW7shl+XV9iOl/GJg1a5/PWrqTf1qfZZiRSW7czIM6V7TdyoLN+dzx3gqePm/MQR2ryvb8CgDW7inGEZvBESmHYzH2pR17qKslyZbGmqKv8Qf8bMsrx+MPYHUEe3MfOmlGi8TS3UhnlRAdlNaaNTuyed/2CDGvHwdvnwdhNdc355RRufJjZpqLAXD1n3ZQ50tLCs7Q9NHylr9FtrlwA36jkOl9p9dYXlWRMsHaD5ffRWZZJlmh4mWmI4s4WwLJzroHXPzp9JG8ebXUkamPJHchOqjMwkpmGosYa2xmvn8kbPkets7DH9Bc9epSbnjmLZ6wvsS6QH+GuF7H1//ohg96AMnRTXuytSny9XJAcUzfY2osr7pJ+vHi4C+tjMKM6sqUA/sUMip5RL0zSl0+JY2pQ5JaLebOTpK7EB3I6Ie+5rGvgtUSs1d/z99t/ybL0o+rvXdTaY2H9Ff4OSOX7zfk8IjlVTxYuFnfjRcL0Y6De+ze0koPAClrPtb4xQyIHEOCo+Z49KqWe8DdE4ViU+EmdhdV4rBXsqt8G2N7SJ2Y5pIiDEJ0EC6vn1K3j//8tJVxBV8xY/MjADhPvB/H7Eg+M47j/I0fkZ9yO5OMdUwx1+E+7i/8I+00tuaVkRR1cC1vfwvPwuT1B4AAzr6votDcOe73tbaxVtWS1zaizV5kFGZgVh5JdNxOXMARvY5o0Zi6E2m5C9FB7Cl2ATDJWMfxGX/hF/8ITnU/RuS4cxjXL4633FNAB8j45iUesfyPHB2HfeJVHNY3jrPGph70+QN1PP5/MJ6bm4HhyMS05+LKPo2jB4ystU14l4tdp5JRlEGpy4vFuQdTmTVG1oimkZa7EB3E6qxiAK41vySXOK713olhj8ZuMYlxWpnn6sWKyNHcw7sAVJz8LNgiW+z8VY/2t5SVmcWYzuDN2Um9D6+377xKZnYsjkA6UZ5ysO6lX0w/7Gbr3Qfo6qTlLkQHsXhrPkk2L9MsqygYMJM1f/0Nyx44AYBpw4IjRi4vv5U5/sN5y3ccEeMvbNHzj+8fz5VHpgHB6o1//mLdQT2xGmU3MR2ZxNsTeOWShicQCbh7odHke3biNXczOK55RdBEkCR3ITqIJdsKOK/XXkztZ+TUM1BKVY8mOWtsKgOSIikmihu8t/OYcV2T67Y3RlW//Z8+X8vL87cxe03zHy7fkV9BTGw2o5JGYrOY9W63/fFTAfCHyhDk+7bgVrkMimt+nRwhyV2INtGYm5V7i12Mt2wNvkmtfSPRFxrjfuERffnyt0e1aHxVquqkFx7kjExaa3YWFFGpshiR2LjSAdqbgM1w4LKuBDQDYgYcVAzdnSR3IVpZXpmbQX/8illLdx5wu0qvn2TvbojqBY6YWutvnT4EgPtPHVH9wFFLc1iDKeGnTcEy3A31k9dnb4mLcrUL0IxMrH0jdX8f3zQFMIiz9MWMDFaHHBAryf1gSHIXopVtyytHESD9+4/AVVLnNh5fAF9Ak+DZDfFpdW5z3oS+bH/81BpznrY0x37dJ2Yzk/svm/MxHZkAjExqOLkPTIoCwOLbV1A2LTatWecWQZLchTgIHl+AE5/5kQc+WVNr3U+bcvn9ByvZXVTJA5Y3+VvlQ+jXz6xRQiC31I3WurpgV6w7q97k3hYc1prJ3d/M4ZHb8sqxROwiyZlMj4geDW4f47QQZbewJTP4kFOCvQdOi7NZ5xZBktyFOAhb88rYll1E/NJn8K//osa6J+Zs4L30TF6eu4rzzXkAqN3LIDv4i6DM7ePwR7/jjvdWUuH1YcVHlCu7nZN7zZTQ3Amzc0tdWCI3c0Svwxu1vVKKKYMS8ZWOxFtyKLceel+zziv2keQuxH58/gCv/bKdElftm4o/bMzh/fR9s0he/soSrjO/4A7rB/De5eBzV6/rExdseV5X9AyRys31ntuDK7b/DMCugmDFxI9/zWJbbjl9VC4K3a7JPS6iZtXJ5iT34ko3ayo+ArOMKb2nNHq/m48dDAEnrqyLOLLP5CafV9QkDzEJsZ/5m/N46LO1LNqaz7VHDyS/zMMJI4JTwV3xv6UApMZH4LAalJUUcY39KwJaYeKDbT/BkODY9PxyD1OMNcw0F/Oi71R+NCeSZySRtHsFADvyy+mnsjnaXMfmnOH0U6HJzNoxuY/b70Gm3UWuJu1fVO5h4ku3YItfBMC0vtMave9hfeOqX0dYJTUdLGm5C7GfHzYGR4ps3bqF6175hR/f+iulGfOr119lzibljanc+MLn3G2ZRbwq4xrzEVxGBGzY1zWTV+bmHPMn8nU0uYffRUqsk030gx0LwO/lm3XZPG39F3+xvERcztIOkdz3Hx2zq7DigNtXeHxc+J9FfLoiC601h//zYWzxi/CVDcHMvoFYe2yz4nDa6h8XLxpHfj0KsZ8l2woYpbbysf8hrMoPVvDNmsUvR/6XkWo7D1rfAOBH++3YlY/i0Veye9cYNnjGMGbrjwD8/oOV7MivYFrMVhIGTeP+M8ZhfLWet+ZPZUrgOf71xlvM2RDN047gvKE98xfRV+WgLQ5UVM92u/Zww3pGU+byHXCbrbnlLNyaz9a8MoyIzdh7zMFXNoTKXVdRWe8cP/XrE+ckq6iyxnyponnkOyjEfnYWVHCF82esyo9XmyzwjyTLE8XEHy7meetzlBDJPd5ryCWObUOuIPbsZ9AaPikeDIXb8OZk8F56JskUBYc29g1OKJEYaWNeYAxubcW6eQ6nmQurz5lasJg0IxcVd3DzoLakhEgbZW4fgQM8gFVY4Qn+69/CH3/5HQFPIhMib0IpxU3Tmv6E6ae3HMn7N0h/e0uQlrsQYbz+AGVuH5OjNzDXO5YbvLfjxcJItZ3Pbfcx0NjL50Me4d3Vg3nXP51tF50CSlHi8vJ9YCwP8zrezT8AvRlnhCZ8DiX3hEgbFThYEBjJNZbZAGx3juCriuHcUP4xGIkQP659LjzMsvuPx1CKuz9YycL1+Qz841fVJQL2F3ySVWMmfU7AF0HFzmv594PTsJpGs1rfSVH2gy5dLII6RhNBiA5i6bYCHLhJ8e5ijU7DG2r/rNVpnOZ5lA+nfsmgY/fN+V7VR/3gzBHs0sn4LZH4s4OTbVyWmo02bZByGLCvbsvH/n0TPi8cdAfzPCMxCNCHXEhs/3oqiVF24iNtrN9T2uC2heUeDEcWlogdePKn8e8LjybSbpFulQ5AWu5ChLnov4s5TO3CIEBe1DDunjiMQcmRvPjTVkoqRzJuzFgGJEXy4MwR1bVeAPomRKAx2GXpR3LueuA4RnjXonqPrS7wlRhlA+DzwBTWufuTqZO5I/lQVmjbvgD6jG/Lyz2grKLK6tda6zpLERRWeLCEygV8efXNDE3q1WbxiQOT5C7EfkYaOwD48/UXVo9cmTEqpUaCu2pqzbonfeMjAFhU1pOz9CriKSGucBUcdk/1NgmR+5L4Ft2HD26YzPq9pXixsMIYxZjAGujbcWYeWnDPdE5/fj755R7cvkCtp1cheEPVHrmLAbEDGJrUux2iFPWRv52E2M8otQ3tiIO4/jWWH6iIVmyElaE9o9io+2J3F3C6uTD4QNKg6dXbJEbu60vuGWNnQloCUfZgwry54lr+nvoPiOvXotdyMPrEOfntccFiZXe9v7LWeq01P27KxbQXkBaT1sbRiYZIchfdQn6Zm3W76y7aVUVrjaFgeuxuVMph0MSiWX+YcQhLA8MAuNbyJdqwVve3w76x28nRdhb/MTh5xYiU4DjwLJIpTJrQpPO1hRhn8I/7L1bVruu+t8RFcaUHZS0gNfrgp/kTLUu6ZUSXV+nxM/4v32HiZ/Ojp6DMun/syz1+TO0juWIL9D6pyeeJtFtYr/tTqp2kqjx0r3G1JtT49OYj6R23ryDW0J5R1a9zS910NCN71/8QUqXHjzLL8Gk3faL6tGFUojGk5S66rJwSF9klLr5Zt5dD1RaW2W/A9cxY2LW0zu1LKr0MVbswtRdSxjT5fFF2C35MVgUGAqD61B7WeFjfOJKj9yX88K4eZx192u1taM9o+idGMCasNEAVjz+AYQs+zds/pn+t9aJ9SXIXXdK/f9zCEY/NZeJjc1m9q4j7rG8Rp8rxlObhe+NsyFlfY/sl2wrIKXUz2tgWXNB7TJPPWVVn/dtAaMTL6HMbtd/Wx07h3pMP4YGZjZuxqK2NSImhzF37SVWPL4BhD5ZMGBTb/kM4RU2S3EWXo7Xm8dkbAOhNHo5FzzDR2MD93is53fMX8t0GgXcvrq6rvjqzmPNeXMjd769ktNqGzxYD8U2fBSgydHP0df+J/LbvR9BvUqP2MwzF9ccMIrGDPrwT7bBQWkeFzKrkbjec9IqUIZAdjSR30eXsDJXSnWKs4RfHb7nL+j7b4ybyjn86O3QvnvRegFGwBfasAGDt7mIAMnLKGGVsw5U0qsk3UyHYLQMQwKDUiG6Zi+kAYhxWSip9lLi8FFfuS/JuXwDDlkNKRP9mT8cnWo8kd9HlPDc3+FDNNeZXANzouY3+v53Nm9ceSaTNZF5gDAEUZHwLQGZhJXdZZrHWfiWHGVvx9W7eWPPwPnO3L3CALTuXaIeVSq+fQx/+hlveXg4EH3C6+L+LMew59ImS/vaOSJK76LBWZxbz4KdrqqegK67wNmryiA+XZ3K68QvTzRW86byYUSdchjJMJg9KZO0jMxg5ZCAZlqGQ8Q1rsop5dd4qrjC/JlK5+dB/FM7JVzUr3vDWq6cLJfeq4ZAAP2fkobXmyMe/x7DvxbCW0C9KJrLuiCS5iw7r7SU7eH3hDl5buJ2Ccg+HPfIN5zz4Aus2bWpw39PNBRTqKE6+4cngDD9h+iZE8LVvHGSlM+uFB3nB+ixRysVM918oPPE57InNb4neGKqEOLhHVANbdh7Rjn2zMyVE2tiYXYqy5eLo8zY6YGVKzxPaMTpRHxnnLjqkrKJK3lmyCxte5sz5guTvvmG5fQUJqoysr7+EoXNq7RMIaGalB/eZat1A4cAzSYmtnWRT45085zqRabZF/Nn6KgEMOOMFvhh78UHHfecJQ4l1Wrl0Utfpqohx7EsTZW4fM/7xE87+H2LYcnHtPo+xvaXl3hE12HJXSr2ilMpRSq0JW/awUipLKbUi9HVK2Lp7lVKblVIblVJNfxJECGD26uATkS9an+YT+4OcaCxjQyD4aH6f/IXgqT1D0Ccrsrj3o9VMNVbjCFSSMvE3dR67b3wELuyc63mIu73XkX3x99ACiR3AYhrccMyg6mGRXUF4y93jC2BGbsISsR139kxO6HcysfvNuyo6hsZ0y7wKzKhj+TNa6zGhr68AlFIjgAuAkaF9XlBKdbwnM0SHV1zppScFHGuuZGugF9suW8Ku02dxjT9UiGvXohrbV3h83PHeSsapTTxvfR63JRoGHFPnsfsmBIt8ubHxt0f/RsqQsa16LZ1deJ87QMCdgjtvGjeMu5gHT+uYY/NFI5K71vonoKCRxzsDeFdr7dZabwM2Ax2nzJ3oNIoqvJziDP6xeIP3dg4d1I/zD+/HRtso/Jiw9Yca2z83dzMxlPO67XEilZs9vU8Ai62OI8MhvYLDFEf3ad78nt1NjKNmy1z7YvDkzuDOE0aSEuusZy/R3g7mhuotSqlVoW6bqinT+wC7wrbJDC2rRSl1nVIqXSmVnpubexBhiK6osMLDVHMdLkcyd1x0evVyqzOaLc7R1cMYITh70gfLMrnQ/J4o5eJOzw1kTnyo3mM7rCYf3jiZV644vFWvoauIdtTuYrrrxKHtEIloiuYm938Bg4AxwB7g7009gNb6P1rrCVrrCcnJyc0MQ3RFOSUuvli1m3GB1TiGTGPG6H11wqOdVtLtEyFnHRRuB2BzThnFZeX8LnouRb2msDFlJmMHH7hK4fj+CTVqvIj6Re13/+CYocncMn1IO0UjGqtZyV1rna219mutA8BL7Ot6yQL6hm2aGlomRKM9MWcjQ1QW8YHCWv3m2cUuXsgejh+Tne/fg9tVwca9pcw0FuJ05RB33B18cetRXeqGZnuzmDXTxMmjpNRAZ9Cs5K6USgl7exZQNZLmM+ACpZRdKTUAGAIsObgQRVe3q6CixkM/uWVuTjDSg28GHF1j270lLjJ1D571nkW/3bPJeGwy3yxdw/XWL9FJh8Dg49sy9G7jf2FdWIfVUSFSdDyNGQr5DrAQGKaUylRKXQ08qZRarZRaBRwL3A6gtV4LvAesA+YAN2utG36kUHRLPn+AO2at4Kgn5/H7t+ZDwM/Dn61l+aYd3GSfDYOOg/ia48WfOjc4+cVz/rO523sdQ1Qm/8w6n0PUTtRRtzerJoxo2LGH9KBXjAOo3U0jOqYGPyWt9YV1LH75ANs/Cjx6MEGJ7mH5ziI++jWTa80vuWfrO5Q9O4Sfc67lfsuXRAVK4bgHau1zzvjU6inf3vdPY0ugN7+3zmLwhBkkjT6vrS+hW/H4g39d1TWXquh4pPyAaBfrdpdw1atLOdNYwH3Wt1muh+ArymKu/W4usPyAf+LN0PvA488zHj2Z0ZNO4OGEJ0k49SEw5Me5NY3sHQNAhE2Se2egtNbtHQMTJkzQ6enp7R2GaGWBgMbjD7C32MX0p75nprGQR62v4EwdxZnl91OcvZVLze+44qJLsY04ud7j5JW5qfT4qx9GEm2jxOUlI7uM8f3jG95YtAml1DKtdZ2T70rnmWgzA//4FaAZqXbwhvUtjjTXku/oR/SZL/Bp4hBemNcHu3M6thFpBzxOUged1KKri3FYJbF3IpLcRRvS/NnyPy61fIcbK9uOeJgBJ90KpgUTuPU4GTstREuR5C5aXanLyyUvL+EkI51LLd9RMPIK4k++nwFR8vCaEK1FkrtodXe8t5Ldu7bzov1V3PFDSTj772DKj54QrUn+h4lWtSqziG/XZfO683/0NF2o816WxC5EG5CxY6JVrcosZpDK4mi9FDX1dkg5tL1DEqJb6NTJfUd+Ode8tpTiCm+922SXuHhyzgZ8/q4zp2VnUeb2cf8na7jE/A5t2mBC8+YmFUI0XadO7ltzy/lufQ5/+nxtvds8PnsDL/ywhZ8ypKxwW3tr0Q5M/JzvWIQ6ZCbIDVQh2kynTu7HHtIDgI9+zeLbddl1buPyBkvb5Ja62ywuEbRoaz5nJ2wnwlcMo85u73CE6FY6dXIH+PDGyQBc+3o6j3y+jszCClZlFlWv31viAqDMLfXL2tLCLfnM25jLbxzpYI2Uao1CtLFOn9zH90/g7pOGAfDKgm1MfWIep/9zAdvyytFaszm7DIByt689w+x2VuwqQhFgfOUvMPREsMp0bEK0pU6f3AGumJJGSqyjxrJjn/qB295dQWkoqZdJcm9THl+A4Won1spcGHJSe4cjRLfTJZJ7pN3CwnuPY/0jM3j58n01dD5bubv69ew1e9ojtG6r0uvnaMu64JuB09o1FiG6oy6R3Ks4bSbHDe/JkB5RNZZfNrk/uwoqWbmrqH0C64ZcXj9TzTWQNAxiUhreQQjRorpUcq/y1W1H8fR5wRl7+sQ5OXV0MLmc8X8LaG6J4xKXlzvfW8nuosoWi7Or8vgCbMzKYzzrYeAxDe8ghGhxXTK5W02D1Ph9tb7H94+v7pPfmF3arGP+uDGXD5dnMuXx71skxq7skS/WErNrHk7c0iUjRDvpkskdICHSBgSn1LSYBq9fdQQAP2zMJauJrW+tNbe+8yu9yeNL273snvtCi8fbFWzYW8Kd761k2eKfecr6byoscZA2tb3DEqJb6rIVnPonRnDM0GRunT4Y2DfBw+OzN/D47A1sf/zURh/rujeWAfCg9Q1GGjsI/HwfR3wbQ0rfAUwemMghvaI5c2yflr+IduTzBwhosFka9/s/p8TFjH/8zIXmXD61vYrPHk/EjXPBEdvKkQoh6tJlk7vVNHgt1FoHiHVaMQ2FPxDsc88pddEj2lHf7jV8uy6beEo4wbKcOb7DmWEu5XeWD3DvsTFw7x4qsFMa/wTRaeNb5Vra0oLNeby9eCc/rMtkkKOUzx64+IDbl7l9bM4pI317Aeeb8/ir9WW8A48j4qx/QXTPNopaCLG/Lpvc92cYioRIW3UZgiMencvKB08kNsIKwJqsYtK3F3DFkQNq7FfpCT7Zeoq5BFP7ec53FomqmIss83BpKw4VLFrmmnUR3LkaLLY2vKqW5fMHuPi/ixmudjDb+jT9/LnopW7U4XUX/FqwOY+L/7uYU4xFnGf+yJXW1TD4eKwXvNOpvw9CdAVdts+9LvvXl1myvaD69czn5/Pw5+v4wweramyXXx58fbr5C574IUT3H8u93mt4x3IGnx79BVNcz3Gr5xYclXthw+dtcyEtZMm2As7798LqqprzNuYSRQWvRT6PTfnYEegBX98LpbXr9mQVVXL5K0u4yJzLC7bnGGlsZ0PC8XDeG5LYhegAulVyNw1V4/3GvSUAFJZ7qpfNSt/FhS8tqn6/aGsBY9RmJhob8I38DccO78lmncq9ZedzwqRxOJP782VgEvlGIqz5qG0upIW8vnA7S7YXcNgj33Dz28v5eVMOf7X+l2R/NgUnv8gV3j+gfC5Y9mqtfW96aznxgUIeiZiFr//RLDj9R4bePAtsEbVPJIRoc90quf9w1zQGJUcCEGW38OovOzjy8e95Y9GOGtttzimrfv3tur38wfIulfYkIiZdjdu7ry58QqSNuXdO46ihPfnJOhUyvgFXcdtcTAuousl8iNrJtRuu4be/nsJp5iLU9PsZdsSJlET0Z7ltPKS/Av59NfMDAc3KXUXcY30Hi9+N5bRnOHP8AKxmt/pxEqJD61b/G/smRPDJzUcy+7aj6J8YQV6Zm6yiSp7+dhMAj541igFJkZiG4t0lOzn0nlkcvvEpJpvrcE65AaJ6kJYUbJk+f+HY6uOO7x/PayXjwe+BDV8eVIyF5R7+t2Abhz/6HXllrVumuKTSSwzlzLI9QqrKZZ5/DHuOfhKO/B2moZh5aArPlU2Hsr3oeX/l8leWkHbPl8zdkMMEtYHfmD/DlFshaXCrximEaLpuc0O1SrTDyvAUK5G22pd+4eH98PoCPPz5Ou75aDW9cHONZTbbHcNJm3IrAKcf1pvBPaIY2XvfEL8hPaJ4Wg8iUyeTuuZDGHNRs2L7bl0217yejg0vd1tmkZNeQNK085p3oY1QWOHhzoT5xFZUsHzGJ0weNpGUsIe/RqfG8drCMXzin8LMBc+zxdWPf1rfYeKsVUy0abyRvbEefVerxSeEaL5u1XIP57SZtZYZhsIX2FeeIJt4DnX9h153zAdrcNikUqpGYgeYMigJUPzkmIbe8j2+bQuaHI/WmmteT2eC2sCHtoe41vIVI364FrLXNflY+yuq8PDknA1c/vznfPv2M5Ab/EuloNzDae4vYeCxjJt0bI2negHOHtsHUDznOxuL9jDffhunmItZEhjGLt0Dyzkvgi3yoOMTQrS8btdyrxKxX3L/4tbgk5STByUCMG1YMkcNSeaqI9NQStXaP1xshJWjhiTxWMZJHGn7kfi3LyPm7tVNurmYV+bBgZtnbf9HAqX8n+90rnL8gPOb++DSj5t4dftorZny+PfEeHL43H4/yfnFBDY/ytuRl5GYH0+CLQ9Gn1vnvoahSIqysbWsN6/5TmC6bT2RJ93PNR/HcPXUAYwcMKLZcQkhWle3Te7hLfdx/eIY1SfYGh/ZO7ZJT69WcfsClBHBXd4beN94BJa/DpNuaNS+Xn+Ax2dv4HrzC/qofOZPfZ2XF0aQXxnLg1vegO0LIO3IJscEsKugEo/HzT9tzxNn8XJV5V1cb/mCS0pf5pKqEYsDjqp3/3l3TWP0w9/wkO9K1o/ty+MTD2X7xGaFIoRoQ922W6aq5X7hEX2Zdf3kgz9gqDdnqT6EZYEh6F9fb9RuRRUeJv/1e7b+Oo+bLJ9SOmgmU48/g9MOTeFd/7EEMGDrD80KKbfUzdF/m8cZxi9MMDZhPeNZjj39Mi713Mstnlsp0RHsTJwKcf3qPUa0w1o901VdXVlCiI6p27bcox3BJ1OTouwtMoTvmQvG8NOmXFZlFjF32VjGZ78HlYXgjD/gfst2FOIty+dV+xPkEUvSjL8A8MDMESzeVsC2kn4MzFrGgTuG6vafn7YAmistc9DJw1Gjz+ViHRwl8/S3Nr5zj+Mf0yZSf2oPOndCKou25nPjtEHNiEII0R66bcvdGnqgyeMLNLBl4/SJc3LhEf244PB+rNChoYFZyw64z4+bclmdVcwNls+JUZUELpyFPTlY/sBiGlx4RD+WeAagM5dBM+rQL9pawOFqI6OM7aiJ14NSGIbi5mMHMzwlGhd2kmMantu0R7SDN66e2OhaPEKI9tdgcldKvaKUylFKrQlblqCU+lYplRH6Nz60XCmlnlNKbVZKrVJKjWvN4A/GiSN7EW238JvxqS163D7xTlYGBuE3bLDp63onB9mUXcrlryzhre+WcqXla9Toc+h7yOE1tomPtLFCD8ZwF0HB1ibHsrfExf1JP4EjDg49v8a6244bCsDgHtFNPq4QouNrTMv9VWDGfsvuAeZqrYcAc0PvAU4GhoS+rgP+1TJhtrxRfWJZ/aeTGNqzZZNbQoQNtxHBxvhjCaycxeh7P+CTX7Nqbbd4az5OXLxg+wdWFYBp99baJsJqsjIQ6grJTK9eviO/HJfX32AsNlc+o8p+hrGX1Bq5c8KInmx//FRindYmXqEQojNoMLlrrX8CCvZbfAbwWuj1a8CZYctf10GLgDilVLeaQDM4fNDOPbunol0l3Gl5n4dmza+13ZuLdnKz5VPGGxlUnPYiJNbuz46wmWzSqfgtEdVdPHllbo77+4+c9+JC3pu/mg1L50KgZtfSj5tyOf0f33OzfgdT+2Hspa1zsUKIDqu5fe49tdZ7Qq/3AlWFu/sAu8K2ywwtq0UpdZ1SKl0plZ6bm9vMMDqmxCgbq/Qg3vcfw5WWr1npuA4Kg/VrNu4tpdLjp7w4n2ts32GMOIPocefUeRynzSSAQUn8KMgKttyX7yjEH/AzYc+7nPTtiRzy5dnw0rTqmjYur58rXlnEXfkPcpFlHjnRI6HHIW1y3UKIjuOgb6jqYKdyk+/2aa3/o7WeoLWekJycfLBhdCjlbh8AT/nOZ32gLwCVr55N5Y5lnPSPnzjmb/O40PcRjkA5HODx/Uh7cDBTftwo2LsaPBX8uquI35g/86D1DVYGBvGU91wCe1bD2xeAq5j/LdjOjeZnHG2u5gv/RH4e8XCrX68QouNpbnLPrupuCf2bE1qeBfQN2y41tKxbSQxVW8wjlpM9T3CX93oo2onl1RnMsf2BHzwXcbPlM3b1nA69Rtd7nKp5YDfHTAoWJcv4muU7CrnWOY+SqIFUnPc+//Sfxe88NxHYuZDtb9xM2beP83vre2xMPpFbvL+lPG5om1yzEKJjaW5y/wy4PPT6cuDTsOWXhUbNTAKKw7pvuo3Hzx7NU+ceVl058gP/MRztfoalvsEcYuxine7P/d4r6XHFgR90SogIJvebFkTgi+yFe/HLlG1fzjDfJmKmXseM0Sn8dvpgPgtM4R3fdNKyPudu63tkp85g6HVv8Pa1kzj/8L4HPIcQomtS9Q3Vq95AqXeAaUASkA08BHwCvAf0A3YA52mtC1SwCMs/CY6uqQCu1Fqn13HYGiZMmKDT0xvcrFO6470VfLQ8+MeLiZ/xahPpehiPnHkol0zq3+D+afcESwjfaP2SP5hvUaQjibQZWO9YDc54ckpcHPHYXOx4OMZYydQxI7js3HOhgXo4QojOTym1TGs9oc51DSX3ttCVk/sXq3Zzy9u/cvdJw5izZi9HDEjggZmNL7j15qId3P/JGqKpYLb9HuIow3nui5ijzqzeZuWuIs74v2AlyubUxRFCdE4HSu7dtvxAW5l5aG9OGtkLq2lw87FNn9Tikkn9GdM3jpnPz2e6++/87ZxRnDGq5nGG9QqO1T/9sN4tErMQovOT5N4GDrZ2zag+scwY2Ys5a/eSEBtba73DarLw3unER8jE1EKIIEnuncQdJw5lYHIkkwYm1rk+JbbhGjFCiO5DknsnMbRnNL+fIQ8jCSEap9tWhRRCiK5MkrsQQnRBktyFEKILkuQuhBBdkCR3IYTogiS5CyFEFyTJXQghuiBJ7kII0QV1iMJhSqlcgtUlmyMJyGvBcNpDZ7+Gzh4/dP5r6OzxQ+e/hvaIv7/Wus7ZjjpEcj8YSqn0+qqidRad/Ro6e/zQ+a+hs8cPnf8aOlr80i0jhBBdkCR3IYTogrpCcv9PewfQAjr7NXT2+KHzX0Nnjx86/zV0qPg7fZ+7EEKI2rpCy10IIcR+JLkLIUQX1KmTu1JqhlJqo1Jqs1LqnvaOpy5Kqb5KqXlKqXVKqbVKqdtCyxOUUt8qpTJC/8aHliul1HOha1qllBrXvlcQpJQylVK/KqW+CL0foJRaHIpzllLKFlpuD73fHFqf1q6Bhyil4pRSHyilNiil1iulJnemz0ApdXvo52eNUuodpZSjo38GSqlXlFI5Sqk1Ycua/D1XSl0e2j5DKXV5O8f/t9DP0Cql1MdKqbiwdfeG4t+olDopbHn75Cmtdaf8AkxgCzAQsAErgRHtHVcdcaYA40Kvo4FNwAjgSeCe0PJ7gCdCr08BZgMKmAQsbu9rCMV1B/A28EXo/XvABaHX/wZuDL2+Cfh36PUFwKz2jj0Uy2vANaHXNiCus3wGQB9gG+AM+95f0dE/A+BoYBywJmxZk77nQAKwNfRvfOh1fDvGfyJgCb1+Iiz+EaEcZAcGhHKT2Z55qt1+YFvgGz8Z+Drs/b3Ave0dVyPi/hQ4AdgIpISWpQAbQ69fBC4M2756u3aMORWYC0wHvgj9B8wL+yGv/iyAr4HJodeW0HaqneOPDSVHtd/yTvEZhJL7rlCCs4Q+g5M6w2cApO2XHJv0PQcuBF4MW15ju7aOf791ZwFvhV7XyD9Vn0F75qnO3C1T9QNfJTO0rMMK/Xk8FlgM9NRa7wmt2gv0DL3uiNf1D+D3QCD0PhEo0lr7Qu/DY6yOP7S+OLR9exoA5AL/C3Ut/VcpFUkn+Qy01lnAU8BOYA/B7+kyOtdnUKWp3/MO9Vns5yqCf21AB4y/Myf3TkUpFQV8CPxOa10Svk4Hf6V3yDGpSqmZQI7Well7x3IQLAT/vP6X1nosUE6wS6BaB/8M4oEzCP6S6g1EAjPaNagW0JG/5w1RSt0H+IC32juW+nTm5J4F9A17nxpa1uEopawEE/tbWuuPQouzlVIpofUpQE5oeUe7riOB05VS24F3CXbNPAvEKaUsoW3CY6yOP7Q+Fshvy4DrkAlkaq0Xh95/QDDZd5bP4Hhgm9Y6V2vtBT4i+Ll0ps+gSlO/5x3ts0ApdQUwE7g49AsKOmD8nTm5LwWGhEYM2AjeOPqsnWOqRSmlgJeB9Vrrp8NWfQZU3fm/nGBffNXyy0KjByYBxWF/xrY5rfW9WutUrXUawe/x91rri4F5wDmhzfaPv+q6zglt366tM631XmCXUmpYaNFxwDo6yWdAsDtmklIqIvTzVBV/p/kMwjT1e/41cKJSKj70F8yJoWXtQik1g2AX5ela64qwVZ8BF4RGKg0AhgBLaM881VY3JlrpZscpBEefbAHua+946olxKsE/PVcBK0JfpxDsA50LZADfAQmh7RXwf6FrWg1MaO9rCLuWaewbLTOQ4A/vZuB9wB5a7gi93xxaP7C94w7FNQZID30OnxAcedFpPgPgT8AGYA3wBsFRGR36MwDeIXiPwEvwr6erm/M9J9i3vTn0dWU7x7+ZYB961f/lf4dtf18o/o3AyWHL2yVPSfkBIYTogjpzt4wQQoh6SHIXQoguSJK7EEJ0QZLchRCiC5LkLoQQXZAkdyGE6IIkuQshRBf0/zw1n04NvjuDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "look_back=100\n",
    "trainPredictPlot = numpy.empty_like(df1)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(df1)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(df1))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "696abd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5948ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t2=y_train.reshape(y_train.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94caa770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6e4c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t2=scaler.inverse_transform(y_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "572732cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72071a5",
   "metadata": {},
   "source": [
    "Best possible Training score...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e55b0f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874776045865374"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_t2,train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24d024ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t3=ytest.reshape(ytest.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4f81f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34ceaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t3=scaler.inverse_transform(y_t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ee6a1",
   "metadata": {},
   "source": [
    "Best possible Testing score...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cdc5a4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705117611433354"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_t3,test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9d43909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input=test_data[341:].reshape(1,-1)\n",
    "x_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83a38f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input=test_data[341:].reshape(1,-1)\n",
    "x_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c02a3496",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input=list(x_input)\n",
    "temp_input=temp_input[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff46d5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bff45806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8583551465000423,\n",
       " 0.8866418981676942,\n",
       " 0.8743139407244789,\n",
       " 0.8843198513890065,\n",
       " 0.8783669678290975,\n",
       " 0.8986321033521913,\n",
       " 0.925821160179009,\n",
       " 0.9287764924427933,\n",
       " 0.9567677108840666,\n",
       " 0.9386979650426415,\n",
       " 0.933040614709111,\n",
       " 0.9495060373216249,\n",
       " 0.9642404796082076,\n",
       " 0.9551211686228154,\n",
       " 0.9598919192772104,\n",
       " 0.9663514312251966,\n",
       " 0.9624672802499368,\n",
       " 0.9229502659799038,\n",
       " 0.9598497002448705,\n",
       " 0.9879253567508233,\n",
       " 0.985941062230854,\n",
       " 0.9253145317909315,\n",
       " 0.9217259140420504,\n",
       " 0.964747107996285,\n",
       " 0.9757240564046274,\n",
       " 0.9915984125643842,\n",
       " 0.9697289538123788,\n",
       " 0.9761462467280253,\n",
       " 0.9679557544541082,\n",
       " 1.0000000000000002,\n",
       " 0.9901629654648318,\n",
       " 0.9905007177235499,\n",
       " 0.9653803934813816,\n",
       " 0.9848855864223593,\n",
       " 0.9708688676855528,\n",
       " 0.9402600692392133,\n",
       " 0.8774803681499621,\n",
       " 0.8348391454867856,\n",
       " 0.8541332432660644,\n",
       " 0.7733682344000676,\n",
       " 0.7726927298826314,\n",
       " 0.8801401671873683,\n",
       " 0.8400743054969182,\n",
       " 0.8967322468969012,\n",
       " 0.8552731571392387,\n",
       " 0.8388499535590646,\n",
       " 0.7423372456303303,\n",
       " 0.8232711306256861,\n",
       " 0.7814320695769654,\n",
       " 0.6665963016127672,\n",
       " 0.7921557037912694,\n",
       " 0.6411804441442204,\n",
       " 0.6861437135860848,\n",
       " 0.6600101325677616,\n",
       " 0.6520307354555435,\n",
       " 0.5864223591995272,\n",
       " 0.5658616904500551,\n",
       " 0.660896732246897,\n",
       " 0.6551549438486872,\n",
       " 0.7097019336316812,\n",
       " 0.664527569028118,\n",
       " 0.6943764248923416,\n",
       " 0.692181035210673,\n",
       " 0.6356919699400492,\n",
       " 0.6526640209406402,\n",
       " 0.637802921557038,\n",
       " 0.7267162036646122,\n",
       " 0.7138816178333194,\n",
       " 0.7419150553069325,\n",
       " 0.7500211095161702,\n",
       " 0.7722283205268936,\n",
       " 0.8304905851557884,\n",
       " 0.8194291986827664,\n",
       " 0.8289706999915563,\n",
       " 0.8125474964113824,\n",
       " 0.7877649244279323,\n",
       " 0.7516254327450818,\n",
       " 0.7842607447437306,\n",
       " 0.7797433082833742,\n",
       " 0.8132652199611587,\n",
       " 0.8141096006079542,\n",
       " 0.7947310647639958,\n",
       " 0.8333614793548934,\n",
       " 0.8589884319851391,\n",
       " 0.8390188296884238,\n",
       " 0.8562864139153934,\n",
       " 0.8748627881448958,\n",
       " 0.887824031073208,\n",
       " 0.9009541501308793,\n",
       " 0.9279321117959978,\n",
       " 0.9485349995778098,\n",
       " 0.9333361479354896,\n",
       " 0.9174617917757326,\n",
       " 0.925441188887951,\n",
       " 0.9177151059697712,\n",
       " 0.9483239044161109,\n",
       " 0.9406400405302711,\n",
       " 0.9663514312251966,\n",
       " 0.9563033015283293,\n",
       " 0.964915984125644]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31decf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96207416]\n",
      "101\n",
      "1 day input [0.8866419  0.87431394 0.88431985 0.87836697 0.8986321  0.92582116\n",
      " 0.92877649 0.95676771 0.93869797 0.93304061 0.94950604 0.96424048\n",
      " 0.95512117 0.95989192 0.96635143 0.96246728 0.92295027 0.9598497\n",
      " 0.98792536 0.98594106 0.92531453 0.92172591 0.96474711 0.97572406\n",
      " 0.99159841 0.96972895 0.97614625 0.96795575 1.         0.99016297\n",
      " 0.99050072 0.96538039 0.98488559 0.97086887 0.94026007 0.87748037\n",
      " 0.83483915 0.85413324 0.77336823 0.77269273 0.88014017 0.84007431\n",
      " 0.89673225 0.85527316 0.83884995 0.74233725 0.82327113 0.78143207\n",
      " 0.6665963  0.7921557  0.64118044 0.68614371 0.66001013 0.65203074\n",
      " 0.58642236 0.56586169 0.66089673 0.65515494 0.70970193 0.66452757\n",
      " 0.69437642 0.69218104 0.63569197 0.65266402 0.63780292 0.7267162\n",
      " 0.71388162 0.74191506 0.75002111 0.77222832 0.83049059 0.8194292\n",
      " 0.8289707  0.8125475  0.78776492 0.75162543 0.78426074 0.77974331\n",
      " 0.81326522 0.8141096  0.79473106 0.83336148 0.85898843 0.83901883\n",
      " 0.85628641 0.87486279 0.88782403 0.90095415 0.92793211 0.948535\n",
      " 0.93333615 0.91746179 0.92544119 0.91771511 0.9483239  0.94064004\n",
      " 0.96635143 0.9563033  0.96491598 0.96207416]\n",
      "1 day output [[0.9662669]]\n",
      "2 day input [0.87431394 0.88431985 0.87836697 0.8986321  0.92582116 0.92877649\n",
      " 0.95676771 0.93869797 0.93304061 0.94950604 0.96424048 0.95512117\n",
      " 0.95989192 0.96635143 0.96246728 0.92295027 0.9598497  0.98792536\n",
      " 0.98594106 0.92531453 0.92172591 0.96474711 0.97572406 0.99159841\n",
      " 0.96972895 0.97614625 0.96795575 1.         0.99016297 0.99050072\n",
      " 0.96538039 0.98488559 0.97086887 0.94026007 0.87748037 0.83483915\n",
      " 0.85413324 0.77336823 0.77269273 0.88014017 0.84007431 0.89673225\n",
      " 0.85527316 0.83884995 0.74233725 0.82327113 0.78143207 0.6665963\n",
      " 0.7921557  0.64118044 0.68614371 0.66001013 0.65203074 0.58642236\n",
      " 0.56586169 0.66089673 0.65515494 0.70970193 0.66452757 0.69437642\n",
      " 0.69218104 0.63569197 0.65266402 0.63780292 0.7267162  0.71388162\n",
      " 0.74191506 0.75002111 0.77222832 0.83049059 0.8194292  0.8289707\n",
      " 0.8125475  0.78776492 0.75162543 0.78426074 0.77974331 0.81326522\n",
      " 0.8141096  0.79473106 0.83336148 0.85898843 0.83901883 0.85628641\n",
      " 0.87486279 0.88782403 0.90095415 0.92793211 0.948535   0.93333615\n",
      " 0.91746179 0.92544119 0.91771511 0.9483239  0.94064004 0.96635143\n",
      " 0.9563033  0.96491598 0.96207416 0.96626687]\n",
      "2 day output [[0.9703974]]\n",
      "3 day input [0.88431985 0.87836697 0.8986321  0.92582116 0.92877649 0.95676771\n",
      " 0.93869797 0.93304061 0.94950604 0.96424048 0.95512117 0.95989192\n",
      " 0.96635143 0.96246728 0.92295027 0.9598497  0.98792536 0.98594106\n",
      " 0.92531453 0.92172591 0.96474711 0.97572406 0.99159841 0.96972895\n",
      " 0.97614625 0.96795575 1.         0.99016297 0.99050072 0.96538039\n",
      " 0.98488559 0.97086887 0.94026007 0.87748037 0.83483915 0.85413324\n",
      " 0.77336823 0.77269273 0.88014017 0.84007431 0.89673225 0.85527316\n",
      " 0.83884995 0.74233725 0.82327113 0.78143207 0.6665963  0.7921557\n",
      " 0.64118044 0.68614371 0.66001013 0.65203074 0.58642236 0.56586169\n",
      " 0.66089673 0.65515494 0.70970193 0.66452757 0.69437642 0.69218104\n",
      " 0.63569197 0.65266402 0.63780292 0.7267162  0.71388162 0.74191506\n",
      " 0.75002111 0.77222832 0.83049059 0.8194292  0.8289707  0.8125475\n",
      " 0.78776492 0.75162543 0.78426074 0.77974331 0.81326522 0.8141096\n",
      " 0.79473106 0.83336148 0.85898843 0.83901883 0.85628641 0.87486279\n",
      " 0.88782403 0.90095415 0.92793211 0.948535   0.93333615 0.91746179\n",
      " 0.92544119 0.91771511 0.9483239  0.94064004 0.96635143 0.9563033\n",
      " 0.96491598 0.96207416 0.96626687 0.97039741]\n",
      "3 day output [[0.9743352]]\n",
      "4 day input [0.87836697 0.8986321  0.92582116 0.92877649 0.95676771 0.93869797\n",
      " 0.93304061 0.94950604 0.96424048 0.95512117 0.95989192 0.96635143\n",
      " 0.96246728 0.92295027 0.9598497  0.98792536 0.98594106 0.92531453\n",
      " 0.92172591 0.96474711 0.97572406 0.99159841 0.96972895 0.97614625\n",
      " 0.96795575 1.         0.99016297 0.99050072 0.96538039 0.98488559\n",
      " 0.97086887 0.94026007 0.87748037 0.83483915 0.85413324 0.77336823\n",
      " 0.77269273 0.88014017 0.84007431 0.89673225 0.85527316 0.83884995\n",
      " 0.74233725 0.82327113 0.78143207 0.6665963  0.7921557  0.64118044\n",
      " 0.68614371 0.66001013 0.65203074 0.58642236 0.56586169 0.66089673\n",
      " 0.65515494 0.70970193 0.66452757 0.69437642 0.69218104 0.63569197\n",
      " 0.65266402 0.63780292 0.7267162  0.71388162 0.74191506 0.75002111\n",
      " 0.77222832 0.83049059 0.8194292  0.8289707  0.8125475  0.78776492\n",
      " 0.75162543 0.78426074 0.77974331 0.81326522 0.8141096  0.79473106\n",
      " 0.83336148 0.85898843 0.83901883 0.85628641 0.87486279 0.88782403\n",
      " 0.90095415 0.92793211 0.948535   0.93333615 0.91746179 0.92544119\n",
      " 0.91771511 0.9483239  0.94064004 0.96635143 0.9563033  0.96491598\n",
      " 0.96207416 0.96626687 0.97039741 0.97433519]\n",
      "4 day output [[0.9782079]]\n",
      "5 day input [0.8986321  0.92582116 0.92877649 0.95676771 0.93869797 0.93304061\n",
      " 0.94950604 0.96424048 0.95512117 0.95989192 0.96635143 0.96246728\n",
      " 0.92295027 0.9598497  0.98792536 0.98594106 0.92531453 0.92172591\n",
      " 0.96474711 0.97572406 0.99159841 0.96972895 0.97614625 0.96795575\n",
      " 1.         0.99016297 0.99050072 0.96538039 0.98488559 0.97086887\n",
      " 0.94026007 0.87748037 0.83483915 0.85413324 0.77336823 0.77269273\n",
      " 0.88014017 0.84007431 0.89673225 0.85527316 0.83884995 0.74233725\n",
      " 0.82327113 0.78143207 0.6665963  0.7921557  0.64118044 0.68614371\n",
      " 0.66001013 0.65203074 0.58642236 0.56586169 0.66089673 0.65515494\n",
      " 0.70970193 0.66452757 0.69437642 0.69218104 0.63569197 0.65266402\n",
      " 0.63780292 0.7267162  0.71388162 0.74191506 0.75002111 0.77222832\n",
      " 0.83049059 0.8194292  0.8289707  0.8125475  0.78776492 0.75162543\n",
      " 0.78426074 0.77974331 0.81326522 0.8141096  0.79473106 0.83336148\n",
      " 0.85898843 0.83901883 0.85628641 0.87486279 0.88782403 0.90095415\n",
      " 0.92793211 0.948535   0.93333615 0.91746179 0.92544119 0.91771511\n",
      " 0.9483239  0.94064004 0.96635143 0.9563033  0.96491598 0.96207416\n",
      " 0.96626687 0.97039741 0.97433519 0.97820789]\n",
      "5 day output [[0.98194015]]\n",
      "6 day input [0.92582116 0.92877649 0.95676771 0.93869797 0.93304061 0.94950604\n",
      " 0.96424048 0.95512117 0.95989192 0.96635143 0.96246728 0.92295027\n",
      " 0.9598497  0.98792536 0.98594106 0.92531453 0.92172591 0.96474711\n",
      " 0.97572406 0.99159841 0.96972895 0.97614625 0.96795575 1.\n",
      " 0.99016297 0.99050072 0.96538039 0.98488559 0.97086887 0.94026007\n",
      " 0.87748037 0.83483915 0.85413324 0.77336823 0.77269273 0.88014017\n",
      " 0.84007431 0.89673225 0.85527316 0.83884995 0.74233725 0.82327113\n",
      " 0.78143207 0.6665963  0.7921557  0.64118044 0.68614371 0.66001013\n",
      " 0.65203074 0.58642236 0.56586169 0.66089673 0.65515494 0.70970193\n",
      " 0.66452757 0.69437642 0.69218104 0.63569197 0.65266402 0.63780292\n",
      " 0.7267162  0.71388162 0.74191506 0.75002111 0.77222832 0.83049059\n",
      " 0.8194292  0.8289707  0.8125475  0.78776492 0.75162543 0.78426074\n",
      " 0.77974331 0.81326522 0.8141096  0.79473106 0.83336148 0.85898843\n",
      " 0.83901883 0.85628641 0.87486279 0.88782403 0.90095415 0.92793211\n",
      " 0.948535   0.93333615 0.91746179 0.92544119 0.91771511 0.9483239\n",
      " 0.94064004 0.96635143 0.9563033  0.96491598 0.96207416 0.96626687\n",
      " 0.97039741 0.97433519 0.97820789 0.98194015]\n",
      "6 day output [[0.9855124]]\n",
      "7 day input [0.92877649 0.95676771 0.93869797 0.93304061 0.94950604 0.96424048\n",
      " 0.95512117 0.95989192 0.96635143 0.96246728 0.92295027 0.9598497\n",
      " 0.98792536 0.98594106 0.92531453 0.92172591 0.96474711 0.97572406\n",
      " 0.99159841 0.96972895 0.97614625 0.96795575 1.         0.99016297\n",
      " 0.99050072 0.96538039 0.98488559 0.97086887 0.94026007 0.87748037\n",
      " 0.83483915 0.85413324 0.77336823 0.77269273 0.88014017 0.84007431\n",
      " 0.89673225 0.85527316 0.83884995 0.74233725 0.82327113 0.78143207\n",
      " 0.6665963  0.7921557  0.64118044 0.68614371 0.66001013 0.65203074\n",
      " 0.58642236 0.56586169 0.66089673 0.65515494 0.70970193 0.66452757\n",
      " 0.69437642 0.69218104 0.63569197 0.65266402 0.63780292 0.7267162\n",
      " 0.71388162 0.74191506 0.75002111 0.77222832 0.83049059 0.8194292\n",
      " 0.8289707  0.8125475  0.78776492 0.75162543 0.78426074 0.77974331\n",
      " 0.81326522 0.8141096  0.79473106 0.83336148 0.85898843 0.83901883\n",
      " 0.85628641 0.87486279 0.88782403 0.90095415 0.92793211 0.948535\n",
      " 0.93333615 0.91746179 0.92544119 0.91771511 0.9483239  0.94064004\n",
      " 0.96635143 0.9563033  0.96491598 0.96207416 0.96626687 0.97039741\n",
      " 0.97433519 0.97820789 0.98194015 0.98551238]\n",
      "7 day output [[0.9890374]]\n",
      "8 day input [0.95676771 0.93869797 0.93304061 0.94950604 0.96424048 0.95512117\n",
      " 0.95989192 0.96635143 0.96246728 0.92295027 0.9598497  0.98792536\n",
      " 0.98594106 0.92531453 0.92172591 0.96474711 0.97572406 0.99159841\n",
      " 0.96972895 0.97614625 0.96795575 1.         0.99016297 0.99050072\n",
      " 0.96538039 0.98488559 0.97086887 0.94026007 0.87748037 0.83483915\n",
      " 0.85413324 0.77336823 0.77269273 0.88014017 0.84007431 0.89673225\n",
      " 0.85527316 0.83884995 0.74233725 0.82327113 0.78143207 0.6665963\n",
      " 0.7921557  0.64118044 0.68614371 0.66001013 0.65203074 0.58642236\n",
      " 0.56586169 0.66089673 0.65515494 0.70970193 0.66452757 0.69437642\n",
      " 0.69218104 0.63569197 0.65266402 0.63780292 0.7267162  0.71388162\n",
      " 0.74191506 0.75002111 0.77222832 0.83049059 0.8194292  0.8289707\n",
      " 0.8125475  0.78776492 0.75162543 0.78426074 0.77974331 0.81326522\n",
      " 0.8141096  0.79473106 0.83336148 0.85898843 0.83901883 0.85628641\n",
      " 0.87486279 0.88782403 0.90095415 0.92793211 0.948535   0.93333615\n",
      " 0.91746179 0.92544119 0.91771511 0.9483239  0.94064004 0.96635143\n",
      " 0.9563033  0.96491598 0.96207416 0.96626687 0.97039741 0.97433519\n",
      " 0.97820789 0.98194015 0.98551238 0.98903739]\n",
      "8 day output [[0.99236226]]\n",
      "9 day input [0.93869797 0.93304061 0.94950604 0.96424048 0.95512117 0.95989192\n",
      " 0.96635143 0.96246728 0.92295027 0.9598497  0.98792536 0.98594106\n",
      " 0.92531453 0.92172591 0.96474711 0.97572406 0.99159841 0.96972895\n",
      " 0.97614625 0.96795575 1.         0.99016297 0.99050072 0.96538039\n",
      " 0.98488559 0.97086887 0.94026007 0.87748037 0.83483915 0.85413324\n",
      " 0.77336823 0.77269273 0.88014017 0.84007431 0.89673225 0.85527316\n",
      " 0.83884995 0.74233725 0.82327113 0.78143207 0.6665963  0.7921557\n",
      " 0.64118044 0.68614371 0.66001013 0.65203074 0.58642236 0.56586169\n",
      " 0.66089673 0.65515494 0.70970193 0.66452757 0.69437642 0.69218104\n",
      " 0.63569197 0.65266402 0.63780292 0.7267162  0.71388162 0.74191506\n",
      " 0.75002111 0.77222832 0.83049059 0.8194292  0.8289707  0.8125475\n",
      " 0.78776492 0.75162543 0.78426074 0.77974331 0.81326522 0.8141096\n",
      " 0.79473106 0.83336148 0.85898843 0.83901883 0.85628641 0.87486279\n",
      " 0.88782403 0.90095415 0.92793211 0.948535   0.93333615 0.91746179\n",
      " 0.92544119 0.91771511 0.9483239  0.94064004 0.96635143 0.9563033\n",
      " 0.96491598 0.96207416 0.96626687 0.97039741 0.97433519 0.97820789\n",
      " 0.98194015 0.98551238 0.98903739 0.99236226]\n",
      "9 day output [[0.99570435]]\n",
      "10 day input [0.93304061 0.94950604 0.96424048 0.95512117 0.95989192 0.96635143\n",
      " 0.96246728 0.92295027 0.9598497  0.98792536 0.98594106 0.92531453\n",
      " 0.92172591 0.96474711 0.97572406 0.99159841 0.96972895 0.97614625\n",
      " 0.96795575 1.         0.99016297 0.99050072 0.96538039 0.98488559\n",
      " 0.97086887 0.94026007 0.87748037 0.83483915 0.85413324 0.77336823\n",
      " 0.77269273 0.88014017 0.84007431 0.89673225 0.85527316 0.83884995\n",
      " 0.74233725 0.82327113 0.78143207 0.6665963  0.7921557  0.64118044\n",
      " 0.68614371 0.66001013 0.65203074 0.58642236 0.56586169 0.66089673\n",
      " 0.65515494 0.70970193 0.66452757 0.69437642 0.69218104 0.63569197\n",
      " 0.65266402 0.63780292 0.7267162  0.71388162 0.74191506 0.75002111\n",
      " 0.77222832 0.83049059 0.8194292  0.8289707  0.8125475  0.78776492\n",
      " 0.75162543 0.78426074 0.77974331 0.81326522 0.8141096  0.79473106\n",
      " 0.83336148 0.85898843 0.83901883 0.85628641 0.87486279 0.88782403\n",
      " 0.90095415 0.92793211 0.948535   0.93333615 0.91746179 0.92544119\n",
      " 0.91771511 0.9483239  0.94064004 0.96635143 0.9563033  0.96491598\n",
      " 0.96207416 0.96626687 0.97039741 0.97433519 0.97820789 0.98194015\n",
      " 0.98551238 0.98903739 0.99236226 0.99570435]\n",
      "10 day output [[0.99900717]]\n",
      "11 day input [0.94950604 0.96424048 0.95512117 0.95989192 0.96635143 0.96246728\n",
      " 0.92295027 0.9598497  0.98792536 0.98594106 0.92531453 0.92172591\n",
      " 0.96474711 0.97572406 0.99159841 0.96972895 0.97614625 0.96795575\n",
      " 1.         0.99016297 0.99050072 0.96538039 0.98488559 0.97086887\n",
      " 0.94026007 0.87748037 0.83483915 0.85413324 0.77336823 0.77269273\n",
      " 0.88014017 0.84007431 0.89673225 0.85527316 0.83884995 0.74233725\n",
      " 0.82327113 0.78143207 0.6665963  0.7921557  0.64118044 0.68614371\n",
      " 0.66001013 0.65203074 0.58642236 0.56586169 0.66089673 0.65515494\n",
      " 0.70970193 0.66452757 0.69437642 0.69218104 0.63569197 0.65266402\n",
      " 0.63780292 0.7267162  0.71388162 0.74191506 0.75002111 0.77222832\n",
      " 0.83049059 0.8194292  0.8289707  0.8125475  0.78776492 0.75162543\n",
      " 0.78426074 0.77974331 0.81326522 0.8141096  0.79473106 0.83336148\n",
      " 0.85898843 0.83901883 0.85628641 0.87486279 0.88782403 0.90095415\n",
      " 0.92793211 0.948535   0.93333615 0.91746179 0.92544119 0.91771511\n",
      " 0.9483239  0.94064004 0.96635143 0.9563033  0.96491598 0.96207416\n",
      " 0.96626687 0.97039741 0.97433519 0.97820789 0.98194015 0.98551238\n",
      " 0.98903739 0.99236226 0.99570435 0.99900717]\n",
      "11 day output [[1.0021989]]\n",
      "12 day input [0.96424048 0.95512117 0.95989192 0.96635143 0.96246728 0.92295027\n",
      " 0.9598497  0.98792536 0.98594106 0.92531453 0.92172591 0.96474711\n",
      " 0.97572406 0.99159841 0.96972895 0.97614625 0.96795575 1.\n",
      " 0.99016297 0.99050072 0.96538039 0.98488559 0.97086887 0.94026007\n",
      " 0.87748037 0.83483915 0.85413324 0.77336823 0.77269273 0.88014017\n",
      " 0.84007431 0.89673225 0.85527316 0.83884995 0.74233725 0.82327113\n",
      " 0.78143207 0.6665963  0.7921557  0.64118044 0.68614371 0.66001013\n",
      " 0.65203074 0.58642236 0.56586169 0.66089673 0.65515494 0.70970193\n",
      " 0.66452757 0.69437642 0.69218104 0.63569197 0.65266402 0.63780292\n",
      " 0.7267162  0.71388162 0.74191506 0.75002111 0.77222832 0.83049059\n",
      " 0.8194292  0.8289707  0.8125475  0.78776492 0.75162543 0.78426074\n",
      " 0.77974331 0.81326522 0.8141096  0.79473106 0.83336148 0.85898843\n",
      " 0.83901883 0.85628641 0.87486279 0.88782403 0.90095415 0.92793211\n",
      " 0.948535   0.93333615 0.91746179 0.92544119 0.91771511 0.9483239\n",
      " 0.94064004 0.96635143 0.9563033  0.96491598 0.96207416 0.96626687\n",
      " 0.97039741 0.97433519 0.97820789 0.98194015 0.98551238 0.98903739\n",
      " 0.99236226 0.99570435 0.99900717 1.00219893]\n",
      "12 day output [[1.005282]]\n",
      "13 day input [0.95512117 0.95989192 0.96635143 0.96246728 0.92295027 0.9598497\n",
      " 0.98792536 0.98594106 0.92531453 0.92172591 0.96474711 0.97572406\n",
      " 0.99159841 0.96972895 0.97614625 0.96795575 1.         0.99016297\n",
      " 0.99050072 0.96538039 0.98488559 0.97086887 0.94026007 0.87748037\n",
      " 0.83483915 0.85413324 0.77336823 0.77269273 0.88014017 0.84007431\n",
      " 0.89673225 0.85527316 0.83884995 0.74233725 0.82327113 0.78143207\n",
      " 0.6665963  0.7921557  0.64118044 0.68614371 0.66001013 0.65203074\n",
      " 0.58642236 0.56586169 0.66089673 0.65515494 0.70970193 0.66452757\n",
      " 0.69437642 0.69218104 0.63569197 0.65266402 0.63780292 0.7267162\n",
      " 0.71388162 0.74191506 0.75002111 0.77222832 0.83049059 0.8194292\n",
      " 0.8289707  0.8125475  0.78776492 0.75162543 0.78426074 0.77974331\n",
      " 0.81326522 0.8141096  0.79473106 0.83336148 0.85898843 0.83901883\n",
      " 0.85628641 0.87486279 0.88782403 0.90095415 0.92793211 0.948535\n",
      " 0.93333615 0.91746179 0.92544119 0.91771511 0.9483239  0.94064004\n",
      " 0.96635143 0.9563033  0.96491598 0.96207416 0.96626687 0.97039741\n",
      " 0.97433519 0.97820789 0.98194015 0.98551238 0.98903739 0.99236226\n",
      " 0.99570435 0.99900717 1.00219893 1.00528204]\n",
      "13 day output [[1.0083563]]\n",
      "14 day input [0.95989192 0.96635143 0.96246728 0.92295027 0.9598497  0.98792536\n",
      " 0.98594106 0.92531453 0.92172591 0.96474711 0.97572406 0.99159841\n",
      " 0.96972895 0.97614625 0.96795575 1.         0.99016297 0.99050072\n",
      " 0.96538039 0.98488559 0.97086887 0.94026007 0.87748037 0.83483915\n",
      " 0.85413324 0.77336823 0.77269273 0.88014017 0.84007431 0.89673225\n",
      " 0.85527316 0.83884995 0.74233725 0.82327113 0.78143207 0.6665963\n",
      " 0.7921557  0.64118044 0.68614371 0.66001013 0.65203074 0.58642236\n",
      " 0.56586169 0.66089673 0.65515494 0.70970193 0.66452757 0.69437642\n",
      " 0.69218104 0.63569197 0.65266402 0.63780292 0.7267162  0.71388162\n",
      " 0.74191506 0.75002111 0.77222832 0.83049059 0.8194292  0.8289707\n",
      " 0.8125475  0.78776492 0.75162543 0.78426074 0.77974331 0.81326522\n",
      " 0.8141096  0.79473106 0.83336148 0.85898843 0.83901883 0.85628641\n",
      " 0.87486279 0.88782403 0.90095415 0.92793211 0.948535   0.93333615\n",
      " 0.91746179 0.92544119 0.91771511 0.9483239  0.94064004 0.96635143\n",
      " 0.9563033  0.96491598 0.96207416 0.96626687 0.97039741 0.97433519\n",
      " 0.97820789 0.98194015 0.98551238 0.98903739 0.99236226 0.99570435\n",
      " 0.99900717 1.00219893 1.00528204 1.00835633]\n",
      "14 day output [[1.0113395]]\n",
      "15 day input [0.96635143 0.96246728 0.92295027 0.9598497  0.98792536 0.98594106\n",
      " 0.92531453 0.92172591 0.96474711 0.97572406 0.99159841 0.96972895\n",
      " 0.97614625 0.96795575 1.         0.99016297 0.99050072 0.96538039\n",
      " 0.98488559 0.97086887 0.94026007 0.87748037 0.83483915 0.85413324\n",
      " 0.77336823 0.77269273 0.88014017 0.84007431 0.89673225 0.85527316\n",
      " 0.83884995 0.74233725 0.82327113 0.78143207 0.6665963  0.7921557\n",
      " 0.64118044 0.68614371 0.66001013 0.65203074 0.58642236 0.56586169\n",
      " 0.66089673 0.65515494 0.70970193 0.66452757 0.69437642 0.69218104\n",
      " 0.63569197 0.65266402 0.63780292 0.7267162  0.71388162 0.74191506\n",
      " 0.75002111 0.77222832 0.83049059 0.8194292  0.8289707  0.8125475\n",
      " 0.78776492 0.75162543 0.78426074 0.77974331 0.81326522 0.8141096\n",
      " 0.79473106 0.83336148 0.85898843 0.83901883 0.85628641 0.87486279\n",
      " 0.88782403 0.90095415 0.92793211 0.948535   0.93333615 0.91746179\n",
      " 0.92544119 0.91771511 0.9483239  0.94064004 0.96635143 0.9563033\n",
      " 0.96491598 0.96207416 0.96626687 0.97039741 0.97433519 0.97820789\n",
      " 0.98194015 0.98551238 0.98903739 0.99236226 0.99570435 0.99900717\n",
      " 1.00219893 1.00528204 1.00835633 1.01133955]\n",
      "15 day output [[1.0142174]]\n",
      "16 day input [0.96246728 0.92295027 0.9598497  0.98792536 0.98594106 0.92531453\n",
      " 0.92172591 0.96474711 0.97572406 0.99159841 0.96972895 0.97614625\n",
      " 0.96795575 1.         0.99016297 0.99050072 0.96538039 0.98488559\n",
      " 0.97086887 0.94026007 0.87748037 0.83483915 0.85413324 0.77336823\n",
      " 0.77269273 0.88014017 0.84007431 0.89673225 0.85527316 0.83884995\n",
      " 0.74233725 0.82327113 0.78143207 0.6665963  0.7921557  0.64118044\n",
      " 0.68614371 0.66001013 0.65203074 0.58642236 0.56586169 0.66089673\n",
      " 0.65515494 0.70970193 0.66452757 0.69437642 0.69218104 0.63569197\n",
      " 0.65266402 0.63780292 0.7267162  0.71388162 0.74191506 0.75002111\n",
      " 0.77222832 0.83049059 0.8194292  0.8289707  0.8125475  0.78776492\n",
      " 0.75162543 0.78426074 0.77974331 0.81326522 0.8141096  0.79473106\n",
      " 0.83336148 0.85898843 0.83901883 0.85628641 0.87486279 0.88782403\n",
      " 0.90095415 0.92793211 0.948535   0.93333615 0.91746179 0.92544119\n",
      " 0.91771511 0.9483239  0.94064004 0.96635143 0.9563033  0.96491598\n",
      " 0.96207416 0.96626687 0.97039741 0.97433519 0.97820789 0.98194015\n",
      " 0.98551238 0.98903739 0.99236226 0.99570435 0.99900717 1.00219893\n",
      " 1.00528204 1.00835633 1.01133955 1.01421738]\n",
      "16 day output [[1.0170141]]\n",
      "17 day input [0.92295027 0.9598497  0.98792536 0.98594106 0.92531453 0.92172591\n",
      " 0.96474711 0.97572406 0.99159841 0.96972895 0.97614625 0.96795575\n",
      " 1.         0.99016297 0.99050072 0.96538039 0.98488559 0.97086887\n",
      " 0.94026007 0.87748037 0.83483915 0.85413324 0.77336823 0.77269273\n",
      " 0.88014017 0.84007431 0.89673225 0.85527316 0.83884995 0.74233725\n",
      " 0.82327113 0.78143207 0.6665963  0.7921557  0.64118044 0.68614371\n",
      " 0.66001013 0.65203074 0.58642236 0.56586169 0.66089673 0.65515494\n",
      " 0.70970193 0.66452757 0.69437642 0.69218104 0.63569197 0.65266402\n",
      " 0.63780292 0.7267162  0.71388162 0.74191506 0.75002111 0.77222832\n",
      " 0.83049059 0.8194292  0.8289707  0.8125475  0.78776492 0.75162543\n",
      " 0.78426074 0.77974331 0.81326522 0.8141096  0.79473106 0.83336148\n",
      " 0.85898843 0.83901883 0.85628641 0.87486279 0.88782403 0.90095415\n",
      " 0.92793211 0.948535   0.93333615 0.91746179 0.92544119 0.91771511\n",
      " 0.9483239  0.94064004 0.96635143 0.9563033  0.96491598 0.96207416\n",
      " 0.96626687 0.97039741 0.97433519 0.97820789 0.98194015 0.98551238\n",
      " 0.98903739 0.99236226 0.99570435 0.99900717 1.00219893 1.00528204\n",
      " 1.00835633 1.01133955 1.01421738 1.01701415]\n",
      "17 day output [[1.0199307]]\n",
      "18 day input [0.9598497  0.98792536 0.98594106 0.92531453 0.92172591 0.96474711\n",
      " 0.97572406 0.99159841 0.96972895 0.97614625 0.96795575 1.\n",
      " 0.99016297 0.99050072 0.96538039 0.98488559 0.97086887 0.94026007\n",
      " 0.87748037 0.83483915 0.85413324 0.77336823 0.77269273 0.88014017\n",
      " 0.84007431 0.89673225 0.85527316 0.83884995 0.74233725 0.82327113\n",
      " 0.78143207 0.6665963  0.7921557  0.64118044 0.68614371 0.66001013\n",
      " 0.65203074 0.58642236 0.56586169 0.66089673 0.65515494 0.70970193\n",
      " 0.66452757 0.69437642 0.69218104 0.63569197 0.65266402 0.63780292\n",
      " 0.7267162  0.71388162 0.74191506 0.75002111 0.77222832 0.83049059\n",
      " 0.8194292  0.8289707  0.8125475  0.78776492 0.75162543 0.78426074\n",
      " 0.77974331 0.81326522 0.8141096  0.79473106 0.83336148 0.85898843\n",
      " 0.83901883 0.85628641 0.87486279 0.88782403 0.90095415 0.92793211\n",
      " 0.948535   0.93333615 0.91746179 0.92544119 0.91771511 0.9483239\n",
      " 0.94064004 0.96635143 0.9563033  0.96491598 0.96207416 0.96626687\n",
      " 0.97039741 0.97433519 0.97820789 0.98194015 0.98551238 0.98903739\n",
      " 0.99236226 0.99570435 0.99900717 1.00219893 1.00528204 1.00835633\n",
      " 1.01133955 1.01421738 1.01701415 1.01993072]\n",
      "18 day output [[1.0226237]]\n",
      "19 day input [0.98792536 0.98594106 0.92531453 0.92172591 0.96474711 0.97572406\n",
      " 0.99159841 0.96972895 0.97614625 0.96795575 1.         0.99016297\n",
      " 0.99050072 0.96538039 0.98488559 0.97086887 0.94026007 0.87748037\n",
      " 0.83483915 0.85413324 0.77336823 0.77269273 0.88014017 0.84007431\n",
      " 0.89673225 0.85527316 0.83884995 0.74233725 0.82327113 0.78143207\n",
      " 0.6665963  0.7921557  0.64118044 0.68614371 0.66001013 0.65203074\n",
      " 0.58642236 0.56586169 0.66089673 0.65515494 0.70970193 0.66452757\n",
      " 0.69437642 0.69218104 0.63569197 0.65266402 0.63780292 0.7267162\n",
      " 0.71388162 0.74191506 0.75002111 0.77222832 0.83049059 0.8194292\n",
      " 0.8289707  0.8125475  0.78776492 0.75162543 0.78426074 0.77974331\n",
      " 0.81326522 0.8141096  0.79473106 0.83336148 0.85898843 0.83901883\n",
      " 0.85628641 0.87486279 0.88782403 0.90095415 0.92793211 0.948535\n",
      " 0.93333615 0.91746179 0.92544119 0.91771511 0.9483239  0.94064004\n",
      " 0.96635143 0.9563033  0.96491598 0.96207416 0.96626687 0.97039741\n",
      " 0.97433519 0.97820789 0.98194015 0.98551238 0.98903739 0.99236226\n",
      " 0.99570435 0.99900717 1.00219893 1.00528204 1.00835633 1.01133955\n",
      " 1.01421738 1.01701415 1.01993072 1.02262366]\n",
      "19 day output [[1.0251327]]\n",
      "20 day input [0.98594106 0.92531453 0.92172591 0.96474711 0.97572406 0.99159841\n",
      " 0.96972895 0.97614625 0.96795575 1.         0.99016297 0.99050072\n",
      " 0.96538039 0.98488559 0.97086887 0.94026007 0.87748037 0.83483915\n",
      " 0.85413324 0.77336823 0.77269273 0.88014017 0.84007431 0.89673225\n",
      " 0.85527316 0.83884995 0.74233725 0.82327113 0.78143207 0.6665963\n",
      " 0.7921557  0.64118044 0.68614371 0.66001013 0.65203074 0.58642236\n",
      " 0.56586169 0.66089673 0.65515494 0.70970193 0.66452757 0.69437642\n",
      " 0.69218104 0.63569197 0.65266402 0.63780292 0.7267162  0.71388162\n",
      " 0.74191506 0.75002111 0.77222832 0.83049059 0.8194292  0.8289707\n",
      " 0.8125475  0.78776492 0.75162543 0.78426074 0.77974331 0.81326522\n",
      " 0.8141096  0.79473106 0.83336148 0.85898843 0.83901883 0.85628641\n",
      " 0.87486279 0.88782403 0.90095415 0.92793211 0.948535   0.93333615\n",
      " 0.91746179 0.92544119 0.91771511 0.9483239  0.94064004 0.96635143\n",
      " 0.9563033  0.96491598 0.96207416 0.96626687 0.97039741 0.97433519\n",
      " 0.97820789 0.98194015 0.98551238 0.98903739 0.99236226 0.99570435\n",
      " 0.99900717 1.00219893 1.00528204 1.00835633 1.01133955 1.01421738\n",
      " 1.01701415 1.01993072 1.02262366 1.02513266]\n",
      "20 day output [[1.0275046]]\n",
      "21 day input [0.92531453 0.92172591 0.96474711 0.97572406 0.99159841 0.96972895\n",
      " 0.97614625 0.96795575 1.         0.99016297 0.99050072 0.96538039\n",
      " 0.98488559 0.97086887 0.94026007 0.87748037 0.83483915 0.85413324\n",
      " 0.77336823 0.77269273 0.88014017 0.84007431 0.89673225 0.85527316\n",
      " 0.83884995 0.74233725 0.82327113 0.78143207 0.6665963  0.7921557\n",
      " 0.64118044 0.68614371 0.66001013 0.65203074 0.58642236 0.56586169\n",
      " 0.66089673 0.65515494 0.70970193 0.66452757 0.69437642 0.69218104\n",
      " 0.63569197 0.65266402 0.63780292 0.7267162  0.71388162 0.74191506\n",
      " 0.75002111 0.77222832 0.83049059 0.8194292  0.8289707  0.8125475\n",
      " 0.78776492 0.75162543 0.78426074 0.77974331 0.81326522 0.8141096\n",
      " 0.79473106 0.83336148 0.85898843 0.83901883 0.85628641 0.87486279\n",
      " 0.88782403 0.90095415 0.92793211 0.948535   0.93333615 0.91746179\n",
      " 0.92544119 0.91771511 0.9483239  0.94064004 0.96635143 0.9563033\n",
      " 0.96491598 0.96207416 0.96626687 0.97039741 0.97433519 0.97820789\n",
      " 0.98194015 0.98551238 0.98903739 0.99236226 0.99570435 0.99900717\n",
      " 1.00219893 1.00528204 1.00835633 1.01133955 1.01421738 1.01701415\n",
      " 1.01993072 1.02262366 1.02513266 1.02750456]\n",
      "21 day output [[1.0300012]]\n",
      "22 day input [0.92172591 0.96474711 0.97572406 0.99159841 0.96972895 0.97614625\n",
      " 0.96795575 1.         0.99016297 0.99050072 0.96538039 0.98488559\n",
      " 0.97086887 0.94026007 0.87748037 0.83483915 0.85413324 0.77336823\n",
      " 0.77269273 0.88014017 0.84007431 0.89673225 0.85527316 0.83884995\n",
      " 0.74233725 0.82327113 0.78143207 0.6665963  0.7921557  0.64118044\n",
      " 0.68614371 0.66001013 0.65203074 0.58642236 0.56586169 0.66089673\n",
      " 0.65515494 0.70970193 0.66452757 0.69437642 0.69218104 0.63569197\n",
      " 0.65266402 0.63780292 0.7267162  0.71388162 0.74191506 0.75002111\n",
      " 0.77222832 0.83049059 0.8194292  0.8289707  0.8125475  0.78776492\n",
      " 0.75162543 0.78426074 0.77974331 0.81326522 0.8141096  0.79473106\n",
      " 0.83336148 0.85898843 0.83901883 0.85628641 0.87486279 0.88782403\n",
      " 0.90095415 0.92793211 0.948535   0.93333615 0.91746179 0.92544119\n",
      " 0.91771511 0.9483239  0.94064004 0.96635143 0.9563033  0.96491598\n",
      " 0.96207416 0.96626687 0.97039741 0.97433519 0.97820789 0.98194015\n",
      " 0.98551238 0.98903739 0.99236226 0.99570435 0.99900717 1.00219893\n",
      " 1.00528204 1.00835633 1.01133955 1.01421738 1.01701415 1.01993072\n",
      " 1.02262366 1.02513266 1.02750456 1.03000116]\n",
      "22 day output [[1.0324119]]\n",
      "23 day input [0.96474711 0.97572406 0.99159841 0.96972895 0.97614625 0.96795575\n",
      " 1.         0.99016297 0.99050072 0.96538039 0.98488559 0.97086887\n",
      " 0.94026007 0.87748037 0.83483915 0.85413324 0.77336823 0.77269273\n",
      " 0.88014017 0.84007431 0.89673225 0.85527316 0.83884995 0.74233725\n",
      " 0.82327113 0.78143207 0.6665963  0.7921557  0.64118044 0.68614371\n",
      " 0.66001013 0.65203074 0.58642236 0.56586169 0.66089673 0.65515494\n",
      " 0.70970193 0.66452757 0.69437642 0.69218104 0.63569197 0.65266402\n",
      " 0.63780292 0.7267162  0.71388162 0.74191506 0.75002111 0.77222832\n",
      " 0.83049059 0.8194292  0.8289707  0.8125475  0.78776492 0.75162543\n",
      " 0.78426074 0.77974331 0.81326522 0.8141096  0.79473106 0.83336148\n",
      " 0.85898843 0.83901883 0.85628641 0.87486279 0.88782403 0.90095415\n",
      " 0.92793211 0.948535   0.93333615 0.91746179 0.92544119 0.91771511\n",
      " 0.9483239  0.94064004 0.96635143 0.9563033  0.96491598 0.96207416\n",
      " 0.96626687 0.97039741 0.97433519 0.97820789 0.98194015 0.98551238\n",
      " 0.98903739 0.99236226 0.99570435 0.99900717 1.00219893 1.00528204\n",
      " 1.00835633 1.01133955 1.01421738 1.01701415 1.01993072 1.02262366\n",
      " 1.02513266 1.02750456 1.03000116 1.03241193]\n",
      "23 day output [[1.0345818]]\n",
      "24 day input [0.97572406 0.99159841 0.96972895 0.97614625 0.96795575 1.\n",
      " 0.99016297 0.99050072 0.96538039 0.98488559 0.97086887 0.94026007\n",
      " 0.87748037 0.83483915 0.85413324 0.77336823 0.77269273 0.88014017\n",
      " 0.84007431 0.89673225 0.85527316 0.83884995 0.74233725 0.82327113\n",
      " 0.78143207 0.6665963  0.7921557  0.64118044 0.68614371 0.66001013\n",
      " 0.65203074 0.58642236 0.56586169 0.66089673 0.65515494 0.70970193\n",
      " 0.66452757 0.69437642 0.69218104 0.63569197 0.65266402 0.63780292\n",
      " 0.7267162  0.71388162 0.74191506 0.75002111 0.77222832 0.83049059\n",
      " 0.8194292  0.8289707  0.8125475  0.78776492 0.75162543 0.78426074\n",
      " 0.77974331 0.81326522 0.8141096  0.79473106 0.83336148 0.85898843\n",
      " 0.83901883 0.85628641 0.87486279 0.88782403 0.90095415 0.92793211\n",
      " 0.948535   0.93333615 0.91746179 0.92544119 0.91771511 0.9483239\n",
      " 0.94064004 0.96635143 0.9563033  0.96491598 0.96207416 0.96626687\n",
      " 0.97039741 0.97433519 0.97820789 0.98194015 0.98551238 0.98903739\n",
      " 0.99236226 0.99570435 0.99900717 1.00219893 1.00528204 1.00835633\n",
      " 1.01133955 1.01421738 1.01701415 1.01993072 1.02262366 1.02513266\n",
      " 1.02750456 1.03000116 1.03241193 1.03458178]\n",
      "24 day output [[1.0366622]]\n",
      "25 day input [0.99159841 0.96972895 0.97614625 0.96795575 1.         0.99016297\n",
      " 0.99050072 0.96538039 0.98488559 0.97086887 0.94026007 0.87748037\n",
      " 0.83483915 0.85413324 0.77336823 0.77269273 0.88014017 0.84007431\n",
      " 0.89673225 0.85527316 0.83884995 0.74233725 0.82327113 0.78143207\n",
      " 0.6665963  0.7921557  0.64118044 0.68614371 0.66001013 0.65203074\n",
      " 0.58642236 0.56586169 0.66089673 0.65515494 0.70970193 0.66452757\n",
      " 0.69437642 0.69218104 0.63569197 0.65266402 0.63780292 0.7267162\n",
      " 0.71388162 0.74191506 0.75002111 0.77222832 0.83049059 0.8194292\n",
      " 0.8289707  0.8125475  0.78776492 0.75162543 0.78426074 0.77974331\n",
      " 0.81326522 0.8141096  0.79473106 0.83336148 0.85898843 0.83901883\n",
      " 0.85628641 0.87486279 0.88782403 0.90095415 0.92793211 0.948535\n",
      " 0.93333615 0.91746179 0.92544119 0.91771511 0.9483239  0.94064004\n",
      " 0.96635143 0.9563033  0.96491598 0.96207416 0.96626687 0.97039741\n",
      " 0.97433519 0.97820789 0.98194015 0.98551238 0.98903739 0.99236226\n",
      " 0.99570435 0.99900717 1.00219893 1.00528204 1.00835633 1.01133955\n",
      " 1.01421738 1.01701415 1.01993072 1.02262366 1.02513266 1.02750456\n",
      " 1.03000116 1.03241193 1.03458178 1.03666222]\n",
      "25 day output [[1.0385636]]\n",
      "26 day input [0.96972895 0.97614625 0.96795575 1.         0.99016297 0.99050072\n",
      " 0.96538039 0.98488559 0.97086887 0.94026007 0.87748037 0.83483915\n",
      " 0.85413324 0.77336823 0.77269273 0.88014017 0.84007431 0.89673225\n",
      " 0.85527316 0.83884995 0.74233725 0.82327113 0.78143207 0.6665963\n",
      " 0.7921557  0.64118044 0.68614371 0.66001013 0.65203074 0.58642236\n",
      " 0.56586169 0.66089673 0.65515494 0.70970193 0.66452757 0.69437642\n",
      " 0.69218104 0.63569197 0.65266402 0.63780292 0.7267162  0.71388162\n",
      " 0.74191506 0.75002111 0.77222832 0.83049059 0.8194292  0.8289707\n",
      " 0.8125475  0.78776492 0.75162543 0.78426074 0.77974331 0.81326522\n",
      " 0.8141096  0.79473106 0.83336148 0.85898843 0.83901883 0.85628641\n",
      " 0.87486279 0.88782403 0.90095415 0.92793211 0.948535   0.93333615\n",
      " 0.91746179 0.92544119 0.91771511 0.9483239  0.94064004 0.96635143\n",
      " 0.9563033  0.96491598 0.96207416 0.96626687 0.97039741 0.97433519\n",
      " 0.97820789 0.98194015 0.98551238 0.98903739 0.99236226 0.99570435\n",
      " 0.99900717 1.00219893 1.00528204 1.00835633 1.01133955 1.01421738\n",
      " 1.01701415 1.01993072 1.02262366 1.02513266 1.02750456 1.03000116\n",
      " 1.03241193 1.03458178 1.03666222 1.03856361]\n",
      "26 day output [[1.0404664]]\n",
      "27 day input [0.97614625 0.96795575 1.         0.99016297 0.99050072 0.96538039\n",
      " 0.98488559 0.97086887 0.94026007 0.87748037 0.83483915 0.85413324\n",
      " 0.77336823 0.77269273 0.88014017 0.84007431 0.89673225 0.85527316\n",
      " 0.83884995 0.74233725 0.82327113 0.78143207 0.6665963  0.7921557\n",
      " 0.64118044 0.68614371 0.66001013 0.65203074 0.58642236 0.56586169\n",
      " 0.66089673 0.65515494 0.70970193 0.66452757 0.69437642 0.69218104\n",
      " 0.63569197 0.65266402 0.63780292 0.7267162  0.71388162 0.74191506\n",
      " 0.75002111 0.77222832 0.83049059 0.8194292  0.8289707  0.8125475\n",
      " 0.78776492 0.75162543 0.78426074 0.77974331 0.81326522 0.8141096\n",
      " 0.79473106 0.83336148 0.85898843 0.83901883 0.85628641 0.87486279\n",
      " 0.88782403 0.90095415 0.92793211 0.948535   0.93333615 0.91746179\n",
      " 0.92544119 0.91771511 0.9483239  0.94064004 0.96635143 0.9563033\n",
      " 0.96491598 0.96207416 0.96626687 0.97039741 0.97433519 0.97820789\n",
      " 0.98194015 0.98551238 0.98903739 0.99236226 0.99570435 0.99900717\n",
      " 1.00219893 1.00528204 1.00835633 1.01133955 1.01421738 1.01701415\n",
      " 1.01993072 1.02262366 1.02513266 1.02750456 1.03000116 1.03241193\n",
      " 1.03458178 1.03666222 1.03856361 1.04046643]\n",
      "27 day output [[1.0422243]]\n",
      "28 day input [0.96795575 1.         0.99016297 0.99050072 0.96538039 0.98488559\n",
      " 0.97086887 0.94026007 0.87748037 0.83483915 0.85413324 0.77336823\n",
      " 0.77269273 0.88014017 0.84007431 0.89673225 0.85527316 0.83884995\n",
      " 0.74233725 0.82327113 0.78143207 0.6665963  0.7921557  0.64118044\n",
      " 0.68614371 0.66001013 0.65203074 0.58642236 0.56586169 0.66089673\n",
      " 0.65515494 0.70970193 0.66452757 0.69437642 0.69218104 0.63569197\n",
      " 0.65266402 0.63780292 0.7267162  0.71388162 0.74191506 0.75002111\n",
      " 0.77222832 0.83049059 0.8194292  0.8289707  0.8125475  0.78776492\n",
      " 0.75162543 0.78426074 0.77974331 0.81326522 0.8141096  0.79473106\n",
      " 0.83336148 0.85898843 0.83901883 0.85628641 0.87486279 0.88782403\n",
      " 0.90095415 0.92793211 0.948535   0.93333615 0.91746179 0.92544119\n",
      " 0.91771511 0.9483239  0.94064004 0.96635143 0.9563033  0.96491598\n",
      " 0.96207416 0.96626687 0.97039741 0.97433519 0.97820789 0.98194015\n",
      " 0.98551238 0.98903739 0.99236226 0.99570435 0.99900717 1.00219893\n",
      " 1.00528204 1.00835633 1.01133955 1.01421738 1.01701415 1.01993072\n",
      " 1.02262366 1.02513266 1.02750456 1.03000116 1.03241193 1.03458178\n",
      " 1.03666222 1.03856361 1.04046643 1.04222429]\n",
      "28 day output [[1.0439646]]\n",
      "29 day input [1.         0.99016297 0.99050072 0.96538039 0.98488559 0.97086887\n",
      " 0.94026007 0.87748037 0.83483915 0.85413324 0.77336823 0.77269273\n",
      " 0.88014017 0.84007431 0.89673225 0.85527316 0.83884995 0.74233725\n",
      " 0.82327113 0.78143207 0.6665963  0.7921557  0.64118044 0.68614371\n",
      " 0.66001013 0.65203074 0.58642236 0.56586169 0.66089673 0.65515494\n",
      " 0.70970193 0.66452757 0.69437642 0.69218104 0.63569197 0.65266402\n",
      " 0.63780292 0.7267162  0.71388162 0.74191506 0.75002111 0.77222832\n",
      " 0.83049059 0.8194292  0.8289707  0.8125475  0.78776492 0.75162543\n",
      " 0.78426074 0.77974331 0.81326522 0.8141096  0.79473106 0.83336148\n",
      " 0.85898843 0.83901883 0.85628641 0.87486279 0.88782403 0.90095415\n",
      " 0.92793211 0.948535   0.93333615 0.91746179 0.92544119 0.91771511\n",
      " 0.9483239  0.94064004 0.96635143 0.9563033  0.96491598 0.96207416\n",
      " 0.96626687 0.97039741 0.97433519 0.97820789 0.98194015 0.98551238\n",
      " 0.98903739 0.99236226 0.99570435 0.99900717 1.00219893 1.00528204\n",
      " 1.00835633 1.01133955 1.01421738 1.01701415 1.01993072 1.02262366\n",
      " 1.02513266 1.02750456 1.03000116 1.03241193 1.03458178 1.03666222\n",
      " 1.03856361 1.04046643 1.04222429 1.04396462]\n",
      "29 day output [[1.0454836]]\n",
      "[[0.9620741605758667], [0.9662668704986572], [0.970397412776947], [0.9743351936340332], [0.9782078862190247], [0.9819401502609253], [0.985512375831604], [0.9890373945236206], [0.9923622608184814], [0.9957043528556824], [0.9990071654319763], [1.0021989345550537], [1.0052820444107056], [1.0083563327789307], [1.011339545249939], [1.0142173767089844], [1.0170141458511353], [1.0199307203292847], [1.0226236581802368], [1.025132656097412], [1.027504563331604], [1.030001163482666], [1.0324119329452515], [1.0345817804336548], [1.036662220954895], [1.03856360912323], [1.0404664278030396], [1.0422242879867554], [1.0439646244049072], [1.0454835891723633]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "lst_output=[]\n",
    "n_steps=100\n",
    "i=0\n",
    "while(i<30):\n",
    "    \n",
    "    if(len(temp_input)>100):\n",
    "        #print(temp_input)\n",
    "        x_input=np.array(temp_input[1:])\n",
    "        print(\"{} day input {}\".format(i,x_input))\n",
    "        x_input=x_input.reshape(1,-1)\n",
    "        x_input = x_input.reshape((1, n_steps, 1))\n",
    "        #print(x_input)\n",
    "        yhat = model[p].predict(x_input, verbose=0)\n",
    "        print(\"{} day output {}\".format(i,yhat))\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        temp_input=temp_input[1:]\n",
    "        #print(temp_input)\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, n_steps,1))\n",
    "        yhat = model[p].predict(x_input, verbose=0)\n",
    "        print(yhat[0])\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        print(len(temp_input))\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "print(lst_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ff5c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_new=np.arange(1,101)\n",
    "day_pred=np.arange(101,131)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ef68e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a689e18",
   "metadata": {},
   "source": [
    "Predicting Future Stock Values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf518781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27f1e7277c0>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(day_new,scaler.inverse_transform(df1[1158:]))\n",
    "plt.plot(day_pred,scaler.inverse_transform(lst_output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89e098",
   "metadata": {},
   "source": [
    "predicted Stock Prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65c6459c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27f1e765e10>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3=df1.tolist()\n",
    "df3.extend(lst_output)\n",
    "plt.plot(df3[1200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adf39e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=scaler.inverse_transform(df3).tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
